# ä½¿ç”¨è„šæœ¬è®­ç»ƒ

> è¯‘è€…ï¼š[BrightLi](https://github.com/brightli)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/transformers/run_scripts>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/transformers/run_scripts>

ä½¿ç”¨è„šæœ¬è®­ç»ƒ
é™¤äº† ğŸ¤— Transformers [ç¬”è®°æœ¬](https://huggingface.co/docs/transformers/notebooks)ä¹‹å¤–ï¼Œè¿˜æœ‰ç¤ºä¾‹è„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ [PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ã€[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow)æˆ–[JAX/Flax](https://github.com/huggingface/transformers/tree/main/examples/flax)ä¸ºä»»åŠ¡è®­ç»ƒæ¨¡å‹ã€‚

ä½ è¿˜ä¼šå‘ç°æˆ‘ä»¬åœ¨æˆ‘ä»¬çš„[ç ”ç©¶é¡¹ç›®](https://github.com/huggingface/transformers/tree/main/examples/research_projects)ä¸­ä½¿ç”¨çš„è„šæœ¬å’Œä¸»è¦æ˜¯ç¤¾åŒºè´¡çŒ®çš„[é—ç•™ç¤ºä¾‹](https://github.com/huggingface/transformers/tree/main/examples/legacy)ã€‚è¿™äº›è„šæœ¬ä¸æ˜¯ç§¯æç»´æŠ¤çš„ï¼Œå¹¶ä¸”éœ€è¦ ğŸ¤— Transformers çš„ç‰¹å®šç‰ˆæœ¬ï¼Œè¿™å¾ˆå¯èƒ½ä¸åº“çš„æœ€æ–°ç‰ˆæœ¬ä¸å…¼å®¹ã€‚

ç¤ºä¾‹è„šæœ¬å¹¶ä¸æœŸæœ›åœ¨æ¯ä¸ªé—®é¢˜ä¸Šéƒ½èƒ½å³æ’å³ç”¨ï¼Œä½ å¯èƒ½éœ€è¦æ ¹æ®ä½ è¦è§£å†³çš„é—®é¢˜æ¥è°ƒæ•´è„šæœ¬ã€‚ä¸ºäº†å¸®åŠ©ä½ åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¤§å¤šæ•°è„šæœ¬éƒ½å®Œå…¨å±•ç¤ºäº†æ•°æ®æ˜¯å¦‚ä½•é¢„å¤„ç†çš„ï¼Œå…è®¸ä½ æ ¹æ®ç”¨ä¾‹éœ€è¦è¿›è¡Œç¼–è¾‘ã€‚

å¯¹äºä½ æƒ³åœ¨ç¤ºä¾‹è„šæœ¬ä¸­å®ç°çš„ä»»ä½•åŠŸèƒ½ï¼Œè¯·åœ¨æäº¤ Pull Request ä¹‹å‰åœ¨[è®ºå›](https://discuss.huggingface.co/)ä¸Šæˆ–åœ¨[é—®é¢˜](https://github.com/huggingface/transformers/issues)ä¸­è®¨è®ºã€‚è™½ç„¶æˆ‘ä»¬æ¬¢è¿ä¿®å¤é”™è¯¯ï¼Œä½†æˆ‘ä»¬ä¸å¤ªå¯èƒ½åˆå¹¶æ·»åŠ æ›´å¤šåŠŸèƒ½ä½†ç‰ºç‰²å¯è¯»æ€§çš„ Pull Requestã€‚

æœ¬æŒ‡å—å°†å±•ç¤ºå¦‚ä½•åœ¨[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)å’Œ[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)ä¸­è¿è¡Œä¸€ä¸ªç¤ºä¾‹æ‘˜è¦è®­ç»ƒè„šæœ¬ã€‚é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰ç¤ºä¾‹éƒ½åº”è¯¥å¯ä»¥åœ¨ä¸¤ä¸ªæ¡†æ¶ä¸Šè¿è¡Œã€‚

è®¾ç½®

ä¸ºäº†æˆåŠŸè¿è¡Œæœ€æ–°ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œä½ å¿…é¡»åœ¨ä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­ä»æºä»£ç **å®‰è£… ğŸ¤— Transformers**

```shell
git clone https://github.com/huggingface/transformers
cd transformers
pip install .
```

å¯¹äºæ—§ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œç‚¹å‡»ä¸‹é¢çš„åˆ‡æ¢æŒ‰é’®ï¼š
æ—§ç‰ˆæœ¬ ğŸ¤— Transformers çš„ç¤ºä¾‹
ç„¶åï¼Œå°†ä½ å½“å‰çš„ ğŸ¤— Transformers å…‹éš†åˆ‡æ¢åˆ°ç‰¹å®šç‰ˆæœ¬ï¼Œä¾‹å¦‚ v3.5.1ï¼š

```shell
git checkout tags/v3.5.1
```

åœ¨è®¾ç½®äº†æ­£ç¡®çš„åº“ç‰ˆæœ¬åï¼Œå¯¼èˆªåˆ°ä½ é€‰æ‹©çš„ç¤ºä¾‹æ–‡ä»¶å¤¹å¹¶å®‰è£…ç¤ºä¾‹ç‰¹å®šçš„è¦æ±‚ï¼š

```shell
pip install -r requirements.txt
```

**è¿è¡Œè„šæœ¬**

Pytorch

ç¤ºä¾‹è„šæœ¬ä» ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/)åº“ä¸‹è½½å¹¶é¢„å¤„ç†ä¸€ä¸ªæ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)åœ¨ä¸€ä¸ªæ”¯æŒæ‘˜è¦çš„æ¶æ„ä¸Šå¾®è°ƒæ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨ [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/google-t5/t5-small)ã€‚ç”±äº T5 çš„è®­ç»ƒæ–¹å¼ï¼ŒT5 æ¨¡å‹éœ€è¦é¢å¤–çš„ source_prefix å‚æ•°ã€‚è¿™ä¸ªæç¤ºè®© T5 çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```shell
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

TensorFlow

ç¤ºä¾‹è„šæœ¬ä» ğŸ¤—[Datasets](https://huggingface.co/docs/datasets/)åº“ä¸‹è½½å¹¶é¢„å¤„ç†ä¸€ä¸ªæ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨ Keras åœ¨ä¸€ä¸ªæ”¯æŒæ‘˜è¦çš„æ¶æ„ä¸Šå¾®è°ƒæ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/google-t5/t5-small)ã€‚ç”±äº T5 çš„è®­ç»ƒæ–¹å¼ï¼ŒT5 æ¨¡å‹éœ€è¦é¢å¤–çš„ source_prefix å‚æ•°ã€‚è¿™ä¸ªæç¤ºè®© T5 çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```shell
python examples/tensorflow/summarization/run_summarization.py  \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```

**åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦**

Trainer æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ï¼Œè¿™æ„å‘³ç€ä½ ä¹Ÿå¯ä»¥åœ¨è„šæœ¬ä¸­ä½¿ç”¨å®ƒã€‚è¦å¯ç”¨è¿™ä¸¤ä¸ªåŠŸèƒ½ï¼š

* æ·»åŠ  fp16 å‚æ•°ä»¥å¯ç”¨æ··åˆç²¾åº¦ã€‚
* ä½¿ç”¨ nproc_per_node å‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„ GPU æ•°é‡ã€‚

```shell
torchrun \
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \
    --fp16 \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

TensorFlow è„šæœ¬åˆ©ç”¨[MirroredStrategy](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy)è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œä½ ä¸éœ€è¦å‘è®­ç»ƒè„šæœ¬æ·»åŠ ä»»ä½•é¢å¤–çš„å‚æ•°ã€‚å¦‚æœå¤šä¸ª GPU å¯ç”¨ï¼ŒTensorFlow è„šæœ¬å°†é»˜è®¤ä½¿ç”¨å®ƒä»¬ã€‚

**åœ¨ TPU ä¸Šè¿è¡Œè„šæœ¬**

Pytorch

å¼ é‡å¤„ç†å•å…ƒ (TPUs) æ˜¯ä¸“é—¨ä¸ºåŠ é€Ÿæ€§èƒ½è€Œè®¾è®¡çš„ã€‚PyTorch é€šè¿‡[XLA](https://www.tensorflow.org/xla)æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨æ”¯æŒ TPUï¼ˆåœ¨[è¿™é‡Œ](https://github.com/pytorch/xla/blob/master/README.md)æŸ¥çœ‹æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼‰ã€‚è¦ä½¿ç”¨ TPUï¼Œå¯åŠ¨ xla_spawn.py è„šæœ¬å¹¶ä½¿ç”¨ num_cores å‚æ•°è®¾ç½®ä½ æƒ³ä½¿ç”¨çš„ TPU æ ¸å¿ƒæ•°ã€‚

```shell
python xla_spawn.py --num_cores 8 \
    summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

TensorFlow

å¼ é‡å¤„ç†å•å…ƒ (TPUs) æ˜¯ä¸“é—¨ä¸ºåŠ é€Ÿæ€§èƒ½è€Œè®¾è®¡çš„ã€‚TensorFlow è„šæœ¬åˆ©ç”¨ [TPUStrategy](https://www.tensorflow.org/guide/distributed_training#tpustrategy)åœ¨ TPU ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¦ä½¿ç”¨ TPUï¼Œå°† TPU èµ„æºçš„åç§°ä¼ é€’ç»™ tpu å‚æ•°ã€‚

```shell
python run_summarization.py  \
    --tpu name_of_tpu_resource \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```

**ä½¿ç”¨ ğŸ¤— Accelerate è¿è¡Œè„šæœ¬**

ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)æ˜¯ä¸€ä¸ªä»…é™ PyTorch çš„åº“ï¼Œå®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³•æ¥åœ¨å‡ ç§ç±»å‹çš„è®¾ç½®ä¸Šè®­ç»ƒæ¨¡å‹ï¼ˆä»…é™ CPUã€å¤šä¸ª GPUã€TPUï¼‰ï¼ŒåŒæ—¶ä¿æŒå¯¹ PyTorch è®­ç»ƒå¾ªç¯çš„å®Œå…¨å¯è§æ€§ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£… ğŸ¤— Accelerateï¼Œè¯·ç¡®ä¿å®‰è£…äº†å®ƒï¼š

>æ³¨æ„ï¼šç”±äº Accelerate æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œå¿…é¡»å®‰è£…åŠ é€Ÿçš„ git ç‰ˆæœ¬æ‰èƒ½è¿è¡Œè„šæœ¬
>
>```shell
>pip install git+https://github.com/huggingface/accelerate
>```

ä½ éœ€è¦ä½¿ç”¨ run_summarization_no_trainer.py è„šæœ¬ï¼Œè€Œä¸æ˜¯ run_summarization.py è„šæœ¬ã€‚æ”¯æŒ ğŸ¤— Accelerate çš„è„šæœ¬ä¼šåœ¨æ–‡ä»¶å¤¹ä¸­æœ‰ä¸€ä¸ª task_no_trainer.py æ–‡ä»¶ã€‚é¦–å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š

```shell
accelerate config
```

æµ‹è¯•ä½ çš„è®¾ç½®ä»¥ç¡®ä¿å…¶é…ç½®æ­£ç¡®ï¼š

```shell
accelerate test
```

ç°åœ¨ä½ å·²ç»å‡†å¤‡å¥½å¯åŠ¨è®­ç»ƒäº†ï¼š

```shell
accelerate launch run_summarization_no_trainer.py \
    --model_name_or_path google-t5/t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir ~/tmp/tst-summarization
```

**ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†**

åªè¦æ•°æ®é›†æ˜¯ CSV æˆ– JSON Line æ–‡ä»¶ï¼Œæ‘˜è¦è„šæœ¬å°±æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†ã€‚å½“ä½ ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†æ—¶ï¼Œä½ éœ€è¦æŒ‡å®šå‡ ä¸ªé¢å¤–çš„å‚æ•°ï¼š

* train_file å’Œ validation_file æŒ‡å®šä½ çš„è®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶çš„è·¯å¾„ã€‚
* text_column æ˜¯è¦æ€»ç»“çš„è¾“å…¥æ–‡æœ¬ã€‚
* summary_column æ˜¯è¦è¾“å‡ºçš„ç›®æ ‡æ–‡æœ¬ã€‚

ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†çš„æ‘˜è¦è„šæœ¬å°†å¦‚ä¸‹æ‰€ç¤ºï¼š

```shell
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --train_file path_to_csv_or_jsonlines_file \
    --validation_file path_to_csv_or_jsonlines_file \
    --text_column text_column_name \
    --summary_column summary_column_name \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --overwrite_output_dir \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --predict_with_generate
```

**æµ‹è¯•è„šæœ¬**

åœ¨æäº¤å¯èƒ½éœ€è¦æ•°å°æ—¶æ‰èƒ½å®Œæˆçš„æ•´ä¸ªæ•°æ®é›†ä¹‹å‰ï¼Œé€šå¸¸æœ€å¥½åœ¨è¾ƒå°‘çš„æ•°æ®é›†ç¤ºä¾‹ä¸Šè¿è¡Œä½ çš„è„šæœ¬ä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œã€‚ä½¿ç”¨ä»¥ä¸‹å‚æ•°å°†æ•°æ®é›†æˆªæ–­åˆ°æœ€å¤§æ ·æœ¬æ•°ï¼š

* max_train_samples
* max_eval_samples
* max_predict_samples

```shell
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path google-t5/t5-small \
    --max_train_samples 50 \
    --max_eval_samples 50 \
    --max_predict_samples 50 \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

å¹¶éæ‰€æœ‰ç¤ºä¾‹è„šæœ¬éƒ½æ”¯æŒ max_predict_samples å‚æ•°ã€‚å¦‚æœä½ ä¸ç¡®å®šä½ çš„è„šæœ¬æ˜¯å¦æ”¯æŒæ­¤å‚æ•°ï¼Œæ·»åŠ  -h å‚æ•°ä»¥æ£€æŸ¥ï¼š

```shell
examples/pytorch/summarization/run_summarization.py -h
```

**ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ**

å¦ä¸€ä¸ªæœ‰ç”¨çš„é€‰é¡¹æ˜¯èƒ½å¤Ÿä»å‰ä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¿™å°†ç¡®ä¿å¦‚æœä½ çš„è®­ç»ƒè¢«ä¸­æ–­ï¼Œä½ å¯ä»¥ä»ä¸­æ–­çš„åœ°æ–¹ç»§ç»­ï¼Œè€Œä¸å¿…é‡æ–°å¼€å§‹ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚
ç¬¬ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ output_dir previous_output_dir å‚æ•°ä»å‰ä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œè¯¥æ£€æŸ¥ç‚¹å­˜å‚¨åœ¨ output_dir ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥ç§»é™¤ overwrite_output_dirï¼š

```shell
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --output_dir previous_output_dir \
    --predict_with_generate
```

ç¬¬äºŒç§æ–¹æ³•æ˜¯ä½¿ç”¨ resume_from_checkpoint path_to_specific_checkpoint å‚æ•°ä»ç‰¹å®šæ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹æ¢å¤è®­ç»ƒã€‚

```shell
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --resume_from_checkpoint path_to_specific_checkpoint \
    --predict_with_generate
```

**åˆ†äº«ä½ çš„æ¨¡å‹**

æ‰€æœ‰è„šæœ¬éƒ½å¯ä»¥å°†ä½ çš„æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ°[Model Hub](https://huggingface.co/models)ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»ç™»å½• Hugging Faceï¼š

```shell
huggingface-cli login
```

ç„¶ååœ¨è„šæœ¬ä¸­æ·»åŠ  push_to_hub å‚æ•°ã€‚æ­¤å‚æ•°å°†ä½¿ç”¨ä½ çš„ Hugging Face ç”¨æˆ·åå’Œ output_dir ä¸­æŒ‡å®šçš„æ–‡ä»¶å¤¹åç§°åˆ›å»ºä¸€ä¸ªä»“åº“ã€‚
è¦ä¸ºä½ çš„ä»“åº“æŒ‡å®šä¸€ä¸ªå…·ä½“åç§°ï¼Œè¯·ä½¿ç”¨ push_to_hub_model_id å‚æ•°æ·»åŠ å®ƒã€‚è¯¥ä»“åº“å°†è‡ªåŠ¨åˆ—åœ¨ä½ çš„å‘½åç©ºé—´ä¸‹ã€‚
ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä¸Šä¼ å…·æœ‰ç‰¹å®šä»“åº“åç§°çš„æ¨¡å‹ï¼š

```shell
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --push_to_hub \
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```