# è‡ªåŠ¨æµæ°´çº¿

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/tutorials/autopipeline>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/tutorials/autopipeline>


ğŸ¤— Diffusers èƒ½å¤Ÿå®Œæˆè®¸å¤šä¸åŒçš„ä»»åŠ¡ï¼Œå¹¶ä¸”æ‚¨é€šå¸¸å¯ä»¥å°†ç›¸åŒçš„é¢„è®­ç»ƒæƒé‡é‡å¤ç”¨äºå¤šä¸ªä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤ã€‚å¦‚æœæ‚¨å¯¹åº“å’Œæ‰©æ•£æ¨¡å‹ä¸ç†Ÿæ‚‰ï¼Œå¯èƒ½å¾ˆéš¾çŸ¥é“è¦ä½¿ç”¨å“ªä¸ªç®¡é“æ¥å®Œæˆä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨
 [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 æ–‡æœ¬åˆ°å›¾åƒçš„æ£€æŸ¥ç‚¹ï¼Œæ‚¨å¯èƒ½ä¸çŸ¥é“è¿˜å¯ä»¥é€šè¿‡ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åŠ è½½æ£€æŸ¥ç‚¹æ¥å°†å…¶ç”¨äºå›¾åƒåˆ°å›¾åƒå’Œä¿®å¤
 [StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)
 å’Œ
 [StableDiffusionInpaintPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline)
 åˆ†åˆ«ä¸Šè¯¾ã€‚


è¿™
 `è‡ªåŠ¨ç®¡é“`
 ç±»æ—¨åœ¨ç®€åŒ– ğŸ¤— Diffusers ä¸­çš„å„ç§ç®¡é“ã€‚å®ƒæ˜¯ä¸€ä¸ªé€šç”¨çš„ï¼Œ
 *ä»»åŠ¡ä¼˜å…ˆ*
 è®©æ‚¨ä¸“æ³¨äºä»»åŠ¡çš„ç®¡é“ã€‚è¿™
 `è‡ªåŠ¨ç®¡é“`
 è‡ªåŠ¨æ£€æµ‹è¦ä½¿ç”¨çš„æ­£ç¡®ç®¡é“ç±»ï¼Œè¿™ä½¿å¾—åœ¨ä¸çŸ¥é“ç‰¹å®šç®¡é“ç±»åç§°çš„æƒ…å†µä¸‹æ›´å®¹æ˜“åŠ è½½ä»»åŠ¡çš„æ£€æŸ¥ç‚¹ã€‚


çœ‹çœ‹
 [è‡ªåŠ¨ç®¡é“](../api/pipelines/auto_pipeline)
 å‚è€ƒä»¥æŸ¥çœ‹æ”¯æŒå“ªäº›ä»»åŠ¡ã€‚ç›®å‰ï¼Œå®ƒæ”¯æŒæ–‡æœ¬è½¬å›¾åƒã€å›¾åƒè½¬å›¾åƒå’Œä¿®å¤ã€‚


æœ¬æ•™ç¨‹å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨
 `è‡ªåŠ¨ç®¡é“`
 ç»™å®šé¢„è®­ç»ƒæƒé‡ï¼Œè‡ªåŠ¨æ¨æ–­è¦ä¸ºç‰¹å®šä»»åŠ¡åŠ è½½çš„ç®¡é“ç±»ã€‚


## ä¸ºæ‚¨çš„ä»»åŠ¡é€‰æ‹© AutoPipeline



é¦–å…ˆé€‰æ‹©ä¸€ä¸ªæ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å¯¹æ–‡æœ¬åˆ°å›¾åƒæ„Ÿå…´è¶£
 [runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 æ£€æŸ¥ç‚¹ï¼Œä½¿ç”¨
 [AutoPipelineForText2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)
 :



```
from diffusers import AutoPipelineForText2Image
import torch

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
prompt = "peasant and dragon combat, wood cutting style, viking era, bevel with rune"

image = pipeline(prompt, num_inference_steps=25).images[0]
image
```


![ç”Ÿæˆçš„æœ¨å¤´åˆ‡å‰²é£æ ¼å†œæ°‘æ–—é¾™å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-text2img.png)


 åœ¨å¼•æ“ç›–ä¸‹ï¼Œ
 [AutoPipelineForText2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForText2Image)
 :


1.è‡ªåŠ¨æ£€æµ‹
 `â€œç¨³å®šæ‰©æ•£â€`
 ç±»æ¥è‡ª
 [`model_index.json`](https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json)
 æ–‡ä»¶
2.åŠ è½½å¯¹åº”çš„æ–‡å­—è½¬å›¾ç‰‡
 [StableDiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 åŸºäº
 `â€œç¨³å®šæ‰©æ•£â€`
 ç­çº§åç§°


åŒæ ·ï¼Œå¯¹äºå›¾åƒåˆ°å›¾åƒï¼Œ
 [AutoPipelineForImage2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)
 æ£€æµ‹åˆ°ä¸€ä¸ª
 `â€œç¨³å®šæ‰©æ•£â€`
 æ£€æŸ¥ç«™ä»
 `model_index.json`
 æ–‡ä»¶ï¼Œå®ƒä¼šåŠ è½½ç›¸åº”çš„
 [StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)
 åœ¨å¹•åã€‚æ‚¨è¿˜å¯ä»¥ä¼ é€’ç‰¹å®šäºç®¡é“ç±»çš„ä»»ä½•å…¶ä»–å‚æ•°ï¼Œä¾‹å¦‚
 â€˜åŠ›é‡â€™
 ï¼Œå®ƒç¡®å®šæ·»åŠ åˆ°è¾“å…¥å›¾åƒçš„å™ªå£°æˆ–å˜åŒ–é‡ï¼š



```
from diffusers import AutoPipelineForImage2Image
import torch
import requests
from PIL import Image
from io import BytesIO

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
).to("cuda")
prompt = "a portrait of a dog wearing a pearl earring"

url = "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/1665\_Girl\_with\_a\_Pearl\_Earring.jpg/800px-1665\_Girl\_with\_a\_Pearl\_Earring.jpg"

response = requests.get(url)
image = Image.open(BytesIO(response.content)).convert("RGB")
image.thumbnail((768, 768))

image = pipeline(prompt, image, num_inference_steps=200, strength=0.75, guidance_scale=10.5).images[0]
image
```


![ç”Ÿæˆçš„æˆ´ç€çç è€³ç¯çš„ç‹—çš„ç»´ç±³å°”è‚–åƒå›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-img2img.png)


 å¦‚æœä½ æƒ³åšä¿®å¤ï¼Œé‚£ä¹ˆ
 [AutoPipelineForInpainting](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 åŠ è½½åº•å±‚
 [StableDiffusionInpaintPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline)
 ä»¥åŒæ ·çš„æ–¹å¼ç±»ï¼š



```
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image
import torch

pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo\_mask.png"

init_image = load_image(img_url).convert("RGB")
mask_image = load_image(mask_url).convert("RGB")

prompt = "A majestic tiger sitting on a bench"
image = pipeline(prompt, image=init_image, mask_image=mask_image, num_inference_steps=50, strength=0.80).images[0]
image
```


![ç”Ÿæˆçš„è€è™ååœ¨é•¿å‡³ä¸Šçš„å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/autopipeline-inpaint.png)


 å¦‚æœæ‚¨å°è¯•åŠ è½½ä¸å—æ”¯æŒçš„æ£€æŸ¥ç‚¹ï¼Œåˆ™ä¼šæŠ›å‡ºé”™è¯¯ï¼š



```
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "openai/shap-e-img2img", torch_dtype=torch.float16, use_safetensors=True
)
"ValueError: AutoPipeline can't find a pipeline linked to ShapEImg2ImgPipeline for None"
```


## ä½¿ç”¨å¤šä¸ªç®¡é“



å¯¹äºæŸäº›å·¥ä½œæµç¨‹æˆ–å¦‚æœæ‚¨è¦åŠ è½½è®¸å¤šç®¡é“ï¼Œä»æ£€æŸ¥ç‚¹é‡ç”¨ç›¸åŒçš„ç»„ä»¶ä¼šæ›´èŠ‚çœå†…å­˜ï¼Œè€Œä¸æ˜¯é‡æ–°åŠ è½½å®ƒä»¬ï¼Œè¿™ä¼šä¸å¿…è¦åœ°æ¶ˆè€—é¢å¤–çš„å†…å­˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒçš„æ£€æŸ¥ç‚¹ï¼Œå¹¶ä¸”æƒ³è¦å†æ¬¡å°†å…¶ç”¨äºå›¾åƒåˆ°å›¾åƒï¼Œè¯·ä½¿ç”¨
 [from\_pipe()](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
 æ–¹æ³•ã€‚æ­¤æ–¹æ³•ä»å…ˆå‰åŠ è½½çš„ç®¡é“çš„ç»„ä»¶åˆ›å»ºæ–°ç®¡é“ï¼Œæ— éœ€é¢å¤–çš„å†…å­˜æˆæœ¬ã€‚


è¿™
 [from\_pipe()](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
 æ–¹æ³•æ£€æµ‹åŸå§‹ç®¡é“ç±»å¹¶å°†å…¶æ˜ å°„åˆ°ä¸æ‚¨æƒ³è¦æ‰§è¡Œçš„ä»»åŠ¡ç›¸å¯¹åº”çš„æ–°ç®¡é“ç±»ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åŠ è½½ä¸€ä¸ª
 `â€œç¨³å®šæ‰©æ•£â€`
 æ–‡æœ¬åˆ°å›¾åƒçš„ç±»ç®¡é“ï¼š



```
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
print(type(pipeline_text2img))
"<class 'diffusers.pipelines.stable\_diffusion.pipeline\_stable\_diffusion.StableDiffusionPipeline'>"
```


ç„¶å
 [from\_pipe()](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
 æ˜ å°„åŸå§‹çš„
 `â€œç¨³å®šæ‰©æ•£â€`
 ç®¡é“ç±»è‡³
 [StableDiffusionImg2ImgPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/img2img#diffusers.StableDiffusionImg2ImgPipeline)
 :



```
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(type(pipeline_img2img))
"<class 'diffusers.pipelines.stable\_diffusion.pipeline\_stable\_diffusion\_img2img.StableDiffusionImg2ImgPipeline'>"
```


å¦‚æœæ‚¨å°†å¯é€‰å‚æ•°ï¼ˆä¾‹å¦‚ç¦ç”¨å®‰å…¨æ£€æŸ¥å™¨ï¼‰ä¼ é€’ç»™åŸå§‹ç®¡é“ï¼Œåˆ™è¯¥å‚æ•°ä¹Ÿä¼šä¼ é€’ç»™æ–°ç®¡é“ï¼š



```
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch

pipeline_text2img = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_safetensors=True,
    requires_safety_checker=False,
).to("cuda")

pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)
print(pipeline_img2img.config.requires_safety_checker)
"False"
```


å¦‚æœæ‚¨æƒ³æ›´æ”¹æ–°ç®¡é“çš„è¡Œä¸ºï¼Œæ‚¨å¯ä»¥è¦†ç›–åŸå§‹ç®¡é“ä¸­çš„ä»»ä½•å‚æ•°ç”šè‡³é…ç½®ã€‚ä¾‹å¦‚ï¼Œè¦é‡æ–°æ‰“å¼€å®‰å…¨æ£€æŸ¥å™¨å¹¶æ·»åŠ 
 â€˜åŠ›é‡â€™
 äº‰è®ºï¼š



```
pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img, requires_safety_checker=True, strength=0.3)
print(pipeline_img2img.config.requires_safety_checker)
"True"
```