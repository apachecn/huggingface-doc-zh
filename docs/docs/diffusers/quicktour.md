![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


# å¿«é€Ÿæ¸¸è§ˆ

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/quicktour>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/quicktour>


æ‰©æ•£æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥é€æ­¥å¯¹éšæœºé«˜æ–¯å™ªå£°è¿›è¡Œå»å™ªï¼Œä»¥ç”Ÿæˆæ„Ÿå…´è¶£çš„æ ·æœ¬ï¼Œä¾‹å¦‚å›¾åƒæˆ–éŸ³é¢‘ã€‚è¿™å¼•å‘äº†äººä»¬å¯¹ç”Ÿæˆäººå·¥æ™ºèƒ½çš„å·¨å¤§å…´è¶£ï¼Œå¹¶ä¸”æ‚¨å¯èƒ½å·²ç»åœ¨äº’è”ç½‘ä¸Šçœ‹åˆ°äº†æ‰©æ•£ç”Ÿæˆå›¾åƒçš„ç¤ºä¾‹ã€‚ ğŸ§¨ Diffusers æ˜¯ä¸€ä¸ªæ—¨åœ¨è®©æ¯ä¸ªäººéƒ½èƒ½å¹¿æ³›ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„åº“ã€‚


æ— è®ºæ‚¨æ˜¯å¼€å‘äººå‘˜è¿˜æ˜¯æ—¥å¸¸ç”¨æˆ·ï¼Œæ­¤å¿«é€Ÿæ•™ç¨‹éƒ½ä¼šå‘æ‚¨ä»‹ç» ğŸ§¨ Diffusersï¼Œå¹¶å¸®åŠ©æ‚¨å¿«é€Ÿå…¥é—¨å’Œç”Ÿæˆï¼è¯¥åº“éœ€è¦äº†è§£ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼š


* è¿™
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 æ˜¯ä¸€ä¸ªé«˜çº§ç«¯åˆ°ç«¯ç±»ï¼Œæ—¨åœ¨ä»é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¿«é€Ÿç”Ÿæˆæ ·æœ¬ä»¥è¿›è¡Œæ¨ç†ã€‚
* æµè¡Œçš„é¢„è®­ç»ƒ
 [æ¨¡å‹](./api/models)
 å¯ç”¨ä½œåˆ›å»ºæ‰©æ•£ç³»ç»Ÿçš„æ„å»ºå—çš„æ¶æ„å’Œæ¨¡å—ã€‚
* å¾ˆå¤šä¸åŒ
 [è°ƒåº¦ç¨‹åº](./api/schedulers/overview)
 - æ§åˆ¶å¦‚ä½•åœ¨è®­ç»ƒä¸­æ·»åŠ å™ªå£°ä»¥åŠå¦‚ä½•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç”Ÿæˆå»å™ªå›¾åƒçš„ç®—æ³•ã€‚


å¿«é€Ÿæµè§ˆå°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 è¿›è¡Œæ¨ç†ï¼Œç„¶åå¼•å¯¼æ‚¨äº†è§£å¦‚ä½•ç»“åˆæ¨¡å‹å’Œè°ƒåº¦ç¨‹åºæ¥å¤åˆ¶å†…éƒ¨å‘ç”Ÿçš„æƒ…å†µ
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 ã€‚


Quicktour æ˜¯ä»‹ç»æ€§ ğŸ§¨ æ‰©æ•£å™¨çš„ç®€åŒ–ç‰ˆæœ¬
 [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)
 å¸®åŠ©æ‚¨å¿«é€Ÿå…¥é—¨ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤šå…³äº ğŸ§¨ Diffusers çš„ç›®æ ‡ã€è®¾è®¡ç†å¿µä»¥åŠå…¶æ ¸å¿ƒ API çš„å…¶ä»–è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ç¬”è®°æœ¬ï¼


åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…éœ€çš„åº“ï¼š



```
# uncomment to install the necessary libraries in Colab
#!pip install --upgrade diffusers accelerate transformers
```


* [ğŸ¤— åŠ é€Ÿ](https://huggingface.co/docs/accelerate/index)
 åŠ å¿«æ¨ç†å’Œè®­ç»ƒçš„æ¨¡å‹åŠ è½½é€Ÿåº¦ã€‚
* [ğŸ¤— å˜å½¢é‡‘åˆš](https://huggingface.co/docs/transformers/index)
 éœ€è¦è¿è¡Œæœ€æµè¡Œçš„æ‰©æ•£æ¨¡å‹ï¼Œä¾‹å¦‚
 [ç¨³å®šæ‰©æ•£](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview)
 ã€‚


## æ‰©æ•£ç®¡é“



è¿™
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 æ˜¯ä½¿ç”¨é¢„è®­ç»ƒæ‰©æ•£ç³»ç»Ÿè¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•ã€‚å®ƒæ˜¯ä¸€ä¸ªåŒ…å«æ¨¡å‹å’Œè°ƒåº¦ç¨‹åºçš„ç«¯åˆ°ç«¯ç³»ç»Ÿã€‚æ‚¨å¯ä»¥ä½¿ç”¨
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 å¯¹äºè®¸å¤šä»»åŠ¡æ¥è¯´ï¼Œå¼€ç®±å³ç”¨ã€‚è¯·æŸ¥çœ‹ä¸‹è¡¨ï¼Œäº†è§£ä¸€äº›æ”¯æŒçš„ä»»åŠ¡ï¼Œæœ‰å…³æ”¯æŒçš„ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹
 [ğŸ§¨ æ‰©æ•£å™¨æ‘˜è¦](./api/pipelines/overview#diffusers-summary)
 æ¡Œå­ã€‚


| **Task**  | **Description**  | **Pipeline**  |
| --- | --- | --- |
| 	 Unconditional Image Generation	  | 	 generate an image from Gaussian noise	  | [unconditional\_image\_generation](./using-diffusers/unconditional_image_generation)  |
| 	 Text-Guided Image Generation	  | 	 generate an image given a text prompt	  | [conditional\_image\_generation](./using-diffusers/conditional_image_generation)  |
| 	 Text-Guided Image-to-Image Translation	  | 	 adapt an image guided by a text prompt	  | [img2img](./using-diffusers/img2img)  |
| 	 Text-Guided Image-Inpainting	  | 	 fill the masked part of an image given the image, the mask and a text prompt	  | [inpaint](./using-diffusers/inpaint)  |
| 	 Text-Guided Depth-to-Image Translation	  | 	 adapt parts of an image guided by a text prompt while preserving structure via depth estimation	  | [depth2img](./using-diffusers/depth2img)  |


é¦–å…ˆåˆ›å»ºä¸€ä¸ªå®ä¾‹
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 å¹¶æŒ‡å®šæ‚¨è¦ä¸‹è½½çš„ç®¡é“æ£€æŸ¥ç‚¹ã€‚
æ‚¨å¯ä»¥ä½¿ç”¨
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 å¯¹äºä»»ä½•
 [æ£€æŸ¥ç‚¹](https://huggingface.co/models?library=diffusers&sort=downloads)
 å­˜å‚¨åœ¨ Hugging Face Hub ä¸Šã€‚
åœ¨æ­¤å¿«é€Ÿæµè§ˆä¸­ï¼Œæ‚¨å°†åŠ è½½
 [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æ£€æŸ¥ç‚¹ã€‚


ä¸ºäº†
 [ç¨³å®šæ‰©æ•£](https://huggingface.co/CompVis/stable-diffusion)
 å‹å·è¯·ä»”ç»†é˜…è¯»
 [è®¸å¯è¯](https://huggingface.co/spaces/CompVis/stable-diffusion-license)
 é¦–å…ˆåœ¨è¿è¡Œæ¨¡å‹ä¹‹å‰ã€‚ ğŸ§¨ æ‰©æ•£å™¨å®ç°äº†
 [`safety_checker`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py)
 ä»¥é˜²æ­¢æ”»å‡»æ€§æˆ–æœ‰å®³å†…å®¹ï¼Œä½†è¯¥æ¨¡å‹æ”¹è¿›çš„å›¾åƒç”ŸæˆåŠŸèƒ½ä»ç„¶å¯ä»¥äº§ç”Ÿæ½œåœ¨çš„æœ‰å®³å†…å®¹ã€‚


åŠ è½½æ¨¡å‹
 [æ¥è‡ª\_pretrained()](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
 æ–¹æ³•ï¼š



```
>>> from diffusers import DiffusionPipeline

>>> pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
```


è¿™
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 ä¸‹è½½å¹¶ç¼“å­˜æ‰€æœ‰å»ºæ¨¡ã€æ ‡è®°åŒ–å’Œè°ƒåº¦ç»„ä»¶ã€‚æ‚¨ä¼šçœ‹åˆ°ç¨³å®šæ‰©æ•£ç®¡é“ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆ
 [UNet2DConditionModel](/docs/diffusers/v0.23.1/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
 å’Œ
 [PNDMScheduler](/docs/diffusers/v0.23.1/en/api/schedulers/pndm#diffusers.PNDMScheduler)
 é™¤å…¶ä»–äº‹é¡¹å¤–ï¼š



```
>>> pipeline
StableDiffusionPipeline {
  "\_class\_name": "StableDiffusionPipeline",
  "\_diffusers\_version": "0.21.4",
  ...,
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  ...,
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}
```


æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨ GPU ä¸Šè¿è¡Œç®¡é“ï¼Œå› ä¸ºè¯¥æ¨¡å‹ç”±å¤§çº¦ 14 äº¿ä¸ªå‚æ•°ç»„æˆã€‚
æ‚¨å¯ä»¥å°†ç”Ÿæˆå™¨å¯¹è±¡ç§»åŠ¨åˆ° GPUï¼Œå°±åƒåœ¨ PyTorch ä¸­ä¸€æ ·ï¼š



```
>>> pipeline.to("cuda")
```


ç°åœ¨æ‚¨å¯ä»¥å°†æ–‡æœ¬æç¤ºä¼ é€’ç»™
 `ç®¡é“`
 ç”Ÿæˆå›¾åƒï¼Œç„¶åè®¿é—®å»å™ªå›¾åƒã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå›¾åƒè¾“å‡ºåŒ…è£…åœ¨
 [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=image#the-image-class)
 ç›®çš„ã€‚



```
>>> image = pipeline("An image of a squirrel in Picasso style").images[0]
>>> image
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/image_of_squirrel_painting.png)


 é€šè¿‡è°ƒç”¨ä¿å­˜å›¾åƒ
 `ä¿å­˜`
 :



```
>>> image.save("image\_of\_squirrel\_painting.png")
```


### 


 æœ¬åœ°ç®¡é“


æ‚¨è¿˜å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨ç®¡é“ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯æ‚¨éœ€è¦å…ˆä¸‹è½½æƒé‡ï¼š



```
!git lfs install
!git clone https://huggingface.co/runwayml/stable-diffusion-v1-5
```


ç„¶åå°†ä¿å­˜çš„æƒé‡åŠ è½½åˆ°ç®¡é“ä¸­ï¼š



```
>>> pipeline = DiffusionPipeline.from_pretrained("./stable-diffusion-v1-5", use_safetensors=True)
```


ç°åœ¨ï¼Œæ‚¨å¯ä»¥åƒä¸Šä¸€èŠ‚ä¸­é‚£æ ·è¿è¡Œç®¡é“ã€‚


### 


 äº¤æ¢è°ƒåº¦ç¨‹åº


ä¸åŒçš„è°ƒåº¦å™¨å…·æœ‰ä¸åŒçš„å»å™ªé€Ÿåº¦å’Œè´¨é‡æƒè¡¡ã€‚æ‰¾å‡ºå“ªä¸€ç§æœ€é€‚åˆæ‚¨çš„æœ€ä½³æ–¹æ³•å°±æ˜¯å°è¯•ä¸€ä¸‹ï¼ ğŸ§¨ Diffusers çš„ä¸»è¦åŠŸèƒ½ä¹‹ä¸€æ˜¯å…è®¸æ‚¨è½»æ¾åœ°åœ¨è°ƒåº¦ç¨‹åºä¹‹é—´åˆ‡æ¢ã€‚ä¾‹å¦‚ï¼Œè¦æ›¿æ¢é»˜è®¤çš„
 [PNDMScheduler](/docs/diffusers/v0.23.1/en/api/schedulers/pndm#diffusers.PNDMScheduler)
 ä¸
 [EulerDiscreteScheduler](/docs/diffusers/v0.23.1/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
 ï¼ŒåŠ è½½å®ƒ
 [from\_config()](/docs/diffusers/v0.23.1/en/api/configuration#diffusers.ConfigMixin.from_config)
 æ–¹æ³•ï¼š



```
>>> from diffusers import EulerDiscreteScheduler

>>> pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", use_safetensors=True)
>>> pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)
```


å°è¯•ä½¿ç”¨æ–°çš„è°ƒåº¦ç¨‹åºç”Ÿæˆå›¾åƒï¼Œçœ‹çœ‹æ‚¨æ˜¯å¦æ³¨æ„åˆ°å·®å¼‚ï¼


åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæ‚¨å°†ä»”ç»†ç ”ç©¶ç»„æˆæ¨¡å‹å’Œè°ƒåº¦ç¨‹åºçš„ç»„ä»¶
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 å¹¶å­¦ä¹ å¦‚ä½•ä½¿ç”¨è¿™äº›ç»„ä»¶ç”ŸæˆçŒ«çš„å›¾åƒã€‚


## æ¥·æ¨¡



å¤§å¤šæ•°æ¨¡å‹éƒ½ä¼šé‡‡ç”¨å™ªå£°æ ·æœ¬ï¼Œå¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥é¢„æµ‹
 *æ®‹ç•™å™ªéŸ³*
 ï¼ˆå…¶ä»–æ¨¡å‹å­¦ä¹ ç›´æ¥é¢„æµ‹å…ˆå‰çš„æ ·æœ¬æˆ–é€Ÿåº¦æˆ–
 [`v-é¢„æµ‹`](https://github.com/huggingface/diffusers/blob/5e5ce13e2f89ac45a0066cb3f369462a3cf1d9ef/src/diffusers/schedulers/scheduling_ddim.py#L110)
 ï¼‰ï¼Œå™ªå£°è¾ƒå°çš„å›¾åƒä¸è¾“å…¥å›¾åƒä¹‹é—´çš„å·®å¼‚ã€‚æ‚¨å¯ä»¥æ··åˆæ­é…æ¨¡å‹æ¥åˆ›å»ºå…¶ä»–æ‰©æ•£ç³»ç»Ÿã€‚


æ¨¡å‹æ˜¯ç”±
 [æ¥è‡ª_pretrained()](/docs/diffusers/v0.23.1/en/api/models/overview#diffusers.ModelMixin.from_pretrained)
 æ–¹æ³•è¿˜ä¼šåœ¨æœ¬åœ°ç¼“å­˜æ¨¡å‹æƒé‡ï¼Œå› æ­¤ä¸‹æ¬¡åŠ è½½æ¨¡å‹æ—¶é€Ÿåº¦ä¼šæ›´å¿«ã€‚å¯¹äºå¿«é€Ÿæµè§ˆï¼Œæ‚¨å°†åŠ è½½
 [UNet2DModel](/docs/diffusers/v0.23.1/en/api/models/unet2d#diffusers.UNet2DModel)
 ï¼Œä¸€ä¸ªåŸºæœ¬çš„æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¸¦æœ‰åœ¨çŒ«å›¾åƒä¸Šè®­ç»ƒçš„æ£€æŸ¥ç‚¹ï¼š



```
>>> from diffusers import UNet2DModel

>>> repo_id = "google/ddpm-cat-256"
>>> model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)
```


è¦è®¿é—®æ¨¡å‹å‚æ•°ï¼Œè¯·è°ƒç”¨
 `æ¨¡å‹.config`
 :



```
>>> model.config
```


æ¨¡å‹é…ç½®æ˜¯ä¸€ä¸ªğŸ§Šå†»ç»“ğŸ§Šå­—å…¸ï¼Œè¿™æ„å‘³ç€è¿™äº›å‚æ•°åœ¨æ¨¡å‹åˆ›å»ºåæ— æ³•æ›´æ”¹ã€‚è¿™æ˜¯æœ‰æ„ä¸ºä¹‹ï¼Œå¹¶ç¡®ä¿ä¸€å¼€å§‹ç”¨äºå®šä¹‰æ¨¡å‹æ¶æ„çš„å‚æ•°ä¿æŒä¸å˜ï¼Œè€Œå…¶ä»–å‚æ•°ä»ç„¶å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œè°ƒæ•´ã€‚


ä¸€äº›æœ€é‡è¦çš„å‚æ•°æ˜¯ï¼š


* `æ ·æœ¬å¤§å°`
 ï¼šè¾“å…¥æ ·æœ¬çš„é«˜åº¦å’Œå®½åº¦å°ºå¯¸ã€‚
* `in_channels`
 ï¼šè¾“å…¥æ ·æœ¬çš„è¾“å…¥é€šé“æ•°ã€‚
* `down_block_types`
 å’Œ
 `up_block_types`
 ï¼šç”¨äºåˆ›å»º UNet æ¶æ„çš„ä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·æ¨¡å—çš„ç±»å‹ã€‚
* `block_out_channels`
 ï¼šä¸‹é‡‡æ ·å—çš„è¾“å‡ºé€šé“æ•°ï¼›ä¹Ÿä»¥ç›¸åçš„é¡ºåºç”¨äºä¸Šé‡‡æ ·å—çš„è¾“å…¥é€šé“çš„æ•°é‡ã€‚
* `æ¯å—å±‚æ•°`
 ï¼šæ¯ä¸ª UNet å—ä¸­å­˜åœ¨çš„ ResNet å—çš„æ•°é‡ã€‚


è¦ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè¯·ä½¿ç”¨éšæœºé«˜æ–¯å™ªå£°åˆ›å»ºå›¾åƒå½¢çŠ¶ã€‚å®ƒåº”è¯¥æœ‰ä¸€ä¸ª
 `æ‰¹é‡`
 è½´ï¼Œå› ä¸ºæ¨¡å‹å¯ä»¥æ¥æ”¶å¤šä¸ªéšæœºå™ªå£°ï¼Œ
 `é¢‘é“`
 è½´å¯¹åº”äºè¾“å…¥é€šé“çš„æ•°é‡ï¼Œä»¥åŠ
 `æ ·æœ¬å¤§å°`
 å›¾åƒçš„é«˜åº¦å’Œå®½åº¦è½´ï¼š



```
>>> import torch

>>> torch.manual_seed(0)

>>> noisy_sample = torch.randn(1, model.config.in_channels, model.config.sample_size, model.config.sample_size)
>>> noisy_sample.shape
torch.Size([1, 3, 256, 256])
```


ä¸ºäº†è¿›è¡Œæ¨ç†ï¼Œä¼ é€’å™ªå£°å›¾åƒå’Œ
 `æ—¶é—´æ­¥é•¿`
 åˆ°æ¨¡å‹ã€‚è¿™
 `æ—¶é—´æ­¥é•¿`
 è¡¨ç¤ºè¾“å…¥å›¾åƒçš„å™ªå£°ç¨‹åº¦ï¼Œå¼€å§‹æ—¶å™ªå£°è¾ƒå¤šï¼Œç»“å°¾æ—¶å™ªå£°è¾ƒå°‘ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹ç¡®å®šå…¶åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­çš„ä½ç½®ï¼Œæ— è®ºæ˜¯æ›´æ¥è¿‘å¼€å§‹è¿˜æ˜¯ç»“æŸã€‚ä½¿ç”¨
 `æ ·æœ¬`
 è·å–æ¨¡å‹è¾“å‡ºçš„æ–¹æ³•ï¼š



```
>>> with torch.no_grad():
...     noisy_residual = model(sample=noisy_sample, timestep=2).sample
```


ä¸è¿‡ï¼Œè¦ç”Ÿæˆå®é™…ç¤ºä¾‹ï¼Œæ‚¨éœ€è¦ä¸€ä¸ªè°ƒåº¦ç¨‹åºæ¥æŒ‡å¯¼å»å™ªè¿‡ç¨‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•å°†æ¨¡å‹ä¸è°ƒåº¦ç¨‹åºç»“åˆèµ·æ¥ã€‚


## è°ƒåº¦ç¨‹åº



ç»™å®šæ¨¡å‹è¾“å‡ºï¼Œè°ƒåº¦ç¨‹åºç®¡ç†ä»å™ªå£°æ ·æœ¬åˆ°å™ªå£°è¾ƒå°çš„æ ·æœ¬ - åœ¨æœ¬ä¾‹ä¸­ï¼Œå®ƒæ˜¯
 `å˜ˆæ‚çš„æ®‹å·®`
 ã€‚


ğŸ§¨ Diffusers æ˜¯ç”¨äºæ„å»ºæ‰©æ•£ç³»ç»Ÿçš„å·¥å…·ç®±ã€‚è™½ç„¶
 [DiffusionPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 æ˜¯å¼€å§‹ä½¿ç”¨é¢„æ„å»ºæ‰©æ•£ç³»ç»Ÿçš„ä¾¿æ·æ–¹æ³•ï¼Œæ‚¨è¿˜å¯ä»¥å•ç‹¬é€‰æ‹©è‡ªå·±çš„æ¨¡å‹å’Œè°ƒåº¦ç¨‹åºç»„ä»¶æ¥æ„å»ºè‡ªå®šä¹‰æ‰©æ•£ç³»ç»Ÿã€‚


å¯¹äºå¿«é€Ÿæµè§ˆï¼Œæ‚¨å°†å®ä¾‹åŒ–
 [DDPMScheduler](/docs/diffusers/v0.23.1/en/api/schedulers/ddpm#diffusers.DDPMScheduler)
 ä»¥å…¶
 [from\_config()](/docs/diffusers/v0.23.1/en/api/configuration#diffusers.ConfigMixin.from_config)
 æ–¹æ³•ï¼š



```
>>> from diffusers import DDPMScheduler

>>> scheduler = DDPMScheduler.from_pretrained(repo_id)
>>> scheduler
DDPMScheduler {
  "\_class\_name": "DDPMScheduler",
  "\_diffusers\_version": "0.21.4",
  "beta\_end": 0.02,
  "beta\_schedule": "linear",
  "beta\_start": 0.0001,
  "clip\_sample": true,
  "clip\_sample\_range": 1.0,
  "dynamic\_thresholding\_ratio": 0.995,
  "num\_train\_timesteps": 1000,
  "prediction\_type": "epsilon",
  "sample\_max\_value": 1.0,
  "steps\_offset": 0,
  "thresholding": false,
  "timestep\_spacing": "leading",
  "trained\_betas": null,
  "variance\_type": "fixed\_small"
}
```


ğŸ’¡ ä¸æ¨¡å‹ä¸åŒï¼Œè°ƒåº¦ç¨‹åºæ²¡æœ‰å¯è®­ç»ƒçš„æƒé‡å¹¶ä¸”æ˜¯æ— å‚æ•°çš„ï¼


ä¸€äº›æœ€é‡è¦çš„å‚æ•°æ˜¯ï¼š


* `num_train_timesteps`
 ï¼šå»å™ªè¿‡ç¨‹çš„é•¿åº¦ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œå°†éšæœºé«˜æ–¯å™ªå£°å¤„ç†ä¸ºæ•°æ®æ ·æœ¬æ‰€éœ€çš„æ—¶é—´æ­¥æ•°ã€‚
* `beta_schedule`
 ï¼šç”¨äºæ¨ç†å’Œè®­ç»ƒçš„å™ªå£°è®¡åˆ’ç±»å‹ã€‚
* `æµ‹è¯•ç‰ˆå¼€å§‹`
 å’Œ
 `æµ‹è¯•ç‰ˆç»“æŸ`
 ï¼šå™ªå£°è¡¨çš„å¼€å§‹å’Œç»“æŸå™ªå£°å€¼ã€‚


è¦é¢„æµ‹å™ªå£°ç¨ä½çš„å›¾åƒï¼Œè¯·å°†ä»¥ä¸‹å†…å®¹ä¼ é€’ç»™è°ƒåº¦ç¨‹åº
 [step()](/docs/diffusers/v0.23.1/en/api/schedulers/ddpm#diffusers.DDPMScheduler.step)
 æ–¹æ³•ï¼šæ¨¡å‹è¾“å‡ºï¼Œ
 `æ—¶é—´æ­¥é•¿`
 ï¼Œå’Œå½“å‰çš„
 `æ ·æœ¬`
 ã€‚



```
>>> less_noisy_sample = scheduler.step(model_output=noisy_residual, timestep=2, sample=noisy_sample).prev_sample
>>> less_noisy_sample.shape
torch.Size([1, 3, 256, 256])
```


è¿™
 `less_noisy_sample`
 å¯ä»¥ä¼ é€’ç»™ä¸‹ä¸€ä¸ª
 `æ—¶é—´æ­¥é•¿`
 é‚£é‡Œçš„å™ªéŸ³ä¼šæ›´å°ï¼ç°åœ¨è®©æˆ‘ä»¬å°†å®ƒä»¬æ”¾åœ¨ä¸€èµ·å¹¶å¯è§†åŒ–æ•´ä¸ªå»å™ªè¿‡ç¨‹ã€‚


é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œå¯¹å»å™ªå›¾åƒè¿›è¡Œåå¤„ç†å¹¶å°†å…¶æ˜¾ç¤ºä¸º
 `PIL.Image`
 :



```
>>> import PIL.Image
>>> import numpy as np


>>> def display\_sample(sample, i):
...     image_processed = sample.cpu().permute(0, 2, 3, 1)
...     image_processed = (image_processed + 1.0) * 127.5
...     image_processed = image_processed.numpy().astype(np.uint8)

...     image_pil = PIL.Image.fromarray(image_processed[0])
...     display(f"Image at step {i}")
...     display(image_pil)
```


ä¸ºäº†åŠ é€Ÿå»å™ªè¿‡ç¨‹ï¼Œè¯·å°†è¾“å…¥å’Œæ¨¡å‹ç§»è‡³ GPUï¼š



```
>>> model.to("cuda")
>>> noisy_sample = noisy_sample.to("cuda")
```


ç°åœ¨åˆ›å»ºä¸€ä¸ªå»å™ªå¾ªç¯æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ ·æœ¬çš„æ®‹å·®ï¼Œå¹¶ä½¿ç”¨è°ƒåº¦ç¨‹åºè®¡ç®—å™ªå£°è¾ƒå°çš„æ ·æœ¬ï¼š



```
>>> import tqdm

>>> sample = noisy_sample

>>> for i, t in enumerate(tqdm.tqdm(scheduler.timesteps)):
...     # 1. predict noise residual
...     with torch.no_grad():
...         residual = model(sample, t).sample

...     # 2. compute less noisy image and set x\_t -> x\_t-1
...     sample = scheduler.step(residual, t, sample).prev_sample

...     # 3. optionally look at image
...     if (i + 1) % 50 == 0:
...         display_sample(sample, i + 1)
```


åä¸‹æ¥çœ‹çœ‹çŒ«æ˜¯ä»å™ªéŸ³ä¸­è¯ç”Ÿçš„ï¼ ğŸ˜»


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/diffusion-quicktour.png)


## ä¸‹ä¸€æ­¥



å¸Œæœ›æ‚¨åœ¨æœ¬å¿«é€Ÿæ•™ç¨‹ä¸­ä½¿ç”¨ ğŸ§¨ æ‰©æ•£å™¨ç”Ÿæˆäº†ä¸€äº›å¾ˆé…·çš„å›¾åƒï¼å¯¹äºåç»­æ­¥éª¤ï¼Œæ‚¨å¯ä»¥ï¼š


* è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ä»¥ç”Ÿæˆæ‚¨è‡ªå·±çš„å›¾åƒ
 [åŸ¹è®­](./tutorials/basic_training)
 æ•™ç¨‹ã€‚
* ç¤ºä¾‹å‚è§å®˜æ–¹å’Œç¤¾åŒº
 [è®­ç»ƒæˆ–å¾®è°ƒè„šæœ¬](https://github.com/huggingface/diffusers/tree/main/examples#-diffusers-examples)
 é€‚ç”¨äºå„ç§ç”¨ä¾‹ã€‚
* äº†è§£æœ‰å…³åŠ è½½ã€è®¿é—®ã€æ›´æ”¹å’Œæ¯”è¾ƒè°ƒåº¦ç¨‹åºçš„æ›´å¤šä¿¡æ¯
 [ä½¿ç”¨ä¸åŒçš„è°ƒåº¦ç¨‹åº](./using-diffusers/schedulers)
 æŒ‡å¯¼ã€‚
* æ¢ç´¢å³æ—¶å·¥ç¨‹ã€é€Ÿåº¦å’Œå†…å­˜ä¼˜åŒ–ï¼Œä»¥åŠä½¿ç”¨ç”Ÿæˆæ›´é«˜è´¨é‡å›¾åƒçš„æç¤ºå’ŒæŠ€å·§
 [ç¨³å®šæ‰©æ•£](./stable_diffusion)
 æŒ‡å¯¼ã€‚
* æ·±å…¥äº†è§£åŠ é€Ÿ ğŸ§¨ æ‰©æ•£å™¨å¹¶å¼€å¯æŒ‡å—
 [GPU ä¸Šä¼˜åŒ–çš„ PyTorch](./optimization/fp16)
 ï¼Œä»¥åŠè¿è¡Œçš„æ¨ç†æŒ‡å—
 [Apple Silicon ä¸Šçš„ç¨³å®šæ‰©æ•£ (M1/M2)](./optimization/mps)
 å’Œ
 [ONNX è¿è¡Œæ—¶](./optimization/onnx)
 ã€‚