# Schedulers

> ËØëËÄÖÔºö[ÁâáÂàªÂ∞èÂì•Âì•](https://github.com/jiangzhonglian)
>
> È°πÁõÆÂú∞ÂùÄÔºö<https://huggingface.apachecn.org/docs/diffusers/api/schedulers/overview>
>
> ÂéüÂßãÂú∞ÂùÄÔºö<https://huggingface.co/docs/diffusers/api/schedulers/overview>



 ü§ó Diffusers provides many scheduler functions for the diffusion process. A scheduler takes a model‚Äôs output (the sample which the diffusion process is iterating on) and a timestep to return a denoised sample. The timestep is important because it dictates where in the diffusion process the step is; data is generated by iterating forward
 *n* 
 timesteps and inference occurs by propagating backward through the timesteps. Based on the timestep, a scheduler may be
 *discrete* 
 in which case the timestep is an
 `int` 
 or
 *continuous* 
 in which case the timestep is a
 `float` 
.
 



 Depending on the context, a scheduler defines how to iteratively add noise to an image or how to update a sample based on a model‚Äôs output:
 


* during
 *training* 
 , a scheduler adds noise (there are different algorithms for how to add noise) to a sample to train a diffusion model
* during
 *inference* 
 , a scheduler defines how to update a sample based on a pretrained model‚Äôs output



 Many schedulers are implemented from the
 [k-diffusion](https://github.com/crowsonkb/k-diffusion) 
 library by
 [Katherine Crowson](https://github.com/crowsonkb/) 
 , and they‚Äôre also widely used in A1111. To help you map the schedulers from k-diffusion and A1111 to the schedulers in ü§ó Diffusers, take a look at the table below:
 


| 	 A1111/k-diffusion	  | 	 ü§ó Diffusers	  | 	 Usage	  |
| --- | --- | --- |
| 	 DPM++ 2M	  | [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)  |  |
| 	 DPM++ 2M Karras	  | [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)  | 	 init with	 `use_karras_sigmas=True`  |
| 	 DPM++ 2M SDE	  | [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)  | 	 init with	 `algorithm_type="sde-dpmsolver++"`  |
| 	 DPM++ 2M SDE Karras	  | [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)  | 	 init with	 `use_karras_sigmas=True` 	 and	 `algorithm_type="sde-dpmsolver++"`  |
| 	 DPM++ 2S a	  | 	 N/A	  | 	 very similar to	 `DPMSolverSinglestepScheduler`  |
| 	 DPM++ 2S a Karras	  | 	 N/A	  | 	 very similar to	 `DPMSolverSinglestepScheduler(use_karras_sigmas=True,...)`  |
| 	 DPM++ SDE	  | [DPMSolverSinglestepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/singlestep_dpm_solver#diffusers.DPMSolverSinglestepScheduler)  |  |
| 	 DPM++ SDE Karras	  | [DPMSolverSinglestepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/singlestep_dpm_solver#diffusers.DPMSolverSinglestepScheduler)  | 	 init with	 `use_karras_sigmas=True`  |
| 	 DPM2	  | [KDPM2DiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete#diffusers.KDPM2DiscreteScheduler)  |  |
| 	 DPM2 Karras	  | [KDPM2DiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete#diffusers.KDPM2DiscreteScheduler)  | 	 init with	 `use_karras_sigmas=True`  |
| 	 DPM2 a	  | [KDPM2AncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete_ancestral#diffusers.KDPM2AncestralDiscreteScheduler)  |  |
| 	 DPM2 a Karras	  | [KDPM2AncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete_ancestral#diffusers.KDPM2AncestralDiscreteScheduler)  | 	 init with	 `use_karras_sigmas=True`  |
| 	 DPM adaptive	  | 	 N/A	  |  |
| 	 DPM fast	  | 	 N/A	  |  |
| 	 Euler	  | [EulerDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)  |  |
| 	 Euler a	  | [EulerAncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler_ancestral#diffusers.EulerAncestralDiscreteScheduler)  |  |
| 	 Heun	  | [HeunDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler)  |  |
| 	 LMS	  | [LMSDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)  |  |
| 	 LMS Karras	  | [LMSDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)  | 	 init with	 `use_karras_sigmas=True`  |
| 	 N/A	  | [DEISMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/deis#diffusers.DEISMultistepScheduler)  |  |
| 	 N/A	  | [UniPCMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/unipc#diffusers.UniPCMultistepScheduler)  |  |



 All schedulers are built from the base
 [SchedulerMixin](/docs/diffusers/v0.23.0/en/api/schedulers/overview#diffusers.SchedulerMixin) 
 class which implements low level utilities shared by all schedulers.
 


## SchedulerMixin




### 




 class
 

 diffusers.
 

 SchedulerMixin




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/schedulers/scheduling_utils.py#L63)



 (
 

 )
 




 Base class for all schedulers.
 



[SchedulerMixin](/docs/diffusers/v0.23.0/en/api/schedulers/overview#diffusers.SchedulerMixin) 
 contains common functions shared by all schedulers such as general loading and saving
functionalities.
 



[ConfigMixin](/docs/diffusers/v0.23.0/en/api/configuration#diffusers.ConfigMixin) 
 takes care of storing the configuration attributes (like
 `num_train_timesteps` 
 ) that are passed to
the scheduler‚Äôs
 `__init__` 
 function, and the attributes can be accessed by
 `scheduler.config.num_train_timesteps` 
.
 



 Class attributes:
 


* **\_compatibles** 
 (
 `List[str]` 
 ) ‚Äî A list of scheduler classes that are compatible with the parent scheduler
class. Use
 [from\_config()](/docs/diffusers/v0.23.0/en/api/configuration#diffusers.ConfigMixin.from_config) 
 to load a different compatible scheduler class (should be overridden
by parent class).



#### 




 from\_pretrained




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/schedulers/scheduling_utils.py#L83)



 (
 


 pretrained\_model\_name\_or\_path
 
 : typing.Union[str, os.PathLike, NoneType] = None
 




 subfolder
 
 : typing.Optional[str] = None
 




 return\_unused\_kwargs
 
 = False
 




 \*\*kwargs
 




 )
 


 Parameters
 




* **pretrained\_model\_name\_or\_path** 
 (
 `str` 
 or
 `os.PathLike` 
 ,
 *optional* 
 ) ‚Äî
Can be either:
 
	+ A string, the
	 *model id* 
	 (for example
	 `google/ddpm-celebahq-256` 
	 ) of a pretrained model hosted on
	the Hub.
	+ A path to a
	 *directory* 
	 (for example
	 `./my_model_directory` 
	 ) containing the scheduler
	configuration saved with
	 [save\_pretrained()](/docs/diffusers/v0.23.0/en/api/schedulers/overview#diffusers.SchedulerMixin.save_pretrained) 
	.
* **subfolder** 
 (
 `str` 
 ,
 *optional* 
 ) ‚Äî
The subfolder location of a model file within a larger model repository on the Hub or locally.
* **return\_unused\_kwargs** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether kwargs that are not consumed by the Python class should be returned or not.
* **cache\_dir** 
 (
 `Union[str, os.PathLike]` 
 ,
 *optional* 
 ) ‚Äî
Path to a directory where a downloaded pretrained model configuration is cached if the standard cache
is not used.
* **force\_download** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.
* **resume\_download** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether or not to resume downloading the model weights and configuration files. If set to
 `False` 
 , any
incompletely downloaded files are deleted.
* **proxies** 
 (
 `Dict[str, str]` 
 ,
 *optional* 
 ) ‚Äî
A dictionary of proxy servers to use by protocol or endpoint, for example,
 `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}` 
. The proxies are used on each request.
* **output\_loading\_info(
 `bool` 
 ,** 
*optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.
* **local\_files\_only(
 `bool` 
 ,** 
*optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether to only load local model weights and configuration files or not. If set to
 `True` 
 , the model
won‚Äôt be downloaded from the Hub.
* **use\_auth\_token** 
 (
 `str` 
 or
 *bool* 
 ,
 *optional* 
 ) ‚Äî
The token to use as HTTP bearer authorization for remote files. If
 `True` 
 , the token generated from
 `diffusers-cli login` 
 (stored in
 `~/.huggingface` 
 ) is used.
* **revision** 
 (
 `str` 
 ,
 *optional* 
 , defaults to
 `"main"` 
 ) ‚Äî
The specific model version to use. It can be a branch name, a tag name, a commit id, or any identifier
allowed by Git.


 Instantiate a scheduler from a pre-defined JSON configuration file in a local directory or Hub repository.
 




 To use private or
 [gated models](https://huggingface.co/docs/hub/models-gated#gated-models) 
 , log-in with
 `huggingface-cli login` 
. You can also activate the special
 [‚Äúoffline-mode‚Äù](https://huggingface.co/diffusers/installation.html#offline-mode) 
 to use this method in a
firewalled environment.
 


#### 




 save\_pretrained




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/schedulers/scheduling_utils.py#L149)



 (
 


 save\_directory
 
 : typing.Union[str, os.PathLike]
 




 push\_to\_hub
 
 : bool = False
 




 \*\*kwargs
 




 )
 


 Parameters
 




* **save\_directory** 
 (
 `str` 
 or
 `os.PathLike` 
 ) ‚Äî
Directory where the configuration JSON file will be saved (will be created if it does not exist).
* **push\_to\_hub** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether or not to push your model to the Hugging Face Hub after saving it. You can specify the
repository you want to push to with
 `repo_id` 
 (will default to the name of
 `save_directory` 
 in your
namespace).
* **kwargs** 
 (
 `Dict[str, Any]` 
 ,
 *optional* 
 ) ‚Äî
Additional keyword arguments passed along to the
 [push\_to\_hub()](/docs/diffusers/v0.23.0/en/api/pipelines/overview#diffusers.utils.PushToHubMixin.push_to_hub) 
 method.


 Save a scheduler configuration object to a directory so that it can be reloaded using the
 [from\_pretrained()](/docs/diffusers/v0.23.0/en/api/schedulers/overview#diffusers.SchedulerMixin.from_pretrained) 
 class method.
 


## SchedulerOutput




### 




 class
 

 diffusers.schedulers.scheduling\_utils.
 

 SchedulerOutput




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/schedulers/scheduling_utils.py#L50)



 (
 


 prev\_sample
 
 : FloatTensor
 



 )
 


 Parameters
 




* **prev\_sample** 
 (
 `torch.FloatTensor` 
 of shape
 `(batch_size, num_channels, height, width)` 
 for images) ‚Äî
Computed sample
 `(x_{t-1})` 
 of previous timestep.
 `prev_sample` 
 should be used as next model input in the
denoising loop.


 Base class for the output of a scheduler‚Äôs
 `step` 
 function.
 


## KarrasDiffusionSchedulers




`KarrasDiffusionSchedulers` 
 are a broad generalization of schedulers in ü§ó Diffusers. The schedulers in this class are distinguished at a high level by their noise sampling strategy, the type of network and scaling, the training strategy, and how the loss is weighed.
 



 The different schedulers in this class, depending on the ordinary differential equations (ODE) solver type, fall into the above taxonomy and provide a good abstraction for the design of the main schedulers implemented in ü§ó Diffusers. The schedulers in this class are given
 [here](https://github.com/huggingface/diffusers/blob/a69754bb879ed55b9b6dc9dd0b3cf4fa4124c765/src/diffusers/schedulers/scheduling_utils.py#L32) 
.
 


## PushToHubMixin




### 




 class
 

 diffusers.utils.
 

 PushToHubMixin




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/utils/hub_utils.py#L373)



 (
 

 )
 




 A Mixin to push a model, scheduler, or pipeline to the Hugging Face Hub.
 



#### 




 push\_to\_hub




[<
 

 source
 

 >](https://github.com/huggingface/diffusers/blob/v0.23.0/src/diffusers/utils/hub_utils.py#L402)



 (
 


 repo\_id
 
 : str
 




 commit\_message
 
 : typing.Optional[str] = None
 




 private
 
 : typing.Optional[bool] = None
 




 token
 
 : typing.Optional[str] = None
 




 create\_pr
 
 : bool = False
 




 safe\_serialization
 
 : bool = True
 




 variant
 
 : typing.Optional[str] = None
 



 )
 


 Parameters
 




* **repo\_id** 
 (
 `str` 
 ) ‚Äî
The name of the repository you want to push your model, scheduler, or pipeline files to. It should
contain your organization name when pushing to an organization.
 `repo_id` 
 can also be a path to a local
directory.
* **commit\_message** 
 (
 `str` 
 ,
 *optional* 
 ) ‚Äî
Message to commit while pushing. Default to
 `"Upload {object}"` 
.
* **private** 
 (
 `bool` 
 ,
 *optional* 
 ) ‚Äî
Whether or not the repository created should be private.
* **token** 
 (
 `str` 
 ,
 *optional* 
 ) ‚Äî
The token to use as HTTP bearer authorization for remote files. The token generated when running
 `huggingface-cli login` 
 (stored in
 `~/.huggingface` 
 ).
* **create\_pr** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `False` 
 ) ‚Äî
Whether or not to create a PR with the uploaded files or directly commit.
* **safe\_serialization** 
 (
 `bool` 
 ,
 *optional* 
 , defaults to
 `True` 
 ) ‚Äî
Whether or not to convert the model weights to the
 `safetensors` 
 format.
* **variant** 
 (
 `str` 
 ,
 *optional* 
 ) ‚Äî
If specified, weights are saved in the format
 `pytorch_model.<variant>.bin` 
.


 Upload model, scheduler, or pipeline files to the ü§ó Hugging Face Hub.
 


 Examples:
 



```
from diffusers import UNet2DConditionModel

unet = UNet2DConditionModel.from_pretrained("stabilityai/stable-diffusion-2", subfolder="unet")

# Push the `unet` to your namespace with the name "my-finetuned-unet".
unet.push_to_hub("my-finetuned-unet")

# Push the `unet` to an organization with the name "my-finetuned-unet".
unet.push_to_hub("your-org/my-finetuned-unet")
```