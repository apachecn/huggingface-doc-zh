# æ§åˆ¶ç½‘

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/controlnet>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/controlnet>


[å‘æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ·»åŠ æ¡ä»¶æ§åˆ¶](https://arxiv.org/abs/2302.05543)
 (ControlNet) ä½œè€…ï¼šLvmin å¼ å’Œ Maneesh Agrawalaã€‚


è¿™ä¸ªä¾‹å­æ˜¯åŸºäº
 [åŸå§‹ ControlNet å­˜å‚¨åº“ä¸­çš„è®­ç»ƒç¤ºä¾‹](https://github.com/lllyasviel/ControlNet/blob/main/docs/train.md)
 ã€‚å®ƒä½¿ç”¨ä»¥ä¸‹æ–¹æ³•è®­ç»ƒ ControlNet æ¥å¡«å……åœ†åœˆ
 [å°å‹åˆæˆæ•°æ®é›†](https://huggingface.co/datasets/fusing/fill50k)
 ã€‚


## å®‰è£…ä¾èµ–é¡¹



åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ã€‚


è¦æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®
 **ä»æºå®‰è£…**
 å¹¶ä½¿å®‰è£…ä¿æŒæœ€æ–°ã€‚æˆ‘ä»¬ç»å¸¸æ›´æ–°ç¤ºä¾‹è„šæœ¬å¹¶å®‰è£…ç‰¹å®šäºç¤ºä¾‹çš„è¦æ±‚ã€‚


ä¸ºæ­¤ï¼Œè¯·åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š



```
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```


ç„¶åå¯¼èˆªåˆ°
 [ç¤ºä¾‹æ–‡ä»¶å¤¹](https://github.com/huggingface/diffusers/tree/main/examples/controlnet)



```
cd examples/controlnet
```


ç°åœ¨è¿è¡Œï¼š



```
pip install -r requirements.txt
```


å¹¶åˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤—åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


æˆ–è€…å¯¹äºé»˜è®¤çš„ğŸ¤—åŠ é€Ÿé…ç½®è€Œä¸å›ç­”æœ‰å…³æ‚¨çš„ç¯å¢ƒçš„é—®é¢˜ï¼š



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒç¬”è®°æœ¬ç­‰äº¤äº’å¼ shellï¼š



```
from accelerate.utils import write_basic_config

write_basic_config()
```


## åœ†å½¢å¡«å……æ•°æ®é›†



åŸå§‹æ•°æ®é›†æ‰˜ç®¡åœ¨ ControlNet ä¸­
 [å›è´­](https://huggingface.co/lllyasviel/ControlNet/blob/main/training/fill50k.zip)
 ï¼Œä½†æˆ‘ä»¬é‡æ–°ä¸Šä¼ äº†å®ƒ
 [æ­¤å¤„](https://huggingface.co/datasets/fusing/fill50k)
 ä¸ğŸ¤—æ•°æ®é›†å…¼å®¹ï¼Œä»¥ä¾¿å®ƒå¯ä»¥å¤„ç†è®­ç»ƒè„šæœ¬ä¸­çš„æ•°æ®åŠ è½½ã€‚


æˆ‘ä»¬çš„è®­ç»ƒç¤ºä¾‹ä½¿ç”¨
 [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 å› ä¸ºè¿™å°±æ˜¯åŸå§‹ ControlNet æ¨¡å‹é›†çš„è®­ç»ƒå†…å®¹ã€‚ç„¶è€Œï¼ŒControlNet å¯ä»¥ç»è¿‡è®­ç»ƒæ¥å¢å¼ºä»»ä½•å…¼å®¹çš„ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼ˆä¾‹å¦‚
 [`CompVis/stable-diffusion-v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4)
 ï¼‰ æˆ–è€…
 [`stabilityai/stable-diffusion-2-1`](https://huggingface.co/stabilityai/stable-diffusion-2-1)
 ã€‚


è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


## è®­ç»ƒ



ä¸‹è½½ä»¥ä¸‹å›¾åƒæ¥è°ƒèŠ‚æˆ‘ä»¬çš„è®­ç»ƒï¼š



```
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png

wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png
```


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚


è®­ç»ƒè„šæœ¬åˆ›å»ºå¹¶ä¿å­˜
 `diffusion_pytorch_model.bin`
 æ–‡ä»¶åœ¨æ‚¨çš„å­˜å‚¨åº“ä¸­ã€‚



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --learning_rate=1e-5  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=4  --push_to_hub
```


æ­¤é»˜è®¤é…ç½®éœ€è¦ ~38GB VRAMã€‚


é»˜è®¤æƒ…å†µä¸‹ï¼Œè®­ç»ƒè„šæœ¬å°†è¾“å‡ºè®°å½•åˆ°å¼ é‡æ¿ã€‚ç»è¿‡
 `--report_to wandb`
 ä½¿ç”¨æƒé‡ &
åè§ã€‚


å…·æœ‰è¾ƒå°æ‰¹é‡å¤§å°çš„æ¢¯åº¦ç´¯ç§¯å¯ç”¨äºå°†è®­ç»ƒè¦æ±‚é™ä½è‡³çº¦ 20 GB VRAMã€‚



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --learning_rate=1e-5  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=1  --gradient_accumulation_steps=4   --push_to_hub
```


## ä½¿ç”¨å¤šä¸ª GPU è¿›è¡Œè®­ç»ƒ



â€˜åŠ é€Ÿâ€™
 å…è®¸æ— ç¼çš„å¤š GPU è®­ç»ƒã€‚æŒ‰ç…§è¯´æ˜æ“ä½œ
 [æ­¤å¤„](https://huggingface.co/docs/accelerate/basic_tutorials/launch)
 ç”¨äºè¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
 â€˜åŠ é€Ÿâ€™
 ã€‚è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å‘½ä»¤ï¼š



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch --mixed_precision="fp16" --multi_gpu train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --learning_rate=1e-5  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=4  --mixed_precision="fp16"  --tracker_project_name="controlnet-demo"  --report_to=wandb   --push_to_hub
```


## ç»“æœç¤ºä¾‹



#### 


 æ‰¹é‡å¤§å°ä¸º 8 çš„ 300 ä¸ªæ­¥éª¤å


|  |  |
| --- | --- |
|  | 	 red circle with blue background	  |
| conditioning image | red circle with blue background |
|  | 	 cyan circle with brown floral background	  |
| conditioning image | cyan circle with brown floral background |


#### 


 æ‰¹é‡å¤§å°ä¸º 8 çš„ 6000 æ­¥åï¼š


|  |  |
| --- | --- |
|  | 	 red circle with blue background	  |
| conditioning image | red circle with blue background |
|  | 	 cyan circle with brown floral background	  |
| conditioning image | cyan circle with brown floral background |


## åœ¨ 16 GB GPU ä¸Šè®­ç»ƒ



å¯ç”¨ä»¥ä¸‹ä¼˜åŒ–ä»¥åœ¨ 16GB GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼š


* æ¢¯åº¦æ£€æŸ¥ç‚¹
* bitsandbyte çš„ 8 ä½ä¼˜åŒ–å™¨ï¼ˆçœ‹ä¸€ä¸‹[å®‰è£…]((
 [https://github.com/TimDettmers/bitsandbytes#requirementsâ€”å®‰è£…](https://github.com/TimDettmers/bitsandbytes#requirements--installation)
 ï¼‰è¯´æ˜ï¼ˆå¦‚æœæ‚¨å°šæœªå®‰è£…ï¼‰


ç°åœ¨æ‚¨å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼š



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --learning_rate=1e-5  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=1  --gradient_accumulation_steps=4  --gradient_checkpointing  --use_8bit_adam   --push_to_hub
```


## åœ¨ 12 GB GPU ä¸Šè®­ç»ƒ



å¯ç”¨ä»¥ä¸‹ä¼˜åŒ–ä»¥åœ¨ 12GB GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼š


* æ¢¯åº¦æ£€æŸ¥ç‚¹
* bitsandbyte çš„ 8 ä½ä¼˜åŒ–å™¨ï¼ˆçœ‹ä¸€ä¸‹[å®‰è£…]((
 [https://github.com/TimDettmers/bitsandbytes#requirementsâ€”å®‰è£…](https://github.com/TimDettmers/bitsandbytes#requirements--installation)
 ï¼‰è¯´æ˜ï¼ˆå¦‚æœæ‚¨å°šæœªå®‰è£…ï¼‰
* xFormersï¼ˆçœ‹çœ‹
 [å®‰è£…](https://huggingface.co/docs/diffusers/training/optimization/xformers)
 å¦‚æœæ‚¨å°šæœªå®‰è£…ï¼Œè¯·å‚é˜…è¯´æ˜ï¼‰
* è®¾ç½®æ¸å˜ä¸º
 `æ— `



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --learning_rate=1e-5  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=1  --gradient_accumulation_steps=4  --gradient_checkpointing  --use_8bit_adam  --enable_xformers_memory_efficient_attention  --set_grads_to_none   --push_to_hub
```


ä½¿ç”¨æ—¶
 `enable_xformers_memory_efficient_attention`
 ï¼Œè¯·ç¡®ä¿å®‰è£…
 `xformers`
 ç»è¿‡
 `pip å®‰è£… xformers`
 ã€‚


## åœ¨ 8 GB GPU ä¸Šè®­ç»ƒ



æˆ‘ä»¬å°šæœªè¯¦å°½æµ‹è¯• DeepSpeed å¯¹ ControlNet çš„æ”¯æŒã€‚è™½ç„¶é…ç½®ç¡®å®
èŠ‚çœå†…å­˜ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰ç¡®è®¤é…ç½®è®­ç»ƒæ˜¯å¦æˆåŠŸã€‚ä½ å¾ˆå¯èƒ½ä¼š
å¿…é¡»æ›´æ”¹é…ç½®æ‰èƒ½æˆåŠŸè¿è¡Œè®­ç»ƒã€‚


å¯ç”¨ä»¥ä¸‹ä¼˜åŒ–ä»¥åœ¨ 8GB GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼š


* æ¢¯åº¦æ£€æŸ¥ç‚¹
* bitsandbyte çš„ 8 ä½ä¼˜åŒ–å™¨ï¼ˆçœ‹ä¸€ä¸‹[å®‰è£…]((
 [https://github.com/TimDettmers/bitsandbytes#requirementsâ€”å®‰è£…](https://github.com/TimDettmers/bitsandbytes#requirements--installation)
 ï¼‰è¯´æ˜ï¼ˆå¦‚æœæ‚¨å°šæœªå®‰è£…ï¼‰
* xFormersï¼ˆçœ‹çœ‹
 [å®‰è£…](https://huggingface.co/docs/diffusers/training/optimization/xformers)
 å¦‚æœæ‚¨å°šæœªå®‰è£…ï¼Œè¯·å‚é˜…è¯´æ˜ï¼‰
* è®¾ç½®æ¸å˜ä¸º
 `æ— `
* DeepSpeed ç¬¬ 2 é˜¶æ®µï¼Œå…·æœ‰å‚æ•°å’Œä¼˜åŒ–å™¨å¸è½½åŠŸèƒ½
* fp16æ··åˆç²¾åº¦


[DeepSpeed](https://www.deepspeed.ai/)
 å¯ä»¥å°†å¼ é‡ä» VRAM å¸è½½åˆ°
CPU æˆ– NVMEã€‚è¿™éœ€è¦æ›´å¤šçš„ RAMï¼ˆå¤§çº¦ 25 GBï¼‰ã€‚


æ‚¨å¿…é¡»é…ç½®æ‚¨çš„ç¯å¢ƒ
 `åŠ é€Ÿé…ç½®`
 å¯ç”¨ DeepSpeed ç¬¬ 2 é˜¶æ®µã€‚


é…ç½®æ–‡ä»¶åº”å¦‚ä¸‹æ‰€ç¤ºï¼š



```
compute\_environment: LOCAL\_MACHINE
deepspeed\_config:
  gradient\_accumulation\_steps: 4
  offload\_optimizer\_device: cpu
  offload\_param\_device: cpu
  zero3\_init\_flag: false
  zero\_stage: 2
distributed\_type: DEEPSPEED
```


çœ‹
 [æ–‡æ¡£](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)
 äº†è§£æ›´å¤š DeepSpeed é…ç½®é€‰é¡¹ã€‚


å°†é»˜è®¤ Adam ä¼˜åŒ–å™¨æ›´æ”¹ä¸º DeepSpeed çš„ Adam
 `deepspeed.ops.adam.DeepSpeedCPUAdam`
 ç»™å‡ºäº†æ˜¾ç€çš„åŠ é€Ÿä½†æ˜¯
å®ƒéœ€è¦ä¸ PyTorch ç‰ˆæœ¬ç›¸åŒçš„ CUDA å·¥å…·é“¾ã€‚ 8ä½ä¼˜åŒ–å™¨
ç›®å‰ä¼¼ä¹ä¸ DeepSpeed ä¸å…¼å®¹ã€‚



```
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path to save model"

accelerate launch train_controlnet.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --resolution=512  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --train_batch_size=1  --gradient_accumulation_steps=4  --gradient_checkpointing  --enable_xformers_memory_efficient_attention  --set_grads_to_none  --mixed_precision fp16  --push_to_hub
```


## æ¨ç†



ç»è¿‡è®­ç»ƒçš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œ
 [StableDiffusionControlNetPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/controlnet#diffusers.StableDiffusionControlNetPipeline)
 ã€‚
æ”¾
 `åŸºæœ¬æ¨¡å‹è·¯å¾„`
 å’Œ
 `æ§åˆ¶ç½‘ç»œè·¯å¾„`
 åˆ°ä»·å€¼è§‚
 `--pretrained_model_name_or_path`
 å’Œ
 `--output_dir`
 åˆ†åˆ«åœ¨è®­ç»ƒè„šæœ¬ä¸­è®¾ç½®ä¸ºã€‚



```
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from diffusers.utils import load_image
import torch

base_model_path = "path to model"
controlnet_path = "path to controlnet"

controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16, use_safetensors=True)
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    base_model_path, controlnet=controlnet, torch_dtype=torch.float16, use_safetensors=True
)

# speed up diffusion process with faster scheduler and memory optimization
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
# remove following line if xformers is not installed
pipe.enable_xformers_memory_efficient_attention()

pipe.enable_model_cpu_offload()

control_image = load_image("./conditioning\_image\_1.png")
prompt = "pale golden rod circle with old lace background"

# generate image
generator = torch.manual_seed(0)
image = pipe(prompt, num_inference_steps=20, generator=generator, image=control_image).images[0]

image.save("./output.png")
```


## ç¨³å®šæ‰©æ•£XL



è®­ç»ƒä¸
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 è¿˜é€šè¿‡ä»¥ä¸‹æ–¹å¼æ”¯æŒ
 `train_controlnet_sdxl.py`
 è„šæœ¬ã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sdxl.md)
 ã€‚