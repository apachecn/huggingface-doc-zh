# æ–‡æœ¬è½¬å›¾åƒ

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/text2image>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/text2image>


æ–‡æœ¬åˆ°å›¾åƒçš„å¾®è°ƒè„šæœ¬æ˜¯å®éªŒæ€§çš„ã€‚å¾ˆå®¹æ˜“è¿‡åº¦é€‚åº”å¹¶é‡åˆ°ç¾éš¾æ€§é—å¿˜ç­‰é—®é¢˜ã€‚æˆ‘ä»¬å»ºè®®æ‚¨æ¢ç´¢ä¸åŒçš„è¶…å‚æ•°ï¼Œä»¥ä¾¿åœ¨æ•°æ®é›†ä¸Šè·å¾—æœ€ä½³ç»“æœã€‚


ç¨³å®šæ‰©æ•£ç­‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒã€‚æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•å¾®è°ƒ
 [`CompVis/stable-diffusion-v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4)
 ä½¿ç”¨ PyTorch å’Œ Flax åœ¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ä¸Šå»ºæ¨¡ã€‚æœ¬æŒ‡å—ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ–‡æœ¬åˆ°å›¾åƒå¾®è°ƒçš„è®­ç»ƒè„šæœ¬éƒ½å¯ä»¥åœ¨æ­¤æ‰¾åˆ°
 [å­˜å‚¨åº“](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image)
 å¦‚æœæ‚¨æœ‰å…´è¶£ä»”ç»†çœ‹çœ‹ã€‚


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š



```
pip install git+https://github.com/huggingface/diffusers.git
pip install -U -r requirements.txt
```


å¹¶åˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤— åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


å¦‚æœæ‚¨å·²ç»å…‹éš†äº†å­˜å‚¨åº“ï¼Œåˆ™æ— éœ€æ‰§è¡Œè¿™äº›æ­¥éª¤ã€‚ç›¸åï¼Œæ‚¨å¯ä»¥å°†æœ¬åœ°ç»“è´¦çš„è·¯å¾„ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ï¼Œå®ƒå°†ä»é‚£é‡ŒåŠ è½½ã€‚


## ç¡¬ä»¶è¦æ±‚



ä½¿ç”¨
 `æ¢¯åº¦æ£€æŸ¥ç‚¹`
 å’Œ
 `æ··åˆç²¾åº¦`
 ï¼Œåº”è¯¥å¯ä»¥åœ¨å•ä¸ª 24GB GPU ä¸Šå¾®è°ƒæ¨¡å‹ã€‚å¯¹äºæ›´é«˜
 `æ‰¹é‡å¤§å°`
 å’Œæ›´å¿«çš„è®­ç»ƒï¼Œæœ€å¥½ä½¿ç”¨å…·æœ‰ 30GB ä»¥ä¸Š GPU å†…å­˜çš„ GPUã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ JAX/Flax åœ¨ TPU æˆ– GPU ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¿™å°†åœ¨åé¢ä»‹ç»
 [ä¸‹](#flax-jax-finetuning)
 ã€‚


é€šè¿‡ä½¿ç”¨ xFormers å¯ç”¨å†…å­˜é«˜æ•ˆå…³æ³¨ï¼Œæ‚¨å¯ä»¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜å ç”¨ã€‚ç¡®ä¿ä½ æœ‰
 [å·²å®‰è£… xFormers](./optimization/xformers)
 å¹¶é€šè¿‡
 `--enable_xformers_memory_efficient_attention`
 æ ‡è®°åˆ°è®­ç»ƒè„šæœ¬ã€‚


xFormers ä¸é€‚ç”¨äº Flaxã€‚


## å°†æ¨¡å‹ä¸Šä¼ åˆ° Hub



é€šè¿‡å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°è®­ç»ƒè„šæœ¬ä¸­ï¼Œå°†æ¨¡å‹å­˜å‚¨åœ¨ Hub ä¸Šï¼š



```
  --push_to_hub
```


## ä¿å­˜å’ŒåŠ è½½æ£€æŸ¥ç‚¹



å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œä»¥é˜²è®­ç»ƒæœŸé—´å‘ç”Ÿä»»ä½•æƒ…å†µã€‚è¦ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè¯·å°†ä»¥ä¸‹å‚æ•°ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ï¼š



```
  --checkpointing_steps=500
```


æ¯ 500 æ­¥ï¼Œå®Œæ•´çš„è®­ç»ƒçŠ¶æ€å°±ä¼šä¿å­˜åœ¨
 `è¾“å‡ºç›®å½•`
 ã€‚æ£€æŸ¥ç‚¹çš„æ ¼å¼ä¸º
 `æ£€æŸ¥ç‚¹-`
 æ¥ä¸‹æ¥æ˜¯åˆ°ç›®å‰ä¸ºæ­¢è®­ç»ƒçš„æ­¥æ•°ã€‚ä¾‹å¦‚ï¼Œ
 `æ£€æŸ¥ç‚¹-1500`
 æ˜¯ 1500 ä¸ªè®­ç»ƒæ­¥éª¤åä¿å­˜çš„æ£€æŸ¥ç‚¹ã€‚


è¦åŠ è½½æ£€æŸ¥ç‚¹ä»¥æ¢å¤è®­ç»ƒï¼Œè¯·ä¼ é€’å‚æ•°
 `--resume_from_checkpoint`
 åˆ°è®­ç»ƒè„šæœ¬å¹¶æŒ‡å®šè¦ä»ä¸­æ¢å¤çš„æ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å‚æ•°ä» 1500 ä¸ªè®­ç»ƒæ­¥éª¤åä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼š



```
  --resume_from_checkpoint="checkpoint-1500"
```


## å¾®è°ƒ



ç«ç‚¬


éšè— Pytorch å†…å®¹


å¯åŠ¨
 [PyTorch è®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py)
 è¿›è¡Œå¾®è°ƒè¿è¡Œ
 [ç¥å¥‡å®è´ BLIP å­—å¹•](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)
 åƒè¿™æ ·çš„æ•°æ®é›†ã€‚


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export dataset_name="lambdalabs/pokemon-blip-captions"

accelerate launch --mixed_precision="fp16"  train_text_to_image.py   --pretrained_model_name_or_path=$MODEL\_NAME   --dataset_name=$dataset\_name   --use_ema   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --gradient_accumulation_steps=4   --gradient_checkpointing   --max_train_steps=15000   --learning_rate=1e-05   --max_grad_norm=1   --lr_scheduler="constant" --lr_warmup_steps=0   --output_dir="sd-pokemon-model"   --push_to_hub
```


è¦å¾®è°ƒæ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æ ¹æ®ğŸ¤—æ‰€éœ€çš„æ ¼å¼å‡†å¤‡æ•°æ®é›†
 [æ•°æ®é›†](https://huggingface.co/docs/datasets/index)
 ã€‚ä½ å¯ä»¥
 [å°†æ•°æ®é›†ä¸Šä¼ åˆ°ä¸­å¿ƒ](https://huggingface.co/docs/datasets/image_dataset#upload-dataset-to-the-hub)
 ï¼Œæˆ–è€…ä½ å¯ä»¥
 [å‡†å¤‡ä¸€ä¸ªåŒ…å«æ–‡ä»¶çš„æœ¬åœ°æ–‡ä»¶å¤¹](https://huggingface.co/docs/datasets/image_dataset#imagefolder)
 ã€‚


å¦‚æœæ‚¨æƒ³ä½¿ç”¨è‡ªå®šä¹‰åŠ è½½é€»è¾‘ï¼Œè¯·ä¿®æ”¹è„šæœ¬ã€‚æˆ‘ä»¬åœ¨ä»£ç ä¸­çš„é€‚å½“ä½ç½®ç•™ä¸‹äº†æŒ‡é’ˆæ¥å¸®åŠ©æ‚¨ã€‚ ğŸ¤— ä¸‹é¢çš„ç¤ºä¾‹è„šæœ¬å±•ç¤ºäº†å¦‚ä½•åœ¨æœ¬åœ°æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒ
 `TRAIN_DIR`
 ä»¥åŠæ¨¡å‹çš„ä¿å­˜ä½ç½®
 `è¾“å‡ºç›®å½•`
 ï¼š



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export TRAIN_DIR="path\_to\_your\_dataset"
export OUTPUT_DIR="path\_to\_save\_model"

accelerate launch train_text_to_image.py   --pretrained_model_name_or_path=$MODEL\_NAME   --train_data_dir=$TRAIN\_DIR   --use_ema   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --gradient_accumulation_steps=4   --gradient_checkpointing   --mixed_precision="fp16"   --max_train_steps=15000   --learning_rate=1e-05   --max_grad_norm=1   --lr_scheduler="constant" 
  --lr_warmup_steps=0   --output_dir=${OUTPUT\_DIR}   --push_to_hub
```


#### 


 ä½¿ç”¨å¤šä¸ª GPU è¿›è¡Œè®­ç»ƒ


â€˜åŠ é€Ÿâ€™
 å…è®¸æ— ç¼çš„å¤š GPU è®­ç»ƒã€‚æŒ‰ç…§è¯´æ˜æ“ä½œ
 [æ­¤å¤„](https://huggingface.co/docs/accelerate/basic_tutorials/launch)
 ç”¨äºè¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
 â€˜åŠ é€Ÿâ€™
 ã€‚è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å‘½ä»¤ï¼š



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export dataset_name="lambdalabs/pokemon-blip-captions"

accelerate launch --mixed_precision="fp16" --multi_gpu  train_text_to_image.py   --pretrained_model_name_or_path=$MODEL\_NAME   --dataset_name=$dataset\_name   --use_ema   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --gradient_accumulation_steps=4   --gradient_checkpointing   --max_train_steps=15000 \ 
  --learning_rate=1e-05   --max_grad_norm=1   --lr_scheduler="constant"   --lr_warmup_steps=0   --output_dir="sd-pokemon-model"   --push_to_hub
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹


å€ŸåŠ© Flaxï¼Œå¯ä»¥åœ¨ TPU å’Œ GPU ä¸Šæ›´å¿«åœ°è®­ç»ƒç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œè¿™è¦å½’åŠŸäº
 [@duongna211](https://github.com/duongna21)
 ã€‚è¿™åœ¨ TPU ç¡¬ä»¶ä¸Šéå¸¸é«˜æ•ˆï¼Œä½†åœ¨ GPU ä¸Šä¹Ÿå¾ˆæœ‰æ•ˆã€‚ Flax è®­ç»ƒè„šæœ¬å°šä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹æˆ–æ¢¯åº¦ç´¯ç§¯ç­‰åŠŸèƒ½ï¼Œå› æ­¤æ‚¨éœ€è¦å…·æœ‰è‡³å°‘ 30GB å†…å­˜çš„ GPU æˆ– TPU v3ã€‚


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…ä»¥ä¸‹è¦æ±‚ï¼š



```
pip install -U -r requirements_flax.txt
```


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚


ç°åœ¨æ‚¨å¯ä»¥å¯åŠ¨
 [Flaxè®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_flax.py)
 åƒè¿™æ ·ï¼š



```
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export dataset_name="lambdalabs/pokemon-blip-captions"

python train_text_to_image_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME   --dataset_name=$dataset\_name   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --max_train_steps=15000   --learning_rate=1e-05   --max_grad_norm=1   --output_dir="sd-pokemon-model"   --push_to_hub
```


è¦å¾®è°ƒæ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æ ¹æ®ğŸ¤—æ‰€éœ€çš„æ ¼å¼å‡†å¤‡æ•°æ®é›†
 [æ•°æ®é›†](https://huggingface.co/docs/datasets/index)
 ã€‚ä½ å¯ä»¥
 [å°†æ•°æ®é›†ä¸Šä¼ åˆ°ä¸­å¿ƒ](https://huggingface.co/docs/datasets/image_dataset#upload-dataset-to-the-hub)
 ï¼Œæˆ–è€…ä½ å¯ä»¥
 [å‡†å¤‡ä¸€ä¸ªåŒ…å«æ–‡ä»¶çš„æœ¬åœ°æ–‡ä»¶å¤¹](https://huggingface.co/docs/datasets/image_dataset#imagefolder)
 ã€‚


å¦‚æœæ‚¨æƒ³ä½¿ç”¨è‡ªå®šä¹‰åŠ è½½é€»è¾‘ï¼Œè¯·ä¿®æ”¹è„šæœ¬ã€‚æˆ‘ä»¬åœ¨ä»£ç ä¸­çš„é€‚å½“ä½ç½®ç•™ä¸‹äº†æŒ‡é’ˆæ¥å¸®åŠ©æ‚¨ã€‚ ğŸ¤— ä¸‹é¢çš„ç¤ºä¾‹è„šæœ¬å±•ç¤ºäº†å¦‚ä½•åœ¨æœ¬åœ°æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒ
 `TRAIN_DIR`
 ï¼š



```
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export TRAIN_DIR="path\_to\_your\_dataset"

python train_text_to_image_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME   --train_data_dir=$TRAIN\_DIR   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --mixed_precision="fp16"   --max_train_steps=15000   --learning_rate=1e-05   --max_grad_norm=1   --output_dir="sd-pokemon-model"   --push_to_hub
```


## ä½¿ç”¨æœ€å° SNR åŠ æƒè¿›è¡Œè®­ç»ƒ



æˆ‘ä»¬æ”¯æŒä½¿ç”¨ Min-SNR åŠ æƒç­–ç•¥è¿›è¡Œè®­ç»ƒ
 [é€šè¿‡æœ€å°SNRåŠ æƒç­–ç•¥è¿›è¡Œé«˜æ•ˆæ‰©æ•£è®­ç»ƒ](https://arxiv.org/abs/2303.09556)
 è¿™æœ‰åŠ©äºå®ç°æ›´å¿«çš„æ”¶æ•›
é€šè¿‡é‡æ–°å¹³è¡¡æŸå¤±ã€‚ä¸ºäº†ä½¿ç”¨å®ƒï¼Œéœ€è¦è®¾ç½®
 `--snr_gamma`
 äº‰è®ºã€‚æ¨èçš„
ä½¿ç”¨æ—¶çš„å€¼ä¸º5.0ã€‚


ä½ å¯ä»¥æ‰¾åˆ°
 [è¿™ä¸ªå…³äºæƒé‡å’Œåå·®çš„é¡¹ç›®](https://wandb.ai/sayakpaul/text2image-finetune-minsnr)
 æ¯”è¾ƒä»¥ä¸‹è®¾ç½®çš„æŸè€—é¢ï¼š


* æ²¡æœ‰Min-SNRåŠ æƒç­–ç•¥çš„è®­ç»ƒ
* ä½¿ç”¨ Min-SNR åŠ æƒç­–ç•¥è¿›è¡Œè®­ç»ƒï¼ˆ
 `snr_gamma`
 è®¾ç½®ä¸º 5.0)
* ä½¿ç”¨ Min-SNR åŠ æƒç­–ç•¥è¿›è¡Œè®­ç»ƒï¼ˆ
 `snr_gamma`
 è®¾ç½®ä¸º 1.0)


å¯¹äºæˆ‘ä»¬çš„å°å‹ Pokemons æ•°æ®é›†ï¼ŒMin-SNR åŠ æƒç­–ç•¥çš„æ•ˆæœå¯èƒ½çœ‹èµ·æ¥å¹¶ä¸æ˜æ˜¾ï¼Œä½†å¯¹äºè¾ƒå¤§çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬ç›¸ä¿¡æ•ˆæœä¼šæ›´åŠ æ˜æ˜¾ã€‚


å¦è¯·æ³¨æ„ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬è¦ä¹ˆé¢„æµ‹
 `epsilon`
 ï¼ˆå³å™ªéŸ³ï¼‰æˆ–
 `v_é¢„æµ‹`
 ã€‚å¯¹äºè¿™ä¸¤ç§æƒ…å†µï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ Min-SNR åŠ æƒç­–ç•¥çš„å…¬å¼éƒ½æˆç«‹ã€‚


ä»… PyTorch æ”¯æŒä½¿ç”¨ Min-SNR åŠ æƒç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚


## æ´›æ‹‰



æ‚¨è¿˜å¯ä»¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ä½ç§©é€‚åº” (LoRA)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåŠ é€Ÿè®­ç»ƒå¤§å‹æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯ï¼Œç”¨äºå¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚æ¬²äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹
 [LoRAè®­ç»ƒ](lora#text-to-image)
 æŒ‡å¯¼ã€‚


## æ¨ç†



ç°åœ¨ï¼Œæ‚¨å¯ä»¥é€šè¿‡å°† Hub ä¸Šçš„æ¨¡å‹è·¯å¾„æˆ–æ¨¡å‹åç§°ä¼ é€’åˆ°
 [StableDiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 ï¼š


ç«ç‚¬


éšè— Pytorch å†…å®¹



```
from diffusers import StableDiffusionPipeline

model_path = "path\_to\_saved\_model"
pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16, use_safetensors=True)
pipe.to("cuda")

image = pipe(prompt="yoda").images[0]
image.save("yoda-pokemon.png")
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹



```
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard
from diffusers import FlaxStableDiffusionPipeline

model_path = "path\_to\_saved\_model"
pipe, params = FlaxStableDiffusionPipeline.from_pretrained(model_path, dtype=jax.numpy.bfloat16)

prompt = "yoda pokemon"
prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 50

num_samples = jax.device_count()
prompt = num_samples * [prompt]
prompt_ids = pipeline.prepare_inputs(prompt)

# shard inputs and rng
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
image.save("yoda-pokemon.png")
```


## ç¨³å®šæ‰©æ•£XL



* æˆ‘ä»¬æ”¯æŒå¯¹å‡ºå‚çš„UNetè¿›è¡Œå¾®è°ƒ
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 é€šè¿‡
 `train_text_to_image_sdxl.py`
 è„šæœ¬ã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/README_sdxl.md)
 ã€‚
* æˆ‘ä»¬è¿˜æ”¯æŒå¯¹ UNet å’Œæ–‡æœ¬ç¼–ç å™¨è¿›è¡Œå¾®è°ƒ
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 é€šè¿‡ LoRA
 `train_text_to_image_lora_sdxl.py`
 è„šæœ¬ã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/README_sdxl.md)
 ã€‚


## åº·å®šæ–¯åŸº2.2



* æˆ‘ä»¬æ”¯æŒå¯¹ Kandinsky2.2 ä¸­çš„è§£ç å™¨å’Œå…ˆéªŒè¿›è¡Œå¾®è°ƒ
 `train_text_to_image_prior.py`
 å’Œ
 `train_text_to_image_decoder.py`
 è„šæœ¬ã€‚è¿˜åŒ…æ‹¬ LoRA æ”¯æŒã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/kandinsky2_2/text_to_image/README_sdxl.md)
 ã€‚