# [](#wuerstchen) Wuerstchen

> è¯‘è€…ï¼šè¯‘è€…ï¼š[ç–¾é£å…”X](https://github.com/jifnegtu)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/wuerstchen>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/wuerstchen>


[Wuerstchen](https://hf.co/papers/2306.00637) æ¨¡å‹é€šè¿‡å°†æ½œåœ¨ç©ºé—´å‹ç¼© 42 å€ï¼Œåœ¨ä¸å½±å“å›¾åƒè´¨é‡å’ŒåŠ é€Ÿæ¨ç†çš„æƒ…å†µä¸‹ï¼Œå¤§å¹…é™ä½äº†è®¡ç®—æˆæœ¬ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒWuerstchen ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹ï¼ˆVQGAN + è‡ªåŠ¨ç¼–ç å™¨ï¼‰æ¥å‹ç¼©æ½œä¼ï¼Œç„¶åç¬¬ä¸‰ä¸ªæ¨¡å‹ï¼ˆæ–‡æœ¬æ¡ä»¶æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰ä»¥è¿™ä¸ªé«˜åº¦å‹ç¼©çš„ç©ºé—´ä¸ºæ¡ä»¶æ¥ç”Ÿæˆå›¾åƒã€‚

è¦å°†å…ˆå‰çš„æ¨¡å‹æ‹Ÿåˆåˆ° GPU å†…å­˜ä¸­å¹¶åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œè¯·å°è¯•åˆ†åˆ«å¯ç”¨`gradient_accumulation_steps` ã€`gradient_checkpointing` å’Œ `mixed_precision`ã€‚

æœ¬æŒ‡å—æ¢è®¨äº† [train\_text\_to\_image\_prior.py](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py) è„šæœ¬ï¼Œä»¥å¸®åŠ©æ‚¨æ›´åŠ ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•æ ¹æ®è‡ªå·±çš„ç”¨ä¾‹è°ƒæ•´å®ƒã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```
ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

```py
cd examples/wuerstchen/text\_to\_image
pip install -r requirements.txt
```
>ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªåº“ï¼Œå¯å¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU ä¸Šæˆ–ä»¥æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚è¯·æŸ¥çœ‹ ğŸ¤— Accelerate [Quick æ•™ç¨‹](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚

åˆå§‹åŒ– ğŸ¤— Accelerate ç¯å¢ƒï¼š

```py
accelerate config
```
è¦åœ¨ä¸é€‰æ‹©ä»»ä½•é…ç½®çš„æƒ…å†µä¸‹è®¾ç½®é»˜è®¤ğŸ¤—çš„ Accelerate ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
accelerate config default
```
æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼ˆå¦‚ç¬”è®°æœ¬ï¼‰ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```
æœ€åï¼Œå¦‚æœè¦åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†ï¼ˆ Create a dataset for training ï¼‰](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

>ä»¥ä¸‹éƒ¨åˆ†é‡ç‚¹ä»‹ç»äº†è®­ç»ƒè„šæœ¬ä¸­å¯¹äºäº†è§£å¦‚ä½•ä¿®æ”¹è®­ç»ƒè„šæœ¬å¾ˆé‡è¦çš„éƒ¨åˆ†ï¼Œä½†å¹¶æœªè¯¦ç»†ä»‹ç»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/train_text_to_image_prior.py)çš„å„ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶é˜…è¯»è„šæœ¬ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ã€‚

## [](#script-parameters)è„šæœ¬å‚æ•°ï¼ˆScript parametersï¼‰

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°æ¥å¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨ [`parse_argsï¼ˆï¼‰`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L192) å‡½æ•°ä¸­æ‰¾åˆ°ã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°æä¾›é»˜è®¤å€¼ï¼Œä¾‹å¦‚è®­ç»ƒæ‰¹æ¬¡å¤§å°å’Œå­¦ä¹ ç‡ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ fp16 æ ¼å¼ä»¥æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒï¼Œè¯·å°†å‚æ•°`--mixed_precision`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```py
accelerate launch train_text_to_image_prior.py \
  --mixed_precision="fp16"
```
å¤§å¤šæ•°å‚æ•°ä¸[æ–‡ç”Ÿå›¾](text2image#script-parameters)è®­ç»ƒæŒ‡å—ä¸­çš„å‚æ•°ç›¸åŒï¼Œå› æ­¤è®©æˆ‘ä»¬ç›´æ¥è¿›å…¥ Wuerstchen è®­ç»ƒè„šæœ¬ï¼

## [](#training-script)è®­ç»ƒè„šæœ¬ï¼ˆTraining scriptï¼‰

è®­ç»ƒè„šæœ¬ä¹Ÿç±»ä¼¼äº[æ–‡ç”Ÿå›¾](text2image#training-script)è®­ç»ƒæŒ‡å—ï¼Œä½†å·²ä¿®æ”¹ä»¥æ”¯æŒ Wuerstchenã€‚æœ¬æŒ‡å—é‡ç‚¹ä»‹ç» Wuerstchen è®­ç»ƒè„šæœ¬ç‹¬æœ‰çš„ä»£ç ã€‚

[`mainï¼ˆï¼‰`](https://github.com/huggingface/diffusers/blob/6e68c71503682c8693cb5b06a4da4911dfd655ee/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L441) å‡½æ•°é¦–å…ˆåˆå§‹åŒ–å›¾åƒç¼–ç å™¨ï¼ˆ[EfficientNet](https://github.com/huggingface/diffusers/blob/main/examples/wuerstchen/text_to_image/modeling_efficient_net_encoder.py)ï¼‰ï¼Œä»¥åŠé€šå¸¸çš„è°ƒåº¦ç¨‹åºå’Œåˆ†è¯å™¨ã€‚

```py
with ContextManagers(deepspeed_zero_init_disabled_context_manager()):
    pretrained_checkpoint_file = hf_hub_download("dome272/wuerstchen", filename="model_v2_stage_b.pt")
    state_dict = torch.load(pretrained_checkpoint_file, map_location="cpu")
    image_encoder = EfficientNetEncoder()
    image_encoder.load_state_dict(state_dict["effnet_state_dict"])
    image_encoder.eval()
```
æ‚¨è¿˜å°†åŠ è½½`WuerstchenPrior`æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚

```py
prior = WuerstchenPrior.from_pretrained(args.pretrained_prior_model_name_or_path, subfolder="prior")

optimizer = optimizer_cls(
    prior.parameters(),
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```
æ¥ä¸‹æ¥ï¼Œæ‚¨å°†å¯¹å›¾åƒåº”ç”¨ä¸€äº›[è½¬æ¢ï¼ˆtransformsï¼‰](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)å¹¶[æ ‡è®°æ ‡é¢˜ï¼ˆtokenizeï¼‰](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L637)ï¼š

```py
def preprocess_train(examples):
    images = [image.convert("RGB") for image in examples[image_column]]
    examples["effnet_pixel_values"] = [effnet_transforms(image) for image in images]
    examples["text_input_ids"], examples["text_mask"] = tokenize_captions(examples)
    return examples
```
æœ€åï¼Œ[è®­ç»ƒå¾ªç¯ï¼ˆtraining loop ï¼‰](https://github.com/huggingface/diffusers/blob/65ef7a0c5c594b4f84092e328fbdd73183613b30/examples/wuerstchen/text_to_image/train_text_to_image_prior.py#L656)å¤„ç†ä½¿ç”¨`EfficientNetEncoder`å°†å›¾åƒå‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ï¼Œå‘æ½œåœ¨ç©ºé—´æ·»åŠ å™ªå£°ï¼Œå¹¶ä½¿ç”¨`WuerstchenPrior`æ¨¡å‹é¢„æµ‹å™ªå£°æ®‹ç•™ã€‚

```py
pred_noise = prior(noisy_latents, timesteps, prompt_embeds)
```
å¦‚æœæ‚¨æƒ³äº†è§£æœ‰å…³è®­ç»ƒå¾ªç¯å·¥ä½œåŸç†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[äº†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦ç¨‹åºï¼ˆ Understanding pipelines, models and schedulersï¼‰](../using-diffusers/write_own_pipeline)æ•™ç¨‹ï¼Œè¯¥æ•™ç¨‹åˆ†è§£äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## [](#launch-the-script)å¯åŠ¨è„šæœ¬ï¼ˆLaunch the scriptï¼‰

å®Œæˆæ‰€æœ‰æ›´æ”¹æˆ–å¯¹é»˜è®¤é…ç½®æ„Ÿåˆ°æ»¡æ„åï¼Œå°±å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬äº†ï¼ğŸš€

å°†ç¯å¢ƒå˜é‡`DATASET_NAME`è®¾ç½®ä¸ºä¸­å¿ƒä¸­çš„æ•°æ®é›†åç§°ã€‚æœ¬æŒ‡å—ä½¿ç”¨ [ Naruto BLIP captions](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions)æ•°æ®é›†ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šåˆ›å»ºå’Œè®­ç»ƒï¼ˆè¯·å‚é˜…[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†ï¼ˆCreate a dataset for trainingï¼‰](create_dataset)æŒ‡å—ï¼‰ã€‚

è¦ä½¿ç”¨æƒé‡å’Œåå·®ç›‘æ§è®­ç»ƒè¿›åº¦ï¼Œè¯·å°†å‚æ•°`--report_to=wandb`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ã€‚æ‚¨è¿˜éœ€è¦å°†`--validation_prompt`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ä»¥è·Ÿè¸ªç»“æœã€‚è¿™å¯¹äºè°ƒè¯•æ¨¡å‹å’ŒæŸ¥çœ‹ä¸­é—´ç»“æœéå¸¸æœ‰ç”¨ã€‚

```py
export DATASET_NAME="lambdalabs/naruto-blip-captions"

accelerate launch  train_text_to_image_prior.py \
  --mixed_precision="fp16" \
  --dataset_name=$DATASET_NAME \
  --resolution=768 \
  --train_batch_size=4 \
  --gradient_accumulation_steps=4 \
  --gradient_checkpointing \
  --dataloader_num_workers=4 \
  --max_train_steps=15000 \
  --learning_rate=1e-05 \
  --max_grad_norm=1 \
  --checkpoints_total_limit=3 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --validation_prompts="A robot naruto, 4k photo" \
  --report_to="wandb" \
  --push_to_hub \
  --output_dir="wuerstchen-prior-naruto-model"
```
è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼

```py
import torch
from diffusers import AutoPipelineForText2Image
from diffusers.pipelines.wuerstchen import DEFAULT_STAGE_C_TIMESTEPS

pipeline = AutoPipelineForText2Image.from_pretrained("path/to/saved/model", torch_dtype=torch.float16).to("cuda")

caption = "A cute bird naruto holding a shield"
images = pipeline(
    caption,
    width=1024,
    height=1536,
    prior_timesteps=DEFAULT_STAGE_C_TIMESTEPS,
    prior_guidance_scale=4.0,
    num_images_per_prompt=2,
).images
```
## [](#next-steps)åç»­æ­¥éª¤ï¼ˆNext stepsï¼‰

æ­å–œæ‚¨è®­ç»ƒäº† Wuerstchen æ¨¡å‹ï¼è¦äº†è§£æœ‰å…³å¦‚ä½•ä½¿ç”¨æ–°æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š

+   è¯·æŸ¥çœ‹ [Wuerstchen](../api/pipelines/wuerstchen#text-to-image-generation) API æ–‡æ¡£ï¼Œè¯¦ç»†äº†è§£å¦‚ä½•ä½¿ç”¨ç®¡é“ç”Ÿæˆæ–‡æœ¬åˆ°å›¾åƒåŠå…¶é™åˆ¶ã€‚