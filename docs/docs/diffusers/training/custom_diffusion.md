# è‡ªå®šä¹‰æ‰©æ•£è®­ç»ƒç¤ºä¾‹

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/custom_diffusion>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/custom_diffusion>


[è‡ªå®šä¹‰æ‰©æ•£](https://arxiv.org/abs/2212.04488)
 æ˜¯ä¸€ç§è‡ªå®šä¹‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä»…ç»™å®šä¸»é¢˜çš„å‡ å¼ ï¼ˆ4~5ï¼‰å¼ å›¾åƒçš„ç¨³å®šæ‰©æ•£ã€‚
è¿™
 `train_custom_diffusion.py`
 è„šæœ¬å±•ç¤ºäº†å¦‚ä½•å®æ–½è®­ç»ƒç¨‹åºå¹¶å¯¹å…¶è¿›è¡Œè°ƒæ•´ä»¥å®ç°ç¨³å®šæ‰©æ•£ã€‚


æ­¤è®­ç»ƒç¤ºä¾‹ç”±ä»¥ä¸‹äººå‘˜è´¡çŒ®
 [åŠªæ™®å°”åº“ç›ä¸½](https://nupurkmr9.github.io/)
 ï¼ˆã€Šè‡ªå®šä¹‰æ‰©æ•£ã€‹çš„ä½œè€…ä¹‹ä¸€ï¼‰ã€‚


## ä½¿ç”¨ PyTorch åœ¨æœ¬åœ°è¿è¡Œ



### 


 å®‰è£…ä¾èµ–é¡¹


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š


**é‡è¦çš„**


ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®
 **ä»æºå®‰è£…**
 å¹¶ä¿æŒå®‰è£…æœ€æ–°ï¼Œå› ä¸ºæˆ‘ä»¬ç»å¸¸æ›´æ–°ç¤ºä¾‹è„šæœ¬å¹¶å®‰è£…ä¸€äº›ç‰¹å®šäºç¤ºä¾‹çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š



```
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```


ç„¶åcdåˆ°
 [ç¤ºä¾‹æ–‡ä»¶å¤¹](https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion)



```
cd examples/custom_diffusion
```


ç°åœ¨è¿è¡Œ



```
pip install -r requirements.txt
pip install clip-retrieval 
```


å¹¶åˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤—åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


æˆ–è€…ä½¿ç”¨é»˜è®¤åŠ é€Ÿé…ç½®è€Œä¸å›ç­”æœ‰å…³æ‚¨çš„ç¯å¢ƒçš„é—®é¢˜



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œä¾‹å¦‚ç¬”è®°æœ¬



```
from accelerate.utils import write_basic_config

write_basic_config()
```


### 


 çŒ«çš„ä¾‹å­ğŸ˜º


ç°åœ¨è®©æˆ‘ä»¬è·å–æ•°æ®é›†ã€‚ä»ä¸‹è½½æ•°æ®é›†
 [æ­¤å¤„](https://www.cs.cmu.edu/~custom-diffusion/assets/data.zip)
 å¹¶è§£å‹å®ƒã€‚è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


æˆ‘ä»¬è¿˜ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ”¶é›†äº† 200 å¼ çœŸå®å›¾åƒ
 `å‰ªè¾‘æ£€ç´¢`
 ä¸è®­ç»ƒæ•°æ®é›†ä¸­çš„ç›®æ ‡å›¾åƒç»„åˆä½œä¸ºæ­£åˆ™åŒ–ã€‚è¿™å¯ä»¥é˜²æ­¢è¿‡åº¦æ‹Ÿåˆç»™å®šçš„ç›®æ ‡å›¾åƒã€‚ä»¥ä¸‹æ ‡å¿—å¯ç”¨æ­£åˆ™åŒ–
 `with_prior_preservation`
 ,
 `çœŸå®å…ˆéªŒ`
 å’Œ
 `prior_loss_weight=1ã€‚`
 ã€‚
è¿™
 `ç±»æç¤º`
 ç±»åˆ«åç§°åº”ä¸ç›®æ ‡å›¾åƒç›¸åŒã€‚æ”¶é›†åˆ°çš„çœŸå®å›¾åƒçš„æ–‡å­—è¯´æ˜ç±»ä¼¼äº
 `ç±»æç¤º`
 ã€‚æ£€ç´¢åˆ°çš„å›¾åƒä¿å­˜åœ¨
 `ç±»æ•°æ®ç›®å½•`
 ã€‚æ‚¨å¯ä»¥ç¦ç”¨
 `çœŸå®å…ˆéªŒ`
 ä½¿ç”¨ç”Ÿæˆçš„å›¾åƒä½œä¸ºæ­£åˆ™åŒ–ã€‚è¦æ”¶é›†çœŸå®å›¾åƒï¼Œè¯·åœ¨è®­ç»ƒä¹‹å‰å…ˆä½¿ç”¨æ­¤å‘½ä»¤ã€‚



```
pip install clip-retrieval
python retrieve.py --class_prompt cat --class_data_dir real_reg/samples_cat --num_class_images 200
```


*****æ³¨æ„ï¼šæ›´æ”¹
 `å†³è®®`
 å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ 768
 [stable-diffusion-2](https://huggingface.co/stabilityai/stable-diffusion-2)
 768x768 æ¨¡å‹ã€‚*****


è¯¥è„šæœ¬åˆ›å»ºå¹¶ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å’Œ
 `pytorch_custom_diffusion_weights.bin`
 æ–‡ä»¶åœ¨æ‚¨çš„å­˜å‚¨åº“ä¸­ã€‚



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"
export INSTANCE_DIR="./data/cat"

accelerate launch train_custom_diffusion.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --class_data_dir=./real_reg/samples_cat/   --with_prior_preservation --real_prior --prior_loss_weight=1.0   --class_prompt="cat" --num_class_images=200   --instance_prompt="photo of a <new1> cat"    --resolution=512    --train_batch_size=2    --learning_rate=1e-5    --lr_warmup_steps=0   --max_train_steps=250   --scale_lr --hflip    --modifier_token "<new1>"   --push_to_hub
```


**ä½¿ç”¨
 `--enable_xformers_memory_efficient_attention`
 ä»¥è¾ƒä½çš„ VRAM è¦æ±‚ï¼ˆæ¯ä¸ª GPU 16GBï¼‰å®ç°æ›´å¿«çš„è®­ç»ƒã€‚è·Ÿéš
 [æœ¬æŒ‡å—](https://github.com/facebookresearch/xformers)
 æœ‰å…³å®‰è£…è¯´æ˜ã€‚**


ä½¿ç”¨æƒé‡å’Œåå·®è·Ÿè¸ªæ‚¨çš„å®éªŒï¼ˆ
 `ä¸‡å¾·å¸ƒ`
 ï¼‰å¹¶ä¿å­˜ä¸­é—´ç»“æœï¼ˆæˆ‘ä»¬å¼ºçƒˆæ¨èï¼‰ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š


* å®‰è£…
 `ä¸‡å¾·å¸ƒ`
 :
 `pip å®‰è£…wandb`
 ã€‚
* æˆæƒï¼š
 `wandbç™»å½•`
 ã€‚
* ç„¶åæŒ‡å®šä¸€ä¸ª
 `éªŒè¯æç¤º`
 å¹¶è®¾ç½®
 `æŠ¥å‘Šå¯¹è±¡`
 åˆ°
 `ä¸‡å¾·å¸ƒ`
 åœ¨å¼€å±•åŸ¹è®­çš„åŒæ—¶ã€‚æ‚¨è¿˜å¯ä»¥é…ç½®ä»¥ä¸‹ç›¸å…³å‚æ•°ï¼š
+ `num_validation_images`
+ `éªŒè¯æ­¥éª¤`


è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å‘½ä»¤ï¼š



```
accelerate launch train_custom_diffusion.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --class_data_dir=./real_reg/samples_cat/   --with_prior_preservation --real_prior --prior_loss_weight=1.0   --class_prompt="cat" --num_class_images=200   --instance_prompt="photo of a <new1> cat"    --resolution=512    --train_batch_size=2    --learning_rate=1e-5    --lr_warmup_steps=0   --max_train_steps=250   --scale_lr --hflip    --modifier_token "<new1>"   --validation_prompt="<new1> cat sitting in a bucket"   --report_to="wandb"   --push_to_hub
```


è¿™æ˜¯ä¸€ä¸ªä¾‹å­
 [æƒé‡å’Œåå·®é¡µé¢](https://wandb.ai/sayakpaul/custom-diffusion/runs/26ghrcau)
 æ‚¨å¯ä»¥åœ¨å…¶ä¸­æŸ¥çœ‹ä¸­é—´ç»“æœä»¥åŠå…¶ä»–åŸ¹è®­è¯¦ç»†ä¿¡æ¯ã€‚


å¦‚æœæ‚¨æŒ‡å®š
 `--push_to_hub`
 ï¼Œå­¦ä¹ åˆ°çš„å‚æ•°å°†è¢«æ¨é€åˆ° Hugging Face Hub ä¸Šçš„å­˜å‚¨åº“ã€‚è¿™æ˜¯ä¸€ä¸ª
 [ç¤ºä¾‹å­˜å‚¨åº“](https://huggingface.co/sayakpaul/custom-diffusion-cat)
 ã€‚


### 


 å¤šä¸ªæ¦‚å¿µçš„åŸ¹è®­ğŸ±ğŸªµ


æä¾›ä¸€ä¸ª
 [json](https://github.com/adobe-research/custom-diffusion/blob/main/assets/concept_list.json)
 åŒ…å«æ¯ä¸ªæ¦‚å¿µä¿¡æ¯çš„æ–‡ä»¶ï¼Œç±»ä¼¼äº
 [è¿™ä¸ª](https://github.com/ShivamShrrirao/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)
 ã€‚


è¦æ”¶é›†çœŸå®å›¾åƒï¼Œè¯·ä¸º json æ–‡ä»¶ä¸­çš„æ¯ä¸ªæ¦‚å¿µè¿è¡Œæ­¤å‘½ä»¤ã€‚



```
pip install clip-retrieval
python retrieve.py --class_prompt {} --class_data_dir {} --num_class_images 200
```


ç„¶åæˆ‘ä»¬å‡†å¤‡å¼€å§‹è®­ç»ƒï¼



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"

accelerate launch train_custom_diffusion.py   --pretrained_model_name_or_path=$MODEL\_NAME    --output_dir=$OUTPUT\_DIR   --concepts_list=./concept_list.json   --with_prior_preservation --real_prior --prior_loss_weight=1.0   --resolution=512    --train_batch_size=2    --learning_rate=1e-5    --lr_warmup_steps=0   --max_train_steps=500   --num_class_images=200   --scale_lr --hflip    --modifier_token "<new1>+<new2>"   --push_to_hub
```


è¿™æ˜¯ä¸€ä¸ªä¾‹å­
 [æƒé‡å’Œåå·®é¡µé¢](https://wandb.ai/sayakpaul/custom-diffusion/runs/3990tzkg)
 æ‚¨å¯ä»¥åœ¨å…¶ä¸­æŸ¥çœ‹ä¸­é—´ç»“æœä»¥åŠå…¶ä»–åŸ¹è®­è¯¦ç»†ä¿¡æ¯ã€‚


### 


 äººè„¸è®­ç»ƒ


ä¸ºäº†å¯¹äººè„¸è¿›è¡Œå¾®è°ƒï¼Œæˆ‘ä»¬å‘ç°ä»¥ä¸‹é…ç½®æ•ˆæœæ›´å¥½ï¼š
 `å­¦ä¹ ç‡=5e-6`
 ,
 `max_train_steps=1000 åˆ° 2000`
 ï¼Œ å’Œ
 `freeze_model=crossattn`
 è‡³å°‘æœ‰ 15-20 å¼ å›¾ç‰‡ã€‚


è¦æ”¶é›†çœŸå®å›¾åƒï¼Œè¯·åœ¨è®­ç»ƒä¹‹å‰å…ˆä½¿ç”¨æ­¤å‘½ä»¤ã€‚



```
pip install clip-retrieval
python retrieve.py --class_prompt person --class_data_dir real_reg/samples_person --num_class_images 200
```


ç„¶åå¼€å§‹è®­ç»ƒå§ï¼



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export OUTPUT_DIR="path-to-save-model"
export INSTANCE_DIR="path-to-images"

accelerate launch train_custom_diffusion.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --class_data_dir=./real_reg/samples_person/   --with_prior_preservation --real_prior --prior_loss_weight=1.0   --class_prompt="person" --num_class_images=200   --instance_prompt="photo of a <new1> person"    --resolution=512    --train_batch_size=2    --learning_rate=5e-6    --lr_warmup_steps=0   --max_train_steps=1000   --scale_lr --hflip --noaug   --freeze_model crossattn   --modifier_token "<new1>"   --enable_xformers_memory_efficient_attention   --push_to_hub
```


## æ¨ç†



ä½¿ç”¨ä¸Šè¿°å‘½ä»¤è®­ç»ƒæ¨¡å‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œæ¨ç†ã€‚ç¡®ä¿åŒ…æ‹¬
 `ä¿®é¥°ç¬¦æ ‡è®°`
 ï¼ˆä¾‹å¦‚ä¸Šä¾‹ä¸­çš„ \<new1>ï¼‰åœ¨æç¤ºç¬¦ä¸­ã€‚



```
import torch
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
pipe.unet.load_attn_procs("path-to-save-model", weight_name="pytorch\_custom\_diffusion\_weights.bin")
pipe.load_textual_inversion("path-to-save-model", weight_name="<new1>.bin")

image = pipe(
    "<new1> cat sitting in a bucket",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("cat.png")
```


å¯ä»¥ç›´æ¥ä» Hub å­˜å‚¨åº“åŠ è½½è¿™äº›å‚æ•°ï¼š



```
import torch
from huggingface_hub.repocard import RepoCard
from diffusers import DiffusionPipeline

model_id = "sayakpaul/custom-diffusion-cat"
card = RepoCard.load(model_id)
base_model_id = card.data.to_dict()["base\_model"]

pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipe.unet.load_attn_procs(model_id, weight_name="pytorch\_custom\_diffusion\_weights.bin")
pipe.load_textual_inversion(model_id, weight_name="<new1>.bin")

image = pipe(
    "<new1> cat sitting in a bucket",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("cat.png")
```


ä»¥ä¸‹æ˜¯ä½¿ç”¨å¤šä¸ªæ¦‚å¿µè¿›è¡Œæ¨ç†çš„ç¤ºä¾‹ï¼š



```
import torch
from huggingface_hub.repocard import RepoCard
from diffusers import DiffusionPipeline

model_id = "sayakpaul/custom-diffusion-cat-wooden-pot"
card = RepoCard.load(model_id)
base_model_id = card.data.to_dict()["base\_model"]

pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, use_safetensors=True).to("cuda")
pipe.unet.load_attn_procs(model_id, weight_name="pytorch\_custom\_diffusion\_weights.bin")
pipe.load_textual_inversion(model_id, weight_name="<new1>.bin")
pipe.load_textual_inversion(model_id, weight_name="<new2>.bin")

image = pipe(
    "the <new1> cat sculpture in the style of a <new2> wooden pot",
    num_inference_steps=100,
    guidance_scale=6.0,
    eta=1.0,
).images[0]
image.save("multi-subject.png")
```


è¿™é‡Œï¼Œ
 `çŒ«`
 å’Œ
 ã€Œæœ¨é”…ã€
 å‚è€ƒå¤šä¸ªæ¦‚å¿µã€‚


### 


 ä»è®­ç»ƒæ£€æŸ¥ç‚¹æ¨æ–­


å¦‚æœæ‚¨ä½¿ç”¨äº†è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„å®Œæ•´æ£€æŸ¥ç‚¹ä¹‹ä¸€ï¼Œæ‚¨è¿˜å¯ä»¥æ‰§è¡Œæ¨ç†
 `--checkpointing_steps`
 äº‰è®ºã€‚


å…¨éƒ¨ã€‚


## å°†æˆç»©è®¾ç½®ä¸ºæ— 



ä¸ºäº†èŠ‚çœæ›´å¤šå†…å­˜ï¼Œè¯·ä¼ é€’
 `--set_grads_to_none`
 è„šæœ¬çš„å‚æ•°ã€‚è¿™ä¼šå°† grads è®¾ç½®ä¸º None è€Œä¸æ˜¯é›¶ã€‚ä½†æ˜¯ï¼Œè¯·æ³¨æ„å®ƒä¼šæ”¹å˜æŸäº›è¡Œä¸ºï¼Œå› æ­¤å¦‚æœæ‚¨å¼€å§‹é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·åˆ é™¤æ­¤å‚æ•°ã€‚


æ›´å¤šä¿¡æ¯ï¼š
 <https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html>


## å®éªŒç»“æœ



æ‚¨å¯ä»¥å‚è€ƒ
 [æˆ‘ä»¬çš„ç½‘é¡µ](https://www.cs.cmu.edu/~custom-diffusion/)
 è¯¦ç»†è®¨è®ºäº†æˆ‘ä»¬çš„å®éªŒã€‚