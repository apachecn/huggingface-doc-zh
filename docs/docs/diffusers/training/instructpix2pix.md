# æŒ‡å¯¼Pix2Pix

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/instructpix2pix>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/instructpix2pix>


[InstructPix2Pix](https://arxiv.org/abs/2211.09800)
 æ˜¯ä¸€ç§å¾®è°ƒæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œä»¥ä¾¿å®ƒä»¬å¯ä»¥éµå¾ªè¾“å…¥å›¾åƒçš„ç¼–è¾‘æŒ‡ä»¤ã€‚ä½¿ç”¨æ­¤æ–¹æ³•å¾®è°ƒçš„æ¨¡å‹å°†ä»¥ä¸‹å†…å®¹ä½œä¸ºè¾“å…¥ï¼š


![instructpix2pix-inputs](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/evaluation_diffusion_models/edit-instruction.png)


è¾“å‡ºæ˜¯ä¸€ä¸ªâ€œç¼–è¾‘â€å›¾åƒï¼Œåæ˜ äº†åº”ç”¨äºè¾“å…¥å›¾åƒçš„ç¼–è¾‘æŒ‡ä»¤ï¼š


![instructpix2pix-output](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/output-gs%407-igs%401-steps%4050.png)


è¿™
 `train_instruct_pix2pix.py`
 è„šæœ¬ï¼ˆä½ å¯ä»¥æ‰¾åˆ°å®ƒ
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/instruct_pix2pix/train_instruct_pix2pix.py)
 ï¼‰å±•ç¤ºäº†å¦‚ä½•å®æ–½è®­ç»ƒç¨‹åºå¹¶ä½¿å…¶é€‚åº”ç¨³å®šæ‰©æ•£ã€‚


***å…è´£å£°æ˜ï¼šå°½ç®¡
 `train_instruct_pix2pix.py`
 å®ç° InstructPix2Pix
åŸ¹è®­ç¨‹åºï¼ŒåŒæ—¶å¿ å®äº
 [åŸå§‹å®ç°](https://github.com/timothybrooks/instruct-pix2pix)
 æˆ‘ä»¬åªåœ¨ä¸€ä¸ªä¸Šæµ‹è¯•è¿‡å®ƒ
 [å°è§„æ¨¡æ•°æ®é›†](https://huggingface.co/datasets/fusing/instructpix2pix-1000-samples)
 ã€‚è¿™å¯èƒ½ä¼šå½±å“æœ€ç»ˆç»“æœã€‚ä¸ºäº†è·å¾—æ›´å¥½çš„ç»“æœï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†è¿›è¡Œæ›´é•¿çš„è®­ç»ƒã€‚
 [æ­¤å¤„](https://huggingface.co/datasets/timbrooks/instructpix2pix-clip-filtered)
 æ‚¨å¯ä»¥æ‰¾åˆ°ç”¨äº InstructPix2Pix è®­ç»ƒçš„å¤§å‹æ•°æ®é›†ã€‚***


## ä½¿ç”¨ PyTorch åœ¨æœ¬åœ°è¿è¡Œ



### 


 å®‰è£…ä¾èµ–é¡¹


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š


**é‡è¦çš„**


ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®
 **ä»æºå®‰è£…**
 å¹¶ä¿æŒå®‰è£…æœ€æ–°ï¼Œå› ä¸ºæˆ‘ä»¬ç»å¸¸æ›´æ–°ç¤ºä¾‹è„šæœ¬å¹¶å®‰è£…ä¸€äº›ç‰¹å®šäºç¤ºä¾‹çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š



```
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```


ç„¶åcdåˆ°ç¤ºä¾‹æ–‡ä»¶å¤¹ä¸­



```
cd examples/instruct_pix2pix
```


ç°åœ¨è¿è¡Œ



```
pip install -r requirements.txt
```


å¹¶åˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤—åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


æˆ–è€…ä½¿ç”¨é»˜è®¤åŠ é€Ÿé…ç½®è€Œä¸å›ç­”æœ‰å…³æ‚¨çš„ç¯å¢ƒçš„é—®é¢˜



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼Œä¾‹å¦‚ç¬”è®°æœ¬



```
from accelerate.utils import write_basic_config

write_basic_config()
```


### 


 ç©å…·ç¤ºä¾‹


å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨
 [å°ç©å…·æ•°æ®é›†](https://huggingface.co/datasets/fusing/instructpix2pix-1000-samples)
 ä¸ºäº†è®­ç»ƒã€‚æ•°æ®é›†
æ˜¯ä¸€ä¸ªè¾ƒå°çš„ç‰ˆæœ¬
 [åŸå§‹æ•°æ®é›†](https://huggingface.co/datasets/timbrooks/instructpix2pix-clip-filtered)
 InstructPix2Pix è®ºæ–‡ä¸­ä½¿ç”¨ã€‚è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚æ‚¨è¿˜éœ€è¦åœ¨ä¸­æŒ‡å®šæ•°æ®é›†åç§°
 `æ•°æ®é›†_ID`
 ï¼š



```
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATASET_ID="fusing/instructpix2pix-1000-samples"
```


ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚è¯¥è„šæœ¬ä¿å­˜æ‰€æœ‰ç»„ä»¶ï¼ˆ
 `ç‰¹å¾æå–å™¨`
 ,
 `è°ƒåº¦ç¨‹åº`
 ,
 `æ–‡æœ¬ç¼–ç å™¨`
 ,
 `ä¹Œå†…ç‰¹`
 ç­‰ï¼‰åœ¨å­˜å‚¨åº“çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚



```
accelerate launch --mixed_precision="fp16" train_instruct_pix2pix.py     --pretrained_model_name_or_path=$MODEL\_NAME     --dataset_name=$DATASET\_ID     --enable_xformers_memory_efficient_attention     --resolution=256 --random_flip     --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing     --max_train_steps=15000     --checkpointing_steps=5000 --checkpoints_total_limit=1     --learning_rate=5e-05 --max_grad_norm=1 --lr_warmup_steps=0     --conditioning_dropout_prob=0.05     --mixed_precision=fp16     --seed=42     --push_to_hub
```


æ­¤å¤–ï¼Œæˆ‘ä»¬æ”¯æŒæ‰§è¡ŒéªŒè¯æ¨ç†æ¥ç›‘æ§è®­ç»ƒè¿›åº¦
å…·æœ‰æƒé‡å’Œåå·®ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨æ­¤åŠŸèƒ½
 `report_to="wandb"`
 ï¼š



```
accelerate launch --mixed_precision="fp16" train_instruct_pix2pix.py     --pretrained_model_name_or_path=$MODEL\_NAME     --dataset_name=$DATASET\_ID     --enable_xformers_memory_efficient_attention     --resolution=256 --random_flip     --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing     --max_train_steps=15000     --checkpointing_steps=5000 --checkpoints_total_limit=1     --learning_rate=5e-05 --max_grad_norm=1 --lr_warmup_steps=0     --conditioning_dropout_prob=0.05     --mixed_precision=fp16     --val_image_url="https://hf.co/datasets/diffusers/diffusers-images-docs/resolve/main/mountain.png"     --validation_prompt="make the mountains snowy"     --seed=42     --report_to=wandb     --push_to_hub
```


æˆ‘ä»¬æ¨èè¿™ç§ç±»å‹çš„éªŒè¯ï¼Œå› ä¸ºå®ƒå¯¹äºæ¨¡å‹è°ƒè¯•å¾ˆæœ‰ç”¨ã€‚è¯·æ³¨æ„ï¼Œæ‚¨éœ€è¦
 `ä¸‡å¾·å¸ƒ`
 å®‰è£…ä½¿ç”¨è¿™ä¸ªã€‚æ‚¨å¯ä»¥å®‰è£…
 `ä¸‡å¾·å¸ƒ`
 é€šè¿‡è·‘æ­¥
 `pip å®‰è£…wandb`
 ã€‚


[æ­¤å¤„](https://wandb.ai/sayakpaul/instruct-pix2pix/runs/ctr3kovq)
 ï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªç¤ºä¾‹è®­ç»ƒè¿è¡Œï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€äº›éªŒè¯æ ·æœ¬å’Œè®­ç»ƒè¶…å‚æ•°ã€‚


***æ³¨æ„ï¼šåœ¨åŸå§‹è®ºæ–‡ä¸­ï¼Œä½œè€…è§‚å¯Ÿåˆ°ï¼Œå³ä½¿ä½¿ç”¨ 256x256 çš„å›¾åƒåˆ†è¾¨ç‡è®­ç»ƒæ¨¡å‹ï¼Œå®ƒä¹Ÿå¯ä»¥å¾ˆå¥½åœ°æ¨å¹¿åˆ°æ›´å¤§çš„åˆ†è¾¨ç‡ï¼Œä¾‹å¦‚ 512x512ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºä»–ä»¬åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨äº†æ›´å¤§çš„æ•°æ®é›†ã€‚***


## ä½¿ç”¨å¤šä¸ª GPU è¿›è¡Œè®­ç»ƒ



â€˜åŠ é€Ÿâ€™
 å…è®¸æ— ç¼çš„å¤š GPU è®­ç»ƒã€‚æŒ‰ç…§è¯´æ˜æ“ä½œ
 [æ­¤å¤„](https://huggingface.co/docs/accelerate/basic_tutorials/launch)
 ç”¨äºè¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
 â€˜åŠ é€Ÿâ€™
 ã€‚è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å‘½ä»¤ï¼š



```
accelerate launch --mixed_precision="fp16" --multi_gpu train_instruct_pix2pix.py  --pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5  --dataset_name=sayakpaul/instructpix2pix-1000-samples  --use_ema  --enable_xformers_memory_efficient_attention  --resolution=512 --random_flip  --train_batch_size=4 --gradient_accumulation_steps=4 --gradient_checkpointing  --max_train_steps=15000  --checkpointing_steps=5000 --checkpoints_total_limit=1  --learning_rate=5e-05 --lr_warmup_steps=0  --conditioning_dropout_prob=0.05  --mixed_precision=fp16  --seed=42  --push_to_hub
```


## æ¨ç†



è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œæ¨ç†ï¼š



```
import PIL
import requests
import torch
from diffusers import StableDiffusionInstructPix2PixPipeline

model_id = "your\_model\_id"  # <- replace this
pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(
   model_id, torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
generator = torch.Generator("cuda").manual_seed(0)

url = "https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/test\_pix2pix\_4.png"


def download\_image(url):
   å›¾åƒ = PIL.Image.open(requests.get(url,stream=True).raw)
   å›¾åƒ = PIL.ImageOps.exif_tâ€‹â€‹ranspose(å›¾åƒ)
   å›¾åƒ = image.convert("RGB")
   è¿”å›å›¾åƒ


image = download_image(url)
prompt = "wipe out the lake"
num_inference_steps = 20
image_guidance_scale = 1.5
guidance_scale = 10

edited_image = pipe(
   prompt,
   image=image,
   num_inference_steps=num_inference_steps,
   image_guidance_scale=image_guidance_scale,
   guidance_scale=guidance_scale,
   generator=generator,
).images[0]
edited_image.save("edited\_image.png")
```


å¯ä»¥æ‰¾åˆ°ä½¿ç”¨æ­¤è®­ç»ƒè„šæœ¬è·å¾—çš„ç¤ºä¾‹æ¨¡å‹å­˜å‚¨åº“
è¿™é‡Œ -
 [sayakpaul/instruct-pix2pix](https://huggingface.co/sayakpaul/instruct-pix2pix)
 ã€‚


æˆ‘ä»¬é¼“åŠ±æ‚¨ä½¿ç”¨ä»¥ä¸‹ä¸‰ä¸ªå‚æ•°æ¥æ§åˆ¶
è¡¨æ¼”æ—¶çš„é€Ÿåº¦å’Œè´¨é‡ï¼š


* `num_inference_steps`
* `image_guidance_scale`
* `æŒ‡å¯¼è§„æ¨¡`


ç‰¹åˆ«ï¼Œ
 `image_guidance_scale`
 å’Œ
 `æŒ‡å¯¼è§„æ¨¡`
 å¯ä»¥äº§ç”Ÿæ·±è¿œçš„å½±å“
åœ¨ç”Ÿæˆçš„ï¼ˆâ€œç¼–è¾‘çš„â€ï¼‰å›¾åƒä¸Šï¼ˆå‚è§
 [æ­¤å¤„](https://twitter.com/RisingSayak/status/1628392199196151808?s=20)
 ä¸¾ä¸ªä¾‹å­ï¼‰ã€‚


å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾ä¸€äº›æœ‰è¶£çš„æ–¹æ³•æ¥ä½¿ç”¨ InstructPix2Pix è®­ç»ƒæ–¹æ³•ï¼Œæˆ‘ä»¬æ¬¢è¿æ‚¨æŸ¥çœ‹æ­¤åšå®¢æ–‡ç« ï¼š
 [ä½¿ç”¨ InstructPix2Pix è¿›è¡ŒæŒ‡ä»¤è°ƒæ•´ç¨³å®šæ‰©æ•£](https://huggingface.co/blog/instruction-tuning-sd)
 ã€‚


## ç¨³å®šæ‰©æ•£XL



è®­ç»ƒä¸
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 è¿˜é€šè¿‡ä»¥ä¸‹æ–¹å¼æ”¯æŒ
 `train_instruct_pix2pix_sdxl.py`
 è„šæœ¬ã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/instruct_pix2pix/README_sdxl.md)
 ã€‚