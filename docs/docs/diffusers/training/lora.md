# å¤§å‹è¯­è¨€æ¨¡å‹çš„ä½ç§©é€‚åº” (LoRA)

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/lora>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/lora>


è¿™æ˜¯ä¸€ä¸ªå®éªŒæ€§åŠŸèƒ½ã€‚å…¶ API å°†æ¥å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚


[å¤§å‹è¯­è¨€æ¨¡å‹çš„ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰](https://arxiv.org/abs/2106.09685)
 æ˜¯ä¸€ç§åŠ é€Ÿå¤§å‹æ¨¡å‹è®­ç»ƒåŒæ—¶æ¶ˆè€—æ›´å°‘å†…å­˜çš„è®­ç»ƒæ–¹æ³•ã€‚å®ƒæ·»åŠ äº†æˆå¯¹çš„æ’åºåˆ†è§£æƒé‡çŸ©é˜µï¼ˆç§°ä¸º
 **æ›´æ–°çŸ©é˜µ**
 ï¼‰åˆ°ç°æœ‰æƒé‡ï¼Œä»¥åŠ
 **ä»…æœ‰çš„**
 è®­ç»ƒé‚£äº›æ–°å¢åŠ çš„é‡é‡ã€‚è¿™æœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š


* ä¹‹å‰çš„é¢„è®­ç»ƒæƒé‡ä¿æŒå†»ç»“ï¼Œå› æ­¤æ¨¡å‹ä¸æ˜“å‡ºç°
 [ç¾éš¾æ€§é—å¿˜](https://www.pnas.org/doi/10.1073/pnas.1611835114)
 ã€‚
* ç­‰çº§åˆ†è§£çŸ©é˜µçš„å‚æ•°æ¯”åŸå§‹æ¨¡å‹å°‘å¾—å¤šï¼Œè¿™æ„å‘³ç€è®­ç»ƒåçš„ LoRA æƒé‡å¾ˆå®¹æ˜“ç§»æ¤ã€‚
* LoRAçŸ©é˜µä¸€èˆ¬ä¼šæ·»åŠ åˆ°åŸå§‹æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­ã€‚ ğŸ§¨ æ‰©æ•£å™¨æä¾›
 [load\_attn\_procs()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.UNet2DConditionLoadersMixin.load_attn_procs)
 å°† LoRA æƒé‡åŠ è½½åˆ°æ¨¡å‹æ³¨æ„åŠ›å±‚çš„æ–¹æ³•ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ§åˆ¶æ¨¡å‹é€‚åº”æ–°è®­ç»ƒå›¾åƒçš„ç¨‹åº¦ï¼š
 `è§„æ¨¡`
 èŒƒå›´ã€‚
* æ›´é«˜çš„å†…å­˜æ•ˆç‡ä½¿æ‚¨å¯ä»¥åœ¨ Tesla T4ã€RTX 3080 ç”šè‡³ RTX 2080 Ti ç­‰æ¶ˆè´¹ç±» GPU ä¸Šè¿è¡Œå¾®è°ƒï¼åƒ T4 è¿™æ ·çš„ GPU æ˜¯å…è´¹çš„ï¼Œå¹¶ä¸”å¯ä»¥åœ¨ Kaggle æˆ– Google Colab ç¬”è®°æœ¬ä¸­è½»æ¾è®¿é—®ã€‚


ğŸ’¡ LoRA ä¸ä»…ä»…å±€é™äºæ³¨æ„åŠ›å±‚ã€‚ä½œè€…å‘ç°ä¿®æ”¹
è¯­è¨€æ¨¡å‹çš„æ³¨æ„åŠ›å±‚è¶³ä»¥é«˜æ•ˆåœ°è·å¾—è‰¯å¥½çš„ä¸‹æ¸¸æ€§èƒ½ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé€šå¸¸åªå°† LoRA æƒé‡æ·»åŠ åˆ°æ¨¡å‹çš„æ³¨æ„åŠ›å±‚ä¸­çš„åŸå› ã€‚æŸ¥çœ‹
 [ä½¿ç”¨LoRAè¿›è¡Œé«˜æ•ˆçš„ç¨³å®šæ‰©æ•£å¾®è°ƒ](https://huggingface.co/blog/lora)
 åšå®¢ä»¥è·å–æœ‰å…³ LoRA å¦‚ä½•å·¥ä½œçš„æ›´å¤šä¿¡æ¯ï¼


[cloneofsimo](https://github.com/cloneofsimo)
 æ˜¯ç¬¬ä¸€ä¸ªåœ¨æµè¡Œçš„é¢†åŸŸå°è¯• LoRA ç¨³å®šæ‰©æ•£è®­ç»ƒçš„äºº
 [æ´›æ‹‰](https://github.com/cloneofsimo/lora)
 GitHub å­˜å‚¨åº“ã€‚ ğŸ§¨ Diffusers ç°åœ¨æ”¯æŒä½¿ç”¨ LoRA è¿›è¡Œå¾®è°ƒ
 [æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image#training-with-lora)
 å’Œ
 [DreamBooth](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#training-with-low-rank-adaptation-of-large-language-models-lora)
 ã€‚æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åšåˆ°è¿™ä¸¤ç‚¹ã€‚


å¦‚æœæ‚¨æƒ³å­˜å‚¨æˆ–ä¸ç¤¾åŒºåˆ†äº«æ‚¨çš„æ¨¡å‹ï¼Œè¯·ç™»å½•æ‚¨çš„ Hugging Face å¸æˆ·ï¼ˆåˆ›å»º
 [ä¸€](https://hf.co/join)
 å¦‚æœæ‚¨è¿˜æ²¡æœ‰ï¼‰ï¼š



```
huggingface-cli login
```


## æ–‡æœ¬è½¬å›¾åƒ



å¯¹åƒç¨³å®šæ‰©æ•£è¿™æ ·å…·æœ‰æ•°åäº¿ä¸ªå‚æ•°çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒå¯èƒ½æ—¢ç¼“æ…¢åˆå›°éš¾ã€‚å€ŸåŠ© LoRAï¼Œå¯ä»¥æ›´è½»æ¾ã€æ›´å¿«é€Ÿåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ã€‚å®ƒå¯ä»¥åœ¨å…·æœ‰ä½è‡³ 11GB GPU RAM çš„ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œè€Œæ— éœ€å€ŸåŠ© 8 ä½ä¼˜åŒ–å™¨ç­‰æŠ€å·§ã€‚


### 


 è®­ç»ƒ


è®©æˆ‘ä»¬å¾®è°ƒä¸€ä¸‹
 [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 äº
 [ç¥å¥‡å®è´ BLIP å­—å¹•](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions)
 æ•°æ®é›†æ¥ç”Ÿæˆæ‚¨è‡ªå·±çš„ç¥å¥‡å®è´ã€‚


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚æ‚¨è¿˜éœ€è¦è®¾ç½®
 `æ•°æ®é›†åç§°`
 ç¯å¢ƒå˜é‡ä¸ºæ‚¨è¦è®­ç»ƒçš„æ•°æ®é›†çš„åç§°ã€‚è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


è¿™
 `è¾“å‡ºç›®å½•`
 å’Œ
 `HUB_MODEL_ID`
 å˜é‡æ˜¯å¯é€‰çš„ï¼ŒæŒ‡å®šæ¨¡å‹åœ¨ Hub ä¸Šçš„ä¿å­˜ä½ç½®ï¼š



```
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/pokemon"
export HUB_MODEL_ID="pokemon-lora"
export DATASET_NAME="lambdalabs/pokemon-blip-captions"
```


åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œéœ€è¦æ³¨æ„ä¸€äº›æ ‡å¿—ï¼š


* `--push_to_hub`
 å°†ç»è¿‡è®­ç»ƒçš„ LoRA åµŒå…¥å­˜å‚¨åœ¨ Hub ä¸Šã€‚
* `--report_to=wandb`
 å°†è®­ç»ƒç»“æœæŠ¥å‘Šå¹¶è®°å½•åˆ°æ‚¨çš„æƒé‡å’Œåå·®ä»ªè¡¨æ¿ï¼ˆä¾‹å¦‚ï¼Œçœ‹çœ‹è¿™ä¸ª
 [æŠ¥å‘Š](https://wandb.ai/pcuenq/text2image-fine-tune/runs/b4k1w0tn?workspace=user-pcuenq)
 ï¼‰ã€‚
* `--learning_rate=1e-04`
 ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ¯” LoRA é€šå¸¸æ›´é«˜çš„å­¦ä¹ ç‡ã€‚


ç°åœ¨æ‚¨å·²å‡†å¤‡å¥½å¯åŠ¨åŸ¹è®­ï¼ˆæ‚¨å¯ä»¥æ‰¾åˆ°å®Œæ•´çš„åŸ¹è®­è„šæœ¬
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)
 ï¼‰ã€‚åœ¨å…·æœ‰ 11GB RAM çš„ 2080 Ti GPU ä¸Šè¿›è¡Œè®­ç»ƒå¤§çº¦éœ€è¦ 5 ä¸ªå°æ—¶ï¼Œå®ƒå°†åˆ›å»ºå¹¶ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å’Œ
 `pytorch_lora_weights`
 åœ¨ä½ çš„å­˜å‚¨åº“ä¸­ã€‚



```
accelerate launch --mixed_precision="fp16"  train_text_to_image_lora.py   --pretrained_model_name_or_path=$MODEL\_NAME   --dataset_name=$DATASET\_NAME   --dataloader_num_workers=8   --resolution=512 --center_crop --random_flip   --train_batch_size=1   --gradient_accumulation_steps=4   --max_train_steps=15000   --learning_rate=1e-04   --max_grad_norm=1   --lr_scheduler="cosine" --lr_warmup_steps=0   --output_dir=${OUTPUT\_DIR}   --push_to_hub   --hub_model_id=${HUB\_MODEL\_ID}   --report_to=wandb   --checkpointing_steps=500   --validation_prompt="A pokemon with blue eyes."   --seed=1337
```


### 


 æ¨ç†


ç°åœ¨æ‚¨å¯ä»¥é€šè¿‡åœ¨ä¸­åŠ è½½åŸºç¡€æ¨¡å‹æ¥ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
 [StableDiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 ç„¶åæ˜¯
 [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)
 :



```
>>> import torch
>>> from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

>>> model_base = "runwayml/stable-diffusion-v1-5"

>>> pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16, use_safetensors=True)
>>> pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
```


ä»å¾®è°ƒæ¨¡å‹åŠ è½½ LoRA æƒé‡
 *åœ¨åŸºæœ¬æ¨¡å‹æƒé‡ä¹‹ä¸Š*
 ï¼Œç„¶åå°†ç®¡é“ç§»è‡³ GPU ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚å½“æ‚¨å°† LoRA æƒé‡ä¸å†»ç»“çš„é¢„è®­ç»ƒæ¨¡å‹æƒé‡åˆå¹¶æ—¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©è°ƒæ•´ä¸ LoRA æƒé‡åˆå¹¶çš„æƒé‡æ•°é‡ã€‚
 `è§„æ¨¡`
 èŒƒå›´ï¼š


ğŸ’¡A
 `è§„æ¨¡`
 çš„ä»·å€¼
 `0`
 ä¸ä¸ä½¿ç”¨ LoRA æƒé‡ç›¸åŒï¼Œæ‚¨ä»…ä½¿ç”¨åŸºæœ¬æ¨¡å‹æƒé‡ï¼Œå¹¶ä¸”
 `è§„æ¨¡`
 çš„ä»·å€¼
 `1`
 æ„å‘³ç€æ‚¨ä»…ä½¿ç”¨å®Œå…¨å¾®è°ƒçš„ LoRA æƒé‡ã€‚å€¼ä»‹äº
 `0`
 å’Œ
 `1`
 åœ¨ä¸¤ä¸ªæƒé‡ä¹‹é—´è¿›è¡Œæ’å€¼ã€‚



```
>>> pipe.unet.load_attn_procs(lora_model_path)
>>> pipe.to("cuda")
# use half the weights from the LoRA finetuned model and half the weights from the base model

>>> image = pipe(
...     "A pokemon with blue eyes.", num_inference_steps=25, guidance_scale=7.5, cross_attention_kwargs={"scale": 0.5}
... ).images[0]
# use the weights from the fully finetuned LoRA model

>>> image = pipe("A pokemon with blue eyes.", num_inference_steps=25, guidance_scale=7.5).images[0]
>>> image.save("blue\_pokemon.png")
```


å¦‚æœæ‚¨è¦ä» Hub åŠ è½½ LoRA å‚æ•°ï¼Œå¹¶ä¸” Hub å­˜å‚¨åº“æœ‰
A
 `åŸºç¡€æ¨¡å‹`
 æ ‡ç­¾ï¼ˆä¾‹å¦‚
 [è¿™ä¸ª](https://huggingface.co/sayakpaul/sd-model-finetuned-lora-t4/blob/main/README.md?code=true#L4)
 ï¼‰ï¼Œ ç„¶å
ä½ å¯ä»¥åšï¼š



```
from huggingface_hub.repocard import RepoCard

lora_model_id = "sayakpaul/sd-model-finetuned-lora-t4"
card = RepoCard.load(lora_model_id)
base_model_id = card.data.to_dict()["base\_model"]

pipe = StableDiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, use_safetensors=True)
...
```


## æ¢¦æƒ³å±•ä½



[DreamBooth](https://arxiv.org/abs/2208.12242)
 æ˜¯ä¸€ç§å¾®è°ƒæŠ€æœ¯ï¼Œç”¨äºä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼ˆä¾‹å¦‚ç¨³å®šæ‰©æ•£ï¼‰ï¼Œä»¥åœ¨ç»™å®šä¸»é¢˜çš„ä¸€äº›å›¾åƒçš„æƒ…å†µä¸‹ç”Ÿæˆä¸åŒä¸Šä¸‹æ–‡ä¸­ä¸»é¢˜çš„ç…§ç‰‡çº§çœŸå®æ„Ÿå›¾åƒã€‚ç„¶è€ŒDreamBoothå¯¹è¶…å‚æ•°éå¸¸æ•æ„Ÿï¼Œå¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆã€‚éœ€è¦è€ƒè™‘çš„ä¸€äº›é‡è¦è¶…å‚æ•°åŒ…æ‹¬å½±å“è®­ç»ƒæ—¶é—´ï¼ˆå­¦ä¹ ç‡ã€è®­ç»ƒæ­¥éª¤æ•°ï¼‰å’Œæ¨ç†æ—¶é—´ï¼ˆæ­¥éª¤æ•°ã€è°ƒåº¦ç¨‹åºç±»å‹ï¼‰çš„å‚æ•°ã€‚


ğŸ’¡ çœ‹çœ‹
 [ä½¿ç”¨ ğŸ§¨ æ‰©æ•£å™¨é€šè¿‡ DreamBooth è®­ç»ƒç¨³å®šæ‰©æ•£](https://huggingface.co/blog/dreambooth)
 åšå®¢æ·±å…¥åˆ†æ DreamBooth å®éªŒå’Œæ¨èè®¾ç½®ã€‚



### 


 è®­ç»ƒ


è®©æˆ‘ä»¬å¾®è°ƒä¸€ä¸‹
 [`stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 ä¸ DreamBooth å’Œ LoRA ä»¥åŠä¸€äº› ğŸ¶
 [ç‹—å›¾ç‰‡](https://drive.google.com/drive/folders/1BO_dyz-p65qhBRRMRA4TbZ8qW4rB99JZ)
 ã€‚ä¸‹è½½è¿™äº›å›¾åƒå¹¶å°†å…¶ä¿å­˜åˆ°ç›®å½•ä¸­ã€‚è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


é¦–å…ˆï¼ŒæŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚æ‚¨è¿˜éœ€è¦è®¾ç½®
 `INSTANCE_DIR`
 åˆ°åŒ…å«å›¾åƒçš„ç›®å½•çš„è·¯å¾„ã€‚


è¿™
 `è¾“å‡ºç›®å½•`
 å˜é‡æ˜¯å¯é€‰çš„ï¼ŒæŒ‡å®šåœ¨ Hub ä¸Šä¿å­˜æ¨¡å‹çš„ä½ç½®ï¼š



```
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export INSTANCE_DIR="path-to-instance-images"
export OUTPUT_DIR="path-to-save-model"
```


åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œéœ€è¦æ³¨æ„ä¸€äº›æ ‡å¿—ï¼š


* `--push_to_hub`
 å°†ç»è¿‡è®­ç»ƒçš„ LoRA åµŒå…¥å­˜å‚¨åœ¨ Hub ä¸Šã€‚
* `--report_to=wandb`
 å°†è®­ç»ƒç»“æœæŠ¥å‘Šå¹¶è®°å½•åˆ°æ‚¨çš„æƒé‡å’Œåå·®ä»ªè¡¨æ¿ï¼ˆä¾‹å¦‚ï¼Œçœ‹çœ‹è¿™ä¸ª
 [æŠ¥å‘Š](https://wandb.ai/pcuenq/text2image-fine-tune/runs/b4k1w0tn?workspace=user-pcuenq)
 ï¼‰ã€‚
* `--learning_rate=1e-04`
 ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ¯” LoRA é€šå¸¸æ›´é«˜çš„å­¦ä¹ ç‡ã€‚


ç°åœ¨æ‚¨å·²å‡†å¤‡å¥½å¯åŠ¨åŸ¹è®­ï¼ˆæ‚¨å¯ä»¥æ‰¾åˆ°å®Œæ•´çš„åŸ¹è®­è„šæœ¬
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)
 ï¼‰ã€‚è¯¥è„šæœ¬åˆ›å»ºå¹¶ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹å’Œ
 `pytorch_lora_weights.bin`
 æ–‡ä»¶åœ¨æ‚¨çš„å­˜å‚¨åº“ä¸­ã€‚


è¿˜å¯ä»¥ä½¿ç”¨ LoRA å¯¹æ–‡æœ¬ç¼–ç å™¨è¿›è¡Œé¢å¤–å¾®è°ƒã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™ä¼šå¯¼è‡´
é€šè¿‡ç¨å¾®å¢åŠ è®¡ç®—é‡æ¥è·å¾—æ›´å¥½çš„ç»“æœã€‚ä¸ºäº†å…è®¸ä½¿ç”¨ LoRA å¾®è°ƒæ–‡æœ¬ç¼–ç å™¨ï¼Œ
æŒ‡å®š
 `--train_text_encoder`
 åŒæ—¶å¯åŠ¨
 `train_dreambooth_lora.py`
 è„šæœ¬ã€‚



```
accelerate launch train_dreambooth_lora.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a photo of sks dog"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=1   --checkpointing_steps=100   --learning_rate=1e-4   --report_to="wandb"   --lr_scheduler="constant"   --lr_warmup_steps=0   --max_train_steps=500   --validation_prompt="A photo of sks dog in a bucket"   --validation_epochs=50   --seed="0"   --push_to_hub
```


### 


 æ¨ç†


ç°åœ¨æ‚¨å¯ä»¥é€šè¿‡åœ¨ä¸­åŠ è½½åŸºç¡€æ¨¡å‹æ¥ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†
 [StableDiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 :



```
>>> import torch
>>> from diffusers import StableDiffusionPipeline

>>> model_base = "runwayml/stable-diffusion-v1-5"

>>> pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16, use_safetensors=True)
```


ä»å¾®è°ƒçš„ DreamBooth æ¨¡å‹åŠ è½½ LoRA æƒé‡
 *åœ¨åŸºæœ¬æ¨¡å‹æƒé‡ä¹‹ä¸Š*
 ï¼Œç„¶åå°†ç®¡é“ç§»è‡³ GPU ä»¥åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚å½“æ‚¨å°† LoRA æƒé‡ä¸å†»ç»“çš„é¢„è®­ç»ƒæ¨¡å‹æƒé‡åˆå¹¶æ—¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©è°ƒæ•´ä¸ LoRA æƒé‡åˆå¹¶çš„æƒé‡æ•°é‡ã€‚
 `è§„æ¨¡`
 èŒƒå›´ï¼š


ğŸ’¡A
 `è§„æ¨¡`
 çš„ä»·å€¼
 `0`
 ä¸ä¸ä½¿ç”¨ LoRA æƒé‡ç›¸åŒï¼Œæ‚¨ä»…ä½¿ç”¨åŸºæœ¬æ¨¡å‹æƒé‡ï¼Œå¹¶ä¸”
 `è§„æ¨¡`
 çš„ä»·å€¼
 `1`
 æ„å‘³ç€æ‚¨ä»…ä½¿ç”¨å®Œå…¨å¾®è°ƒçš„ LoRA æƒé‡ã€‚å€¼ä»‹äº
 `0`
 å’Œ
 `1`
 åœ¨ä¸¤ä¸ªæƒé‡ä¹‹é—´è¿›è¡Œæ’å€¼ã€‚



```
>>> pipe.unet.load_attn_procs(lora_model_path)
>>> pipe.to("cuda")
# use half the weights from the LoRA finetuned model and half the weights from the base model

>>> image = pipe(
...     "A picture of a sks dog in a bucket.",
...     num_inference_steps=25,
...     guidance_scale=7.5,
...     cross_attention_kwargs={"scale": 0.5},
... ).images[0]
# use the weights from the fully finetuned LoRA model

>>> image = pipe("A picture of a sks dog in a bucket.", num_inference_steps=25, guidance_scale=7.5).images[0]
>>> image.save("bucket-dog.png")
```


å¦‚æœä½ ç”¨è¿‡
 `--train_text_encoder`
 åœ¨è®­ç»ƒæœŸé—´ï¼Œç„¶åä½¿ç”¨
 `pipe.load_lora_weights()`
 åŠ è½½ LoRA
é‡é‡ã€‚ä¾‹å¦‚ï¼š



```
from huggingface_hub.repocard import RepoCard
from diffusers import StableDiffusionPipeline
import torch

lora_model_id = "sayakpaul/dreambooth-text-encoder-test"
card = RepoCard.load(lora_model_id)
base_model_id = card.data.to_dict()["base\_model"]

pipe = StableDiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, use_safetensors=True)
pipe = pipe.to("cuda")
pipe.load_lora_weights(lora_model_id)
image = pipe("A picture of a sks dog in a bucket", num_inference_steps=25).images[0]
```


å¦‚æœæ‚¨çš„ LoRA å‚æ•°æ¶‰åŠ UNet ä»¥åŠæ–‡æœ¬ç¼–ç å™¨ï¼Œåˆ™ä¼ é€’
 `cross_attention_kwargs={"scale": 0.5}`
 å°†åº”ç”¨
 `è§„æ¨¡`
 å¯¹ UNet çš„ä»·å€¼
å’Œæ–‡æœ¬ç¼–ç å™¨ã€‚


è¯·æ³¨æ„ï¼Œä½¿ç”¨
 [load\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.load_lora_weights)
 ä¼˜å…ˆäº
 [load\_attn\_procs()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.UNet2DConditionLoadersMixin.load_attn_procs)
 ç”¨äºåŠ è½½ LoRA å‚æ•°ã€‚è¿™æ˜¯å› ä¸º
 [load\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.load_lora_weights)
 å¯ä»¥å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š


* LoRA å‚æ•°æ²¡æœ‰å•ç‹¬çš„ UNet å’Œæ–‡æœ¬ç¼–ç å™¨æ ‡è¯†ç¬¦ï¼ˆä¾‹å¦‚
 [`"patrickvonplaten/lora_dreambooth_dog_example"`](https://huggingface.co/patrickvonplaten/lora_dreambooth_dog_example)
 ï¼‰ã€‚æ‰€ä»¥ï¼Œä½ å¯ä»¥è¿™æ ·åšï¼š



```
pipe.load_lora_weights(lora_model_path)
```
* LoRA parameters that have separate identifiers for the UNet and the text encoder such as:
 `"sayakpaul/dreambooth"`
 .


æ‚¨è¿˜å¯ä»¥æä¾›æœ¬åœ°ç›®å½•è·¯å¾„
 [load\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.load_lora_weights)
 ä¹Ÿ
 [load\_attn\_procs()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.UNet2DConditionLoadersMixin.load_attn_procs)
 ã€‚


## ç¨³å®šæ‰©æ•£XL



æˆ‘ä»¬æ”¯æŒå¾®è°ƒ
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 ã€‚è¯·å‚è€ƒä»¥ä¸‹æ–‡æ¡£ï¼š


* [text\_to\_image/README\_sdxl.md](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/README_sdxl.md)
* [dreambooth/README\_sdxl.md](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_sdxl.md)


## å¸è½½LoRAå‚æ•°



æ‚¨å¯ä»¥è‡´ç”µ
 [å¸è½½\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.LoraLoaderMixin.unload_lora_weights)
 åœ¨ç®¡é“ä¸Šå¸è½½ LoRA å‚æ•°ã€‚


## èåˆLoRAå‚æ•°



æ‚¨å¯ä»¥è‡´ç”µ
 [fuse\_lora()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.LoraLoaderMixin.fuse_lora)
 åœ¨ç®¡é“ä¸Šå°† LoRA å‚æ•°ä¸åº•å±‚æ¨¡å‹çš„åŸå§‹å‚æ•°åˆå¹¶ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´æ¨ç†å»¶è¿Ÿçš„æ½œåœ¨åŠ é€Ÿã€‚


## è§£é™¤ LoRA å‚æ•°èåˆ



æ’¤é”€
 `ä¿é™©ä¸åŠ³æ‹‰`
 ï¼Œ ç§°å‘¼
 [unfuse\_lora()](/docs/diffusers/v0.23.0/en/api/loaders#diffusers.loaders.LoraLoaderMixin.unfuse_lora)
 åœ¨ç®¡é“ä¸Šã€‚


## ä½¿ç”¨ LoRA èåˆæ—¶ä½¿ç”¨ä¸åŒçš„ LoRA è§„æ¨¡



å¦‚æœæ‚¨éœ€è¦ä½¿ç”¨
 `è§„æ¨¡`
 å½“ä¸
 `fuse_lora()`
 è¦æ§åˆ¶ LoRA å‚æ•°å¯¹è¾“å‡ºçš„å½±å“ï¼Œæ‚¨åº”è¯¥æŒ‡å®š
 `lora_scale`
 ä¹‹å†…
 `fuse_lora()`
 ã€‚é€šè¿‡
 `è§„æ¨¡`
 å‚æ•°ä¸º
 `cross_attention_kwargs`
 å½“ä½ è°ƒç”¨ç®¡é“æ—¶å°†æ— æ³•å·¥ä½œã€‚


è¦ä½¿ç”¨ä¸åŒçš„
 `lora_scale`
 å’Œ
 `fuse_lora()`
 ï¼Œä½ åº”è¯¥å…ˆæ‰“ç”µè¯
 `unfuse_lora()`
 åœ¨ç›¸åº”çš„ç®¡é“ä¸Šå¹¶è°ƒç”¨
 `fuse_lora()`
 å†æ¬¡ä¸é¢„æœŸ
 `lora_scale`
 ã€‚



```
from diffusers import DiffusionPipeline
import torch 

pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
lora_model_id = "hf-internal-testing/sdxl-1.0-lora"
lora_filename = "sd\_xl\_offset\_example-lora\_1.0.safetensors"
pipe.load_lora_weights(lora_model_id, weight_name=lora_filename)

# This uses a default `lora\_scale` of 1.0.
pipe.fuse_lora()

generator = torch.manual_seed(0)
images_fusion = pipe(
    "masterpiece, best quality, mountain", generator=generator, num_inference_steps=2
).images

# To work with a different `lora\_scale`, first reverse the effects of `fuse\_lora()`.
pipe.unfuse_lora()

# Then proceed as follows.
pipe.load_lora_weights(lora_model_id, weight_name=lora_filename)
pipe.fuse_lora(lora_scale=0.5)

generator = torch.manual_seed(0)
images_fusion = pipe(
    "masterpiece, best quality, mountain", generator=generator, num_inference_steps=2
).images
```


## ä½¿ç”¨èåˆ LoRA å‚æ•°åºåˆ—åŒ–ç®¡é“



å‡è®¾æ‚¨æƒ³è¦åŠ è½½ä¸Šé¢çš„ç®¡é“ï¼Œå…¶ UNet ä¸ LoRA å‚æ•°èåˆã€‚æ‚¨åªéœ€è°ƒç”¨
 `save_pretrained()`
 æ–¹æ³•ä¸Š
 `ç®¡é“`
 ã€‚


å°† LoRA å‚æ•°åŠ è½½åˆ°ç®¡é“åï¼Œå¦‚æœæ‚¨æƒ³è¦åºåˆ—åŒ–ç®¡é“ä»¥ä½¿å—å½±å“çš„æ¨¡å‹ç»„ä»¶å·²ç»ä¸ LoRA å‚æ•°èåˆï¼Œæ‚¨åº”è¯¥ï¼š


* ç§°å‘¼
 `fuse_lora()`
 åœ¨ç®¡é“ä¸Šä¸æ‰€éœ€çš„
 `lora_scale`
 ï¼Œå‰ææ˜¯æ‚¨å·²ç»å°† LoRA å‚æ•°åŠ è½½åˆ°å…¶ä¸­ã€‚
* ç§°å‘¼
 `save_pretrained()`
 åœ¨ç®¡é“ä¸Šã€‚


è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­ï¼š



```
from diffusers import DiffusionPipeline
import torch 

pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")
lora_model_id = "hf-internal-testing/sdxl-1.0-lora"
lora_filename = "sd\_xl\_offset\_example-lora\_1.0.safetensors"
pipe.load_lora_weights(lora_model_id, weight_name=lora_filename)

# First, fuse the LoRA parameters.
pipe.fuse_lora()

# Then save.
pipe.save_pretrained("my-pipeline-with-fused-lora")
```


ç°åœ¨ï¼Œæ‚¨å¯ä»¥åŠ è½½ç®¡é“å¹¶ç›´æ¥æ‰§è¡Œæ¨ç†ï¼Œè€Œæ— éœ€å†æ¬¡åŠ è½½LoRAå‚æ•°ï¼š



```
from diffusers import DiffusionPipeline
import torch 

pipe = DiffusionPipeline.from_pretrained("my-pipeline-with-fused-lora", torch_dtype=torch.float16).to("cuda")

generator = torch.manual_seed(0)
images_fusion = pipe(
    "masterpiece, best quality, mountain", generator=generator, num_inference_steps=2
).images
```


## ä½¿ç”¨å¤šä¸ª LoRA æ£€æŸ¥ç‚¹



éšç€
 `fuse_lora()`
 å¦‚ä¸Šæ‰€è¿°çš„æ–¹æ³•ï¼Œå¯ä»¥åŠ è½½å¤šä¸ªLoRAæ£€æŸ¥ç‚¹ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­ã€‚é¦–å…ˆæˆ‘ä»¬åŠ è½½åŸºç¡€ç®¡é“ï¼š



```
from diffusers import StableDiffusionXLPipeline, AutoencoderKL
import torch

vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=torch.float16)
pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    vae=vae,
    torch_dtype=torch.float16,
)
pipe.to("cuda")
```


ç„¶åè®©æˆ‘ä»¬ä¸¤ä¸ª LoRA æ£€æŸ¥ç‚¹å¹¶å°†å®ƒä»¬ä¸ç‰¹å®šçš„èåˆ
 `lora_scale`
 ä»·å€¼è§‚ï¼š



```
# LoRA one.
pipe.load_lora_weights("goofyai/cyborg\_style\_xl")
pipe.fuse_lora(lora_scale=0.7)

# LoRA two.
pipe.load_lora_weights("TheLastBen/Pikachu\_SDXL")
pipe.fuse_lora(lora_scale=0.7)
```


ç©
 `lora_scale`
 ä¸å¤šä¸ª LoRA ä¸€èµ·ä½¿ç”¨æ—¶çš„å‚æ•°ï¼Œä»¥æ§åˆ¶å®ƒä»¬å¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ç¨‹åº¦ã€‚


è®©æˆ‘ä»¬çœ‹çœ‹ä»–ä»¬çš„å®é™…è¡ŒåŠ¨ï¼š



```
prompt = "cyborg style pikachu"
image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
```


![cyborg_pikachu](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/cyborg_pikachu.png)


 ç›®å‰ï¼Œå–æ¶ˆå¤šä¸ª LoRA æ£€æŸ¥ç‚¹çš„èåˆæ˜¯ä¸å¯èƒ½çš„ã€‚


## æ”¯æŒ Diffusers çš„ä¸åŒ LoRA æ£€æŸ¥ç‚¹



ğŸ¤— Diffusers æ”¯æŒä»æµè¡Œçš„ LoRA è®­ç»ƒå™¨åŠ è½½æ£€æŸ¥ç‚¹ï¼Œä¾‹å¦‚
 [Kohya](https://github.com/kohya-ss/sd-scripts/)
 å’Œ
 [TheLastBen](https://github.com/TheLastBen/fast-stable-diffusion)
 ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æ¦‚è¿°äº†å½“å‰ API çš„è¯¦ç»†ä¿¡æ¯å’Œé™åˆ¶ã€‚


### 


 ç§‘äºš


è¿™ç§æ”¯æŒä¹‹æ‰€ä»¥æˆä¸ºå¯èƒ½ï¼Œæ˜¯å› ä¸ºæœ‰å‡ºè‰²çš„è´¡çŒ®è€…ï¼š
 [@takuma104](https://github.com/takuma104)
 å’Œ
 [@isidentical](https://github.com/isidentical)
 ã€‚


æˆ‘ä»¬æ”¯æŒä½¿ç”¨ä»¥ä¸‹æ–¹å¼åŠ è½½ Kohya LoRA æ£€æŸ¥ç‚¹
 [load\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.load_lora_weights)
 ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è§£é‡Šå¦‚ä½•ä»åŠ è½½è¿™æ ·çš„æ£€æŸ¥ç‚¹
 [CivitAI](https://civitai.com/)
 åœ¨ Diffusers ä¸­å¹¶ç”¨å®ƒè¿›è¡Œæ¨ç†ã€‚


é¦–å…ˆï¼Œä¸‹è½½æ£€æŸ¥ç‚¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨
 [è¿™ä¸ª](https://civitai.com/models/13239/light-and-shadow)
 å‡ºäºæ¼”ç¤ºç›®çš„ã€‚



```
wget https://civitai.com/api/download/models/15603 -O light_and_shadow.safetensors
```


æ¥ä¸‹æ¥æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ª
 [~DiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 :



```
import torch

from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

pipeline = StableDiffusionPipeline.from_pretrained(
    "gsdf/Counterfeit-V2.5", torch_dtype=torch.float16, safety_checker=None, use_safetensors=True
).to("cuda")
pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
    pipeline.scheduler.config, use_karras_sigmas=True
)
```


ç„¶åæˆ‘ä»¬åŠ è½½ä» CivitAI ä¸‹è½½çš„æ£€æŸ¥ç‚¹ï¼š



```
pipeline.load_lora_weights(".", weight_name="light\_and\_shadow.safetensors")
```


å¦‚æœæ‚¨æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹
 `å®‰å…¨å¼ é‡`
 æ ¼å¼ï¼Œè¯·ç¡®ä¿æ‚¨æœ‰
 `å®‰å…¨å¼ é‡`
 å®‰è£…ã€‚


ç„¶åæ˜¯è¿è¡Œæ¨ç†çš„æ—¶å€™äº†ï¼š



```
prompt = "masterpiece, best quality, 1girl, at dusk"
negative_prompt = ("(low quality, worst quality:1.4), (bad anatomy), (inaccurate limb:1.2), "
                   "bad composition, inaccurate eyes, extra digit, fewer digits, (extra arms:1.2), large breasts")

images = pipeline(prompt=prompt, 
    negative_prompt=negative_prompt, 
    width=512, 
    height=768, 
    num_inference_steps=15, 
    num_images_per_prompt=4,
    generator=torch.manual_seed(0)
).images
```


ä¸‹é¢æ˜¯ LoRA å’Œé LoRA ç»“æœä¹‹é—´çš„æ¯”è¾ƒï¼š


![lora_non_lora](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lora_non_lora_comparison.png)


æ‚¨åœ¨ Hugging Face Hub ä¸Šå­˜å‚¨äº†ä¸€ä¸ªç±»ä¼¼çš„æ£€æŸ¥ç‚¹ï¼Œæ‚¨å¯ä»¥åŠ è½½å®ƒ
ç›´æ¥ä¸
 [load\_lora\_weights()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.load_lora_weights)
 åƒè¿™æ ·ï¼š



```
lora_model_id = "sayakpaul/civitai-light-shadow-lora"
lora_filename = "light\_and\_shadow.safetensors"
pipeline.load_lora_weights(lora_model_id, weight_name=lora_filename)
```


### 


 Kohya + ç¨³å®šæ‰©æ•£ XL


å‘å¸ƒå
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 ï¼Œç¤¾åŒºè´¡çŒ®äº†ä¸€äº›ä»¤äººæƒŠå¹çš„ LoRA æ£€æŸ¥ç‚¹ï¼Œå¹¶åœ¨ Kohya è®­ç»ƒå™¨çš„åŸºç¡€ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚


ä»¥ä¸‹æ˜¯æˆ‘ä»¬å°è¯•è¿‡çš„ä¸€äº›æ£€æŸ¥ç‚¹ç¤ºä¾‹ï¼š


* SDXL 0.9ï¼š
+ <https://civitai.com/models/22279?modelVersionId=118556>
+ <https://civitai.com/models/104515/sdxlor30costumesrevue-starlight-saijoclaudine-lora>
+ <https://civitai.com/models/108448/daiton-sdxl-test>
+ <https://filebin.net/2ntfqqnapiu9q3zx/pixelbuildings128-v1.safetensors>
* SDXL 1.0ï¼š
+ <https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_offset_example-lora_1.0.safetensors>


ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨è¿™äº›æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†çš„ç¤ºä¾‹
 `æ‰©æ•£å™¨`
 :



```
from diffusers import DiffusionPipeline
import torch 

base_model_id = "stabilityai/stable-diffusion-xl-base-0.9"
pipeline = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16).to("cuda")
pipeline.load_lora_weights(".", weight_name="Kamepan.safetensors")

prompt = "anime screencap, glint, drawing, best quality, light smile, shy, a full body of a girl wearing wedding dress in the middle of the forest beneath the trees, fireflies, big eyes, 2d, cute, anime girl, waifu, cel shading, magical girl, vivid colors, (outline:1.1), manga anime artstyle, masterpiece, official wallpaper, glint <lora:kame\_sdxl\_v2:1>"
negative_prompt = "(deformed, bad quality, sketch, depth of field, blurry:1.1), grainy, bad anatomy, bad perspective, old, ugly, realistic, cartoon, disney, bad proportions"
generator = torch.manual_seed(2947883060)
num_inference_steps = 30
guidance_scale = 7

image = pipeline(
    prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps,
    generator=generator, guidance_scale=guidance_scale
).images[0]
image.save("Kamepan.png")
```


`Kamepan.safetensors`
 æ¥è‡ª
 <https://civitai.com/models/22279?modelVersionId=118556>
 ã€‚


å¦‚æœæ‚¨ä»”ç»†è§‚å¯Ÿï¼Œæ¨ç†ç”¨æˆ·ä½“éªŒä¸æˆ‘ä»¬åœ¨ä¸Šé¢éƒ¨åˆ†ä¸­ä»‹ç»çš„å®Œå…¨ç›¸åŒã€‚


è°¢è°¢
 [@isidentical](https://github.com/isidentical)
 å¸®åŠ©æˆ‘ä»¬é›†æˆæ­¤åŠŸèƒ½ã€‚


**ç‰¹å®šäº Kohya LoRA çš„å·²çŸ¥é™åˆ¶**
 :


* å½“å›¾åƒçœ‹èµ·æ¥ä¸å…¶ä»– UIï¼ˆä¾‹å¦‚ ComfyUIï¼‰ä¸ç›¸ä¼¼æ—¶ï¼Œå¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› é€ æˆçš„ï¼Œå¦‚æ‰€è§£é‡Šçš„
 [æ­¤å¤„](https://github.com/huggingface/diffusers/pull/4287/#issuecomment-1655110736)
 ã€‚
* æˆ‘ä»¬ä¸å®Œå…¨æ”¯æŒ
 [LyCORIS æ£€æŸ¥ç‚¹](https://github.com/KohakuBlueleaf/LyCORIS)
 ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬ç›®å‰
 `load_lora_weights()`
 åº”æ”¯æŒå…·æœ‰ LoRA å’Œ LoCon æ¨¡å—çš„ LyCORIS æ£€æŸ¥ç‚¹ï¼Œä½†ä¸æ”¯æŒå…¶ä»–æ¨¡å—ï¼Œä¾‹å¦‚ Hadaã€LoKR ç­‰ã€‚



### 


 æœ€åçš„æœ¬


è¿™æ˜¯ä¸€ä¸ªä¾‹å­ï¼š



```
from diffusers import DiffusionPipeline
import torch

pipeline_id = "Lykon/dreamshaper-xl-1-0"

pipe = DiffusionPipeline.from_pretrained(pipeline_id, torch_dtype=torch.float16)
pipe.enable_model_cpu_offload()

lora_model_id = "TheLastBen/Papercut\_SDXL"
lora_filename = "papercut.safetensors"
pipe.load_lora_weights(lora_model_id, weight_name=lora_filename)

prompt = "papercut sonic"
image = pipe(prompt=prompt, num_inference_steps=20, generator=torch.manual_seed(0)).images[0]
image
```