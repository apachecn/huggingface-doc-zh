# æ–‡æœ¬å€’è£…

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/text_inversion>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/text_inversion>


[æ–‡æœ¬å€’ç½®](https://arxiv.org/abs/2208.01618)
 æ˜¯ä¸€ç§ä»å°‘é‡ç¤ºä¾‹å›¾åƒä¸­æ•è·æ–°é¢–æ¦‚å¿µçš„æŠ€æœ¯ã€‚è™½ç„¶è¯¥æŠ€æœ¯æœ€åˆæ˜¯é€šè¿‡
 [æ½œåœ¨æ‰©æ•£æ¨¡å‹](https://github.com/CompVis/latent-diffusion)
 ï¼Œæ­¤åå®ƒå·²è¢«åº”ç”¨äºå…¶ä»–æ¨¡å‹å˜ä½“ï¼Œä¾‹å¦‚
 [ç¨³å®šæ‰©æ•£](https://huggingface.co/docs/diffusers/main/en/conceptual/stable_diffusion)
 ã€‚å­¦ä¹ åˆ°çš„æ¦‚å¿µå¯ç”¨äºæ›´å¥½åœ°æ§åˆ¶ä»æ–‡æœ¬åˆ°å›¾åƒç®¡é“ç”Ÿæˆçš„å›¾åƒã€‚å®ƒåœ¨æ–‡æœ¬ç¼–ç å™¨çš„åµŒå…¥ç©ºé—´ä¸­å­¦ä¹ æ–°çš„â€œå•è¯â€ï¼Œè¿™äº›å•è¯åœ¨æ–‡æœ¬æç¤ºä¸­ä½¿ç”¨ä»¥ç”Ÿæˆä¸ªæ€§åŒ–å›¾åƒã€‚


![æ–‡æœ¬åè½¬ç¤ºä¾‹](https://textual-inversion.github.io/static/images/editing/colorful_teapot.JPG)


åªéœ€ä½¿ç”¨ 3-5 å¼ å›¾åƒï¼Œæ‚¨å°±å¯ä»¥å‘æ¨¡å‹æ•™æˆæ–°æ¦‚å¿µï¼Œä¾‹å¦‚ç”¨äºç”Ÿæˆä¸ªæ€§åŒ–å›¾åƒçš„ç¨³å®šæ‰©æ•£
 [ï¼ˆå›¾ç‰‡æ¥æºï¼‰]ï¼ˆhttps://github.com/rinongal/textual_inversionï¼‰
 ã€‚
 

 æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•è®­ç»ƒ
 [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 å…·æœ‰æ–‡æœ¬åè½¬çš„æ¨¡å‹ã€‚æœ¬æŒ‡å—ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ–‡æœ¬åè½¬è®­ç»ƒè„šæœ¬éƒ½å¯ä»¥æ‰¾åˆ°
 [æ­¤å¤„](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion)
 å¦‚æœæ‚¨æœ‰å…´è¶£ä»”ç»†äº†è§£äº‹ç‰©çš„å¹•åå·¥ä½œåŸç†ã€‚


æœ‰ä¸€ä¸ªç¤¾åŒºåˆ›å»ºçš„è®­ç»ƒæœ‰ç´ çš„æ–‡æœ¬åè½¬æ¨¡å‹é›†åˆ
 [ç¨³å®šæ‰©æ•£æ–‡æœ¬åè½¬æ¦‚å¿µåº“](https://huggingface.co/sd-concepts-library)
 å¾ˆå®¹æ˜“ç”¨äºæ¨æ–­ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œéšç€æ›´å¤šæ¦‚å¿µçš„æ·»åŠ ï¼Œè¿™å°†æœ‰æœ›æˆä¸ºæœ‰ç”¨çš„èµ„æºï¼


åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…äº†åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š



```
pip install diffusers accelerate transformers
```


è®¾ç½®å®Œæ‰€æœ‰ä¾èµ–é¡¹åï¼Œåˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤—åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


è¦è®¾ç½®é»˜è®¤ğŸ¤—åŠ é€Ÿç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒç¬”è®°æœ¬ç­‰äº¤äº’å¼ shellï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š



```
from accelerate.utils import write_basic_config

write_basic_config()
```


æœ€åï¼Œä½ å°è¯•å¹¶
 [å®‰è£… xFormers](https://huggingface.co/docs/diffusers/main/en/training/optimization/xformers)
 é€šè¿‡ xFormers å†…å­˜é«˜æ•ˆå…³æ³¨æ¥å‡å°‘å†…å­˜å ç”¨ã€‚å®‰è£… xFormers åï¼Œæ·»åŠ 
 `--enable_xformers_memory_efficient_attention`
 è®­ç»ƒè„šæœ¬çš„å‚æ•°ã€‚ Flax ä¸æ”¯æŒ xFormersã€‚


## å°†æ¨¡å‹ä¸Šä¼ åˆ° Hub



å¦‚æœè¦å°†æ¨¡å‹å­˜å‚¨åœ¨ Hub ä¸Šï¼Œè¯·å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°è®­ç»ƒè„šæœ¬ä¸­ï¼š



```
--push_to_hub
```


## ä¿å­˜å’ŒåŠ è½½æ£€æŸ¥ç‚¹



åœ¨è®­ç»ƒæœŸé—´å®šæœŸä¿å­˜æ¨¡å‹çš„æ£€æŸ¥ç‚¹é€šå¸¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚è¿™æ ·ï¼Œå¦‚æœæ‚¨çš„è®­ç»ƒå› ä»»ä½•åŸå› ä¸­æ–­ï¼Œæ‚¨å¯ä»¥ä»ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚è¦ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œè¯·å°†ä»¥ä¸‹å‚æ•°ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ï¼Œä»¥å°†å®Œæ•´çš„è®­ç»ƒçŠ¶æ€ä¿å­˜åœ¨ä»¥ä¸‹ä½ç½®çš„å­æ–‡ä»¶å¤¹ä¸­ï¼š
 `è¾“å‡ºç›®å½•`
 æ¯ 500 æ­¥ï¼š



```
--checkpointing_steps=500
```


è¦ä»ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œè¯·å°†ä»¥ä¸‹å‚æ•°ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ä»¥åŠæ‚¨è¦ä»ä¸­æ¢å¤çš„ç‰¹å®šæ£€æŸ¥ç‚¹ï¼š



```
--resume_from_checkpoint="checkpoint-1500"
```


## å¾®è°ƒ



å¯¹äºæ‚¨çš„è®­ç»ƒæ•°æ®é›†ï¼Œè¯·ä¸‹è½½è¿™äº›
 [çŒ«ç©å…·çš„å›¾åƒ](https://huggingface.co/datasets/diffusers/cat_toy_example)
 å¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªç›®å½•ä¸­ã€‚è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚



```
from huggingface_hub import snapshot_download

local_dir = "./cat"
snapshot_download(
    "diffusers/cat\_toy\_example", local_dir=local_dir, repo_type="dataset", ignore_patterns=".gitattributes"
)
```


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 è®ºè¯ï¼Œä»¥åŠ
 `æ•°æ®ç›®å½•`
 ç¯å¢ƒå˜é‡åˆ°åŒ…å«å›¾åƒçš„ç›®å½•çš„è·¯å¾„ã€‚


ç°åœ¨æ‚¨å¯ä»¥å¯åŠ¨
 [è®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion.py)
 ã€‚è¯¥è„šæœ¬åˆ›å»ºä»¥ä¸‹æ–‡ä»¶å¹¶å°†å…¶ä¿å­˜åˆ°æ‚¨çš„å­˜å‚¨åº“ä¸­ï¼š
 `learned_embeds.bin`
 ,
 `token_identifier.txt`
 ï¼Œ å’Œ
 `type_of_concept.txt`
 ã€‚


ğŸ’¡ åœ¨ä¸€ä¸ª V100 GPU ä¸Šå®Œæ•´çš„è®­ç»ƒè¿è¡Œå¤§çº¦éœ€è¦ 1 å°æ—¶ã€‚å½“æ‚¨ç­‰å¾…åŸ¹è®­å®Œæˆæ—¶ï¼Œè¯·éšæ—¶æŸ¥çœ‹
 [æ–‡æœ¬å€’ç½®çš„å·¥ä½œåŸç†](#how-it-works)
 å¦‚æœæ‚¨å¥½å¥‡çš„è¯ï¼Œè¯·åœ¨ä¸‹é¢çš„éƒ¨åˆ†ä¸­æŸ¥çœ‹ï¼


 ç«ç‚¬


éšè— Pytorch å†…å®¹



```
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export DATA_DIR="./cat"

accelerate launch textual_inversion.py   --pretrained_model_name_or_path=$MODEL\_NAME   --train_data_dir=$DATA\_DIR   --learnable_property="object"   --placeholder_token="<cat-toy>" --initializer_token="toy"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=4   --max_train_steps=3000   --learning_rate=5.0e-04 --scale_lr   --lr_scheduler="constant"   --lr_warmup_steps=0   --output_dir="textual\_inversion\_cat"   --push_to_hub
```


ğŸ’¡å¦‚æœä½ æƒ³å¢åŠ å¯è®­ç»ƒå®¹é‡ï¼Œä½ å¯ä»¥å…³è”ä½ çš„å ä½ç¬¦tokenï¼Œ
 *ä¾‹å¦‚ã€‚*
`<çŒ«ç©å…·>`
 åˆ°
å¤šä¸ªåµŒå…¥å‘é‡ã€‚è¿™å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ•æ‰æ›´å¤šï¼ˆå¤æ‚ï¼‰å›¾åƒçš„é£æ ¼ã€‚
è¦è®­â€‹â€‹ç»ƒå¤šä¸ªåµŒå…¥å‘é‡ï¼Œåªéœ€ä¼ é€’ï¼š



```
--num_vectors=5
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹


å¦‚æœæ‚¨å¯ä»¥ä½¿ç”¨ TPUï¼Œè¯·å°è¯•
 [Flaxè®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion_flax.py)
 è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼ˆè¿™ä¹Ÿé€‚ç”¨äº GPUï¼‰ã€‚åœ¨ç›¸åŒçš„é…ç½®è®¾ç½®ä¸‹ï¼ŒFlax è®­ç»ƒè„šæœ¬åº”è¯¥æ¯” PyTorch è®­ç»ƒè„šæœ¬è‡³å°‘å¿« 70%ï¼ âš¡ï¸


åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…äº† Flax ç‰¹å®šçš„ä¾èµ–é¡¹ï¼š



```
pip install -U -r requirements_flax.txt
```


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 [`pretrained_model_name_or_path`](https://huggingface.co/docs/diffusers/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path)
 äº‰è®ºã€‚


ç„¶åä½ å°±å¯ä»¥å¯åŠ¨
 [è®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/textual_inversion/textual_inversion_flax.py)
 :



```
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export DATA_DIR="./cat"

python textual_inversion_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME   --train_data_dir=$DATA\_DIR   --learnable_property="object"   --placeholder_token="<cat-toy>" --initializer_token="toy"   --resolution=512   --train_batch_size=1   --max_train_steps=3000   --learning_rate=5.0e-04 --scale_lr   --output_dir="textual\_inversion\_cat"   --push_to_hub
```


### 


 ä¸­çº§è®°å½•


å¦‚æœæ‚¨æœ‰å…´è¶£è·Ÿè¸ªæ¨¡å‹è®­ç»ƒè¿›åº¦ï¼Œå¯ä»¥ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„å›¾åƒã€‚å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°è®­ç»ƒè„šæœ¬ä»¥å¯ç”¨ä¸­é—´æ—¥å¿—è®°å½•ï¼š


* `éªŒè¯æç¤º`
 ï¼Œç”¨äºç”Ÿæˆæ ·æœ¬çš„æç¤ºï¼ˆè®¾ç½®ä¸º
 `æ— `
 é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸­é—´æ—¥å¿—è®°å½•è¢«ç¦ç”¨ï¼‰
* `num_validation_images`
 ï¼Œè¦ç”Ÿæˆçš„æ ·æœ¬å›¾åƒçš„æ•°é‡
* `éªŒè¯æ­¥éª¤`
 , ç”Ÿæˆå‰çš„æ­¥æ•°
 `num_validation_images`
 æ¥è‡ª
 `éªŒè¯æç¤º`



```
--validation_prompt="A <cat-toy> backpack"
--num_validation_images=4
--validation_steps=100
```


## æ¨ç†



è®­ç»ƒå®Œæ¨¡å‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†
 [StableDiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 ã€‚


é»˜è®¤æƒ…å†µä¸‹ï¼Œæ–‡æœ¬åæ¼”è„šæœ¬å°†ä»…ä¿å­˜å…·æœ‰ä»¥ä¸‹ç‰¹å¾çš„æ–‡æœ¬åæ¼”åµŒå…¥å‘é‡ï¼š
è¢«æ·»åŠ åˆ°æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µä¸­å¹¶å› æ­¤è¢«è®­ç»ƒã€‚


ç«ç‚¬


éšè— Pytorch å†…å®¹


 ğŸ’¡ ç¤¾åŒºåˆ›å»ºäº†ä¸€ä¸ªåŒ…å«ä¸åŒæ–‡æœ¬åè½¬åµŒå…¥å‘é‡çš„å¤§å‹åº“ï¼Œç§°ä¸º
 [sd-concepts-library](https://huggingface.co/sd-concepts-library)
 ã€‚
æ‚¨æ— éœ€ä»å¤´å¼€å§‹è®­ç»ƒæ–‡æœ¬åæ¼”åµŒå…¥ï¼Œæ‚¨è¿˜å¯ä»¥æŸ¥çœ‹æ˜¯å¦å·²å°†åˆé€‚çš„æ–‡æœ¬åæ¼”åµŒå…¥æ·»åŠ åˆ°åº“ä¸­ã€‚


è¦åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥ï¼Œæ‚¨é¦–å…ˆéœ€è¦åŠ è½½è®­ç»ƒæ—¶ä½¿ç”¨çš„åŸºæœ¬æ¨¡å‹
æ‚¨çš„æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ã€‚è¿™é‡Œæˆ‘ä»¬å‡è®¾
 [`runwayml/stable-diffusion-v1-5`](runwayml/stable-diffusion-v1-5)
 è¢«ç”¨ä½œåŸºç¡€æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬é¦–å…ˆåŠ è½½å®ƒï¼š



```
from diffusers import StableDiffusionPipeline
import torch

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True).to("cuda")
```


æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½æ–‡æœ¬åè½¬åµŒå…¥å‘é‡ï¼Œè¿™å¯ä»¥é€šè¿‡
 `TextualInversionLoaderMixin.load_textual_inversion`
 åŠŸèƒ½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åŠ è½½ä¹‹å‰â€œ<cat-toy>â€ç¤ºä¾‹çš„åµŒå…¥ã€‚



```
pipe.load_textual_inversion("sd-concepts-library/cat-toy")
```


ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿è¡Œç®¡é“ï¼Œç¡®ä¿å ä½ç¬¦æ ‡è®°
 `<çŒ«ç©å…·>`
 åœ¨æˆ‘ä»¬çš„æç¤ºä¸­ä½¿ç”¨ã€‚



```
prompt = "A <cat-toy> backpack"

image = pipe(prompt, num_inference_steps=50).images[0]
image.save("cat-backpack.png")
```


åŠŸèƒ½
 `TextualInversionLoaderMixin.load_textual_inversion`
 ä¸ä»…å¯ä»¥
åŠ è½½ä»¥ Diffusers æ ¼å¼ä¿å­˜çš„æ–‡æœ¬åµŒå…¥å‘é‡ï¼Œä»¥åŠåµŒå…¥å‘é‡
ä¿å­˜åœ¨
 [Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
 æ ¼å¼ã€‚
ä¸ºæ­¤ï¼Œæ‚¨å¯ä»¥é¦–å…ˆä»ä»¥ä¸‹ä½ç½®ä¸‹è½½åµŒå…¥å‘é‡
 [civitAI](https://civitai.com/models/3036?modelVersionId=8387)
 ç„¶ååœ¨æœ¬åœ°åŠ è½½ï¼š



```
pipe.load_textual_inversion("./charturnerv2.pt")
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹


ç›®å‰æ²¡æœ‰
 `åŠ è½½æ–‡æœ¬åè½¬`
 Flax çš„å‡½æ•°ï¼Œå› æ­¤å¿…é¡»ç¡®ä¿æ–‡æœ¬åè½¬
è®­ç»ƒååµŒå…¥å‘é‡ä¿å­˜ä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†ã€‚


ç„¶åï¼Œè¯¥æ¨¡å‹å¯ä»¥åƒä»»ä½•å…¶ä»– Flax æ¨¡å‹ä¸€æ ·è¿è¡Œï¼š



```
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard
from diffusers import FlaxStableDiffusionPipeline

model_path = "path-to-your-trained-model"
pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(model_path, dtype=jax.numpy.bfloat16)

prompt = "A <cat-toy> backpack"
prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 50

num_samples = jax.device_count()
prompt = num_samples * [prompt]
prompt_ids = pipeline.prepare_inputs(prompt)

# shard inputs and rng
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
image.save("cat-backpack.png")
```


## æ€ä¹ˆè¿è¡Œçš„



![è®ºæ–‡ä¸­çš„å›¾è¡¨æ˜¾ç¤ºæ¦‚è¿°](https://textual-inversion.github.io/static/images/training/training.JPG)


æ–‡æœ¬åè½¬çš„æ¶æ„æ¦‚è¿°
 [åšå®¢æ–‡ç« ã€‚](https://textual-inversion.github.io/)


 é€šå¸¸ï¼Œæ–‡æœ¬æç¤ºåœ¨ä¼ é€’ç»™æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯è½¬æ¢å™¨ï¼‰ä¹‹å‰ä¼šè¢«æ ‡è®°ä¸ºåµŒå…¥ã€‚æ–‡æœ¬åè½¬åšäº†ç±»ä¼¼çš„äº‹æƒ…ï¼Œä½†å®ƒå­¦ä¹ äº†æ–°çš„æ ‡è®°åµŒå…¥ï¼Œ
 `v*`
 ï¼Œæ¥è‡ªä¸€ä¸ªç‰¹æ®Šçš„ä»¤ç‰Œ
 `S*`
 åœ¨ä¸Šå›¾ä¸­ã€‚æ¨¡å‹è¾“å‡ºç”¨äºè°ƒèŠ‚æ‰©æ•£æ¨¡å‹ï¼Œè¿™æœ‰åŠ©äºæ‰©æ•£æ¨¡å‹ä»å‡ ä¸ªç¤ºä¾‹å›¾åƒä¸­ç†è§£æç¤ºå’Œæ–°æ¦‚å¿µã€‚


ä¸ºæ­¤ï¼Œæ–‡æœ¬åè½¬ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å‹å’Œè®­ç»ƒå›¾åƒçš„å™ªå£°ç‰ˆæœ¬ã€‚ç”Ÿæˆå™¨å°è¯•é¢„æµ‹å›¾åƒçš„å™ªå£°è¾ƒå°çš„ç‰ˆæœ¬ï¼Œä»¥åŠä»¤ç‰ŒåµŒå…¥
 `v*`
 æ ¹æ®ç”Ÿæˆå™¨çš„æ€§èƒ½è¿›è¡Œä¼˜åŒ–ã€‚å¦‚æœä»¤ç‰ŒåµŒå…¥æˆåŠŸåœ°æ•è·äº†æ–°æ¦‚å¿µï¼Œå®ƒå°±ä¼šä¸ºæ‰©æ•£æ¨¡å‹æä¾›æ›´å¤šæœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¹¶æœ‰åŠ©äºåˆ›å»ºå™ªå£°æ›´å°‘çš„æ›´æ¸…æ™°çš„å›¾åƒã€‚æ­¤ä¼˜åŒ–è¿‡ç¨‹é€šå¸¸åœ¨æ¥è§¦å„ç§æç¤ºå’Œå›¾åƒå˜ä½“æ•°åƒä¸ªæ­¥éª¤åå‘ç”Ÿã€‚