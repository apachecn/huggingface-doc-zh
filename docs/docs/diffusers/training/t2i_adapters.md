# ç”¨äºç¨³å®šæ‰©æ•£ XL (SDXL) çš„ T2I é€‚é…å™¨

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/t2i_adapters>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/t2i_adapters>


è¿™
 `train_t2i_adapter_sdxl.py`
 è„šæœ¬ï¼ˆå¦‚ä¸‹æ‰€ç¤ºï¼‰å±•ç¤ºäº†å¦‚ä½•å®ç°
 [T2I-Adapter åŸ¹è®­æµç¨‹](https://hf.co/papers/2302.08453)
 ä¸ºäº†
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 ã€‚


## ä½¿ç”¨ PyTorch åœ¨æœ¬åœ°è¿è¡Œ



### 


 å®‰è£…ä¾èµ–é¡¹


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š


**é‡è¦çš„**


ä¸ºäº†ç¡®ä¿æ‚¨å¯ä»¥æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®
 **ä»æºå®‰è£…**
 å¹¶ä¿æŒå®‰è£…æœ€æ–°ï¼Œå› ä¸ºæˆ‘ä»¬ç»å¸¸æ›´æ–°ç¤ºä¾‹è„šæœ¬å¹¶å®‰è£…ä¸€äº›ç‰¹å®šäºç¤ºä¾‹çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š



```
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
```


ç„¶åcdåˆ°
 `ç¤ºä¾‹/t2i_adapter`
 æ–‡ä»¶å¤¹å¹¶è¿è¡Œ



```
pip install -r requirements_sdxl.txt
```


å¹¶åˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤—åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


æˆ–è€…ä½¿ç”¨é»˜è®¤åŠ é€Ÿé…ç½®è€Œä¸å›ç­”æœ‰å…³æ‚¨çš„ç¯å¢ƒçš„é—®é¢˜



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼ˆä¾‹å¦‚ç¬”è®°æœ¬ï¼‰



```
from accelerate.utils import write_basic_config
write_basic_config()
```


è·‘æ­¥æ—¶
 `åŠ é€Ÿé…ç½®`
 ï¼Œå¦‚æœæˆ‘ä»¬å°† torch ç¼–è¯‘æ¨¡å¼æŒ‡å®šä¸º Trueï¼Œåˆ™å¯ä»¥æ˜¾ç€æé«˜é€Ÿåº¦ã€‚


## åœ†å½¢å¡«å……æ•°æ®é›†



åŸå§‹æ•°æ®é›†æ‰˜ç®¡åœ¨
 [ControlNet å­˜å‚¨åº“](https://huggingface.co/lllyasviel/ControlNet/blob/main/training/fill50k.zip)
 ã€‚æˆ‘ä»¬é‡æ–°ä¸Šä¼ å®ƒä»¥å…¼å®¹
 `æ•°æ®é›†`
[æ­¤å¤„](https://huggingface.co/datasets/fusing/fill50k)
 ã€‚æ³¨æ„
 `æ•°æ®é›†`
 å¤„ç†è®­ç»ƒè„šæœ¬ä¸­çš„æ•°æ®åŠ è½½ã€‚


## è®­ç»ƒ



æˆ‘ä»¬çš„è®­ç»ƒç¤ºä¾‹ä½¿ç”¨ä¸¤ä¸ªæµ‹è¯•æ¡ä»¶å›¾åƒã€‚å¯ä»¥é€šè¿‡è¿è¡Œæ¥ä¸‹è½½å®ƒä»¬



```
wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png

wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png
```


ç„¶åè¿è¡Œ
 `huggingface-cli ç™»å½•`
 ç™»å½•æ‚¨çš„ Hugging Face å¸æˆ·ã€‚è¿™æ˜¯ä¸ºäº†èƒ½å¤Ÿå°†ç»è¿‡è®­ç»ƒçš„ T2IAdapter å‚æ•°æ¨é€åˆ° Hugging Face Hub æ‰€å¿…éœ€çš„ã€‚



```
export MODEL_DIR="stabilityai/stable-diffusion-xl-base-1.0"
export OUTPUT_DIR="path to save model"

accelerate launch train_t2i_adapter_sdxl.py  --pretrained_model_name_or_path=$MODEL\_DIR  --output_dir=$OUTPUT\_DIR  --dataset_name=fusing/fill50k  --mixed_precision="fp16"  --resolution=1024  --learning_rate=1e-5  --max_train_steps=15000  --validation_image "./conditioning\_image\_1.png" "./conditioning\_image\_2.png"  --validation_prompt "red circle with blue background" "cyan circle with brown floral background"  --validation_steps=100  --train_batch_size=1  --gradient_accumulation_steps=4  --report_to="wandb"  --seed=42  --push_to_hub
```


ä¸ºäº†æ›´å¥½åœ°è·Ÿè¸ªæˆ‘ä»¬çš„è®­ç»ƒå®éªŒï¼Œæˆ‘ä»¬åœ¨ä¸Šé¢çš„å‘½ä»¤ä¸­ä½¿ç”¨ä»¥ä¸‹æ ‡å¿—ï¼š


* `report_to="wandb`
 å°†ç¡®ä¿è·Ÿè¸ªè®­ç»ƒè¿è¡Œçš„æƒé‡å’Œåå·®ã€‚è¦ä½¿ç”¨å®ƒï¼Œè¯·åŠ¡å¿…å®‰è£…
 `ä¸‡å¾·å¸ƒ`
 å’Œ
 `pip å®‰è£…wandb`
 ã€‚
* `éªŒè¯å›¾åƒ`
 ,
 `éªŒè¯æç¤º`
 ï¼Œ å’Œ
 `éªŒè¯æ­¥éª¤`
 å…è®¸è„šæœ¬æ‰§è¡Œä¸€äº›éªŒè¯æ¨ç†è¿è¡Œã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå®šæ€§åœ°æ£€æŸ¥åŸ¹è®­æ˜¯å¦æŒ‰é¢„æœŸè¿›è¡Œã€‚


æˆ‘ä»¬çš„å®éªŒæ˜¯åœ¨å•ä¸ª 40GB A100 GPU ä¸Šè¿›è¡Œçš„ã€‚


### 


 æ¨ç†


è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥åƒè¿™æ ·è¿›è¡Œæ¨ç†ï¼š



```
from diffusers import StableDiffusionXLAdapterPipeline, T2IAdapter, EulerAncestralDiscreteSchedulerTest
from diffusers.utils import load_image
import torch

base_model_path = "stabilityai/stable-diffusion-xl-base-1.0"
adapter_path = "path to adapter"

adapter = T2IAdapter.from_pretrained(adapter_path, torch_dtype=torch.float16)
pipe = StableDiffusionXLAdapterPipeline.from_pretrained(
    base_model_path, adapter=adapter, torch_dtype=torch.float16
)

# speed up diffusion process with faster scheduler and memory optimization
pipe.scheduler = EulerAncestralDiscreteSchedulerTest.from_config(pipe.scheduler.config)
# remove following line if xformers is not installed or when using Torch 2.0.
pipe.enable_xformers_memory_efficient_attention()
# memory optimization.
pipe.enable_model_cpu_offload()

control_image = load_image("./conditioning\_image\_1.png")
prompt = "pale golden rod circle with old lace background"

# generate image
generator = torch.manual_seed(0)
image = pipe(
    prompt, num_inference_steps=20, generator=generator, image=control_image
).images[0]
image.save("./output.png")
```


## ç¬”è®°



### 


 æŒ‡å®šæ›´å¥½çš„ VAE


ä¼—æ‰€å‘¨çŸ¥ï¼ŒSDXL çš„ VAE å­˜åœ¨æ•°å€¼ä¸ç¨³å®šé—®é¢˜ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¿˜å…¬å¼€ä¸€ä¸ª CLI å‚æ•°ï¼Œå³
 `--pretrained_vae_model_name_or_path`
 å…è®¸æ‚¨æŒ‡å®šæ›´å¥½çš„ VAE çš„ä½ç½®ï¼ˆä¾‹å¦‚
 [è¿™ä¸ª](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)
 ï¼‰ã€‚