# æ¢¦æƒ³å±•ä½

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/dreambooth>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/dreambooth>


[DreamBooth](https://arxiv.org/abs/2208.12242)
 æ˜¯ä¸€ç§ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä»…ç»™å®šä¸»é¢˜çš„å‡ å¼ ï¼ˆ3-5ï¼‰å›¾åƒçš„ç¨³å®šæ‰©æ•£ã€‚å®ƒå…è®¸æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ã€å§¿åŠ¿å’Œè§†å›¾ä¸­ç”Ÿæˆä¸»ä½“çš„ä¸Šä¸‹æ–‡å›¾åƒã€‚


![é¡¹ç›®åšå®¢ä¸­çš„ Dreamambooth ç¤ºä¾‹](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)


Dreambooth ç¤ºä¾‹æ¥è‡ª
 [é¡¹ç›®çš„åšå®¢ã€‚](https://dreambooth.github.io)


 æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ DreamBooth è¿›è¡Œå¾®è°ƒ
 [`CompVis/stable-diffusion-v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4)
 é€‚ç”¨äºå„ç§ GPU å¤§å°å’Œ Flax çš„æ¨¡å‹ã€‚æœ¬æŒ‡å—ä¸­ä½¿ç”¨çš„æ‰€æœ‰ DreamBooth åŸ¹è®­è„šæœ¬å‡å¯åœ¨æ­¤å¤„æ‰¾åˆ°
 [æ­¤å¤„](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)
 å¦‚æœæ‚¨æœ‰å…´è¶£æ·±å…¥æŒ–æ˜å¹¶äº†è§£äº‹æƒ…æ˜¯å¦‚ä½•è¿ä½œçš„ã€‚


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿å®‰è£…åº“çš„è®­ç»ƒä¾èµ–é¡¹ã€‚æˆ‘ä»¬è¿˜å»ºè®®å®‰è£… ğŸ§¨ æ‰©æ•£å™¨
 `ä¸»è¦`
 GitHub åˆ†æ”¯ï¼š



```
pip install git+https://github.com/huggingface/diffusers
pip install -U -r diffusers/examples/dreambooth/requirements.txt
```


xFormers ä¸æ˜¯åŸ¹è®­è¦æ±‚çš„ä¸€éƒ¨åˆ†ï¼Œä½†æˆ‘ä»¬å»ºè®®æ‚¨
 [å®‰è£…](../optimization/xformers)
 å¦‚æœå¯ä»¥çš„è¯ï¼Œå› ä¸ºå®ƒå¯ä»¥è®©ä½ çš„è®­ç»ƒæ›´å¿«å¹¶ä¸”æ›´å°‘çš„å†…å­˜æ¶ˆè€—ã€‚


è®¾ç½®å®Œæ‰€æœ‰ä¾èµ–é¡¹åï¼Œåˆå§‹åŒ–ä¸€ä¸ª
 [ğŸ¤— åŠ é€Ÿ](https://github.com/huggingface/accelerate/)
 ç¯å¢ƒï¼š



```
accelerate config
```


è¦è®¾ç½®é»˜è®¤ğŸ¤—åŠ é€Ÿç¯å¢ƒè€Œä¸é€‰æ‹©ä»»ä½•é…ç½®ï¼š



```
accelerate config default
```


æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒç¬”è®°æœ¬ç­‰äº¤äº’å¼ shellï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š



```
from accelerate.utils import write_basic_config

write_basic_config()
```


æœ€åï¼Œä¸‹è½½ä¸€ä¸ª
 [å‡ å¼ ç‹—çš„å›¾ç‰‡](https://huggingface.co/datasets/diffusers/dog-example)
 å‰å¾€ DreamBoothï¼š



```
from huggingface_hub import snapshot_download

local_dir = "./dog"
snapshot_download(
    "diffusers/dog-example",
    local_dir=local_dir,
    repo_type="dataset",
    ignore_patterns=".gitattributes",
)
```


è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†ï¼Œè¯·æŸ¥çœ‹
 [åˆ›å»ºè®­ç»ƒæ•°æ®é›†](create_dataset)
 æŒ‡å¯¼ã€‚


## å¾®è°ƒ



DreamBoothå¾®è°ƒå¯¹è¶…å‚æ•°éå¸¸æ•æ„Ÿï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚æˆ‘ä»¬å»ºè®®æ‚¨çœ‹çœ‹æˆ‘ä»¬çš„
 [æ·±å…¥åˆ†æ](https://huggingface.co/blog/dreambooth)
 å…·æœ‰é’ˆå¯¹ä¸åŒä¸»é¢˜çš„æ¨èè®¾ç½®ï¼Œå¸®åŠ©æ‚¨é€‰æ‹©åˆé€‚çš„è¶…å‚æ•°ã€‚


 torch


éšè— Pytorch å†…å®¹


è®¾ç½®
 `INSTANCE_DIR`
 ç¯å¢ƒå˜é‡åˆ°åŒ…å«ç‹—å›¾åƒçš„ç›®å½•è·¯å¾„ã€‚


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 `é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„`
 äº‰è®ºã€‚è¿™
 `å®ä¾‹æç¤º`
 å‚æ•°æ˜¯åŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦çš„æ–‡æœ¬æç¤ºï¼Œä¾‹å¦‚
 `sks`
 ï¼Œä»¥åŠå›¾åƒæ‰€å±çš„ç±»ï¼Œåœ¨æœ¬ä¾‹ä¸­æ˜¯
 â€œä¸€å¼  sks ç‹—çš„ç…§ç‰‡â€
 ã€‚



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export OUTPUT_DIR="path\_to\_saved\_model"
```


ç„¶åæ‚¨å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼ˆæ‚¨å¯ä»¥æ‰¾åˆ°å®Œæ•´çš„è®­ç»ƒè„šæœ¬
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py)
 ï¼‰ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š



```
accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a photo of sks dog"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=1   --learning_rate=5e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --max_train_steps=400   --push_to_hub
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹


å¦‚æœæ‚¨å¯ä»¥ä½¿ç”¨ TPU æˆ–æƒ³è¦æ›´å¿«åœ°è®­ç»ƒï¼Œæ‚¨å¯ä»¥å°è¯•
 [Flaxè®­ç»ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_flax.py)
 ã€‚ Flax è®­ç»ƒè„šæœ¬ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹æˆ–æ¢¯åº¦ç´¯ç§¯ï¼Œå› æ­¤æ‚¨éœ€è¦å…·æœ‰è‡³å°‘ 30GB å†…å­˜çš„ GPUã€‚


åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…ä»¥ä¸‹è¦æ±‚ï¼š



```
pip install -U -r requirements.txt
```


æŒ‡å®š
 `å‹å·_åç§°`
 ç¯å¢ƒå˜é‡ï¼ˆé›†çº¿å™¨æ¨¡å‹å­˜å‚¨åº“ ID æˆ–åŒ…å«æ¨¡å‹æƒé‡çš„ç›®å½•çš„è·¯å¾„ï¼‰å¹¶å°†å…¶ä¼ é€’ç»™
 `é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„`
 äº‰è®ºã€‚è¿™
 `å®ä¾‹æç¤º`
 å‚æ•°æ˜¯åŒ…å«å”¯ä¸€æ ‡è¯†ç¬¦çš„æ–‡æœ¬æç¤ºï¼Œä¾‹å¦‚
 `sks`
 ï¼Œä»¥åŠå›¾åƒæ‰€å±çš„ç±»ï¼Œåœ¨æœ¬ä¾‹ä¸­æ˜¯
 â€œä¸€å¼  sks ç‹—çš„ç…§ç‰‡â€
 ã€‚


ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒè„šæœ¬ï¼š



```
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="./dog"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a photo of sks dog"   --resolution=512   --train_batch_size=1   --learning_rate=5e-6   --max_train_steps=400   --push_to_hub
```


## é€šè¿‡ä¿ç•™å…ˆéªŒæŸå¤±è¿›è¡Œå¾®è°ƒ



é¢„å…ˆä¿å­˜ç”¨äºé¿å…è¿‡åº¦æ‹Ÿåˆå’Œè¯­è¨€æ¼‚ç§»ï¼ˆæŸ¥çœ‹
 [è®ºæ–‡](https://arxiv.org/abs/2208.12242)
 å¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œå¯ä»¥äº†è§£æ›´å¤šä¿¡æ¯ï¼‰ã€‚ä¸ºäº†é¢„å…ˆä¿å­˜ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨åŒä¸€ç±»çš„å…¶ä»–å›¾åƒä½œä¸ºè®­ç»ƒè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ã€‚å¥½å¤„æ˜¯æ‚¨å¯ä»¥ä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹æœ¬èº«ç”Ÿæˆè¿™äº›å›¾åƒï¼è®­ç»ƒè„šæœ¬ä¼šå°†ç”Ÿæˆçš„å›¾åƒä¿å­˜åˆ°æ‚¨æŒ‡å®šçš„æœ¬åœ°è·¯å¾„ã€‚


ä½œè€…å»ºè®®ç”Ÿæˆ
 `num_epochs * num_samples`
 é¢„å…ˆä¿å­˜çš„å›¾åƒã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ200-300 å¼ å›¾åƒæ•ˆæœå¾ˆå¥½ã€‚


torch


éšè— Pytorch å†…å®¹



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path\_to\_class\_images"
export OUTPUT_DIR="path\_to\_saved\_model"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=1   --learning_rate=5e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹



```
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --learning_rate=5e-6   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


## å¾®è°ƒæ–‡æœ¬ç¼–ç å™¨å’Œ UNet



è¯¥è„šæœ¬è¿˜å…è®¸æ‚¨å¾®è°ƒ
 `æ–‡æœ¬ç¼–ç å™¨`
 éšç€
 `ä¹Œå†…ç‰¹`
 ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼ˆæŸ¥çœ‹
 [ä½¿ç”¨ ğŸ§¨ æ‰©æ•£å™¨é€šè¿‡ DreamBooth è®­ç»ƒç¨³å®šæ‰©æ•£](https://huggingface.co/blog/dreambooth)
 å‘å¸ƒæ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼‰ï¼Œè¿™ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆé¢éƒ¨å›¾åƒæ—¶ã€‚


è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨éœ€è¦é¢å¤–çš„å†…å­˜ï¼Œå¹¶ä¸”ä¸é€‚åˆ 16GB GPUã€‚æ‚¨éœ€è¦è‡³å°‘ 24GB VRAM æ‰èƒ½ä½¿ç”¨æ­¤é€‰é¡¹ã€‚


é€šè¿‡
 `--train_text_encoder`
 è®­ç»ƒè„šæœ¬çš„å‚æ•°ä»¥å¯ç”¨å¾®è°ƒ
 `æ–‡æœ¬ç¼–ç å™¨`
 å’Œ
 `ä¹Œå†…ç‰¹`
 ï¼š


torch


éšè— Pytorch å†…å®¹



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path\_to\_class\_images"
export OUTPUT_DIR="path\_to\_saved\_model"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --train_text_encoder   --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --use_8bit_adam   --gradient_checkpointing   --learning_rate=2e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


.J{
 ä¸­é£ï¼š#dce0dfï¼›
 }
.K {
 ç¬”åˆ’çº¿è¿æ¥ï¼šåœ†å½¢ï¼›
 }


è´¾å…‹æ–¯


éšè— JAX å†…å®¹



```
export MODEL_NAME="duongna/stable-diffusion-v1-4-flax"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

python train_dreambooth_flax.py   --pretrained_model_name_or_path=$MODEL\_NAME    --train_text_encoder   --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --learning_rate=2e-6   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


## ä½¿ç”¨ LoRA è¿›è¡Œå¾®è°ƒ



æ‚¨è¿˜å¯ä»¥åœ¨ DreamBooth ä¸Šä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ä½ç§©é€‚åº” (LoRA)ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåŠ é€Ÿè®­ç»ƒå¤§å‹æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯ã€‚æ¬²äº†è§£æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹
 [LoRA åŸ¹è®­](./lora#dreambooth)
 æŒ‡å¯¼ã€‚


## è®­ç»ƒæ—¶ä¿å­˜æ£€æŸ¥ç‚¹



ä½¿ç”¨ Dreambooth è¿›è¡Œè®­ç»ƒæ—¶å¾ˆå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆï¼Œå› æ­¤æœ‰æ—¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜å®šæœŸæ£€æŸ¥ç‚¹å¾ˆæœ‰ç”¨ã€‚ä¸­é—´æ£€æŸ¥ç‚¹ä¹‹ä¸€å®é™…ä¸Šå¯èƒ½æ¯”æœ€ç»ˆæ¨¡å‹æ•ˆæœæ›´å¥½ï¼å°†ä»¥ä¸‹å‚æ•°ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ä»¥å¯ç”¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼š



```
  --checkpointing_steps=500
```


è¿™ä¼šå°†å®Œæ•´çš„è®­ç»ƒçŠ¶æ€ä¿å­˜åœ¨æ‚¨çš„å­æ–‡ä»¶å¤¹ä¸­
 `è¾“å‡ºç›®å½•`
 ã€‚å­æ–‡ä»¶å¤¹åç§°ä»¥å‰ç¼€å¼€å¤´
 `æ£€æŸ¥ç‚¹-`
 ï¼Œåé¢æ˜¯è¿„ä»Šä¸ºæ­¢æ‰§è¡Œçš„æ­¥éª¤æ•°ï¼›ä¾‹å¦‚ï¼Œ
 `æ£€æŸ¥ç‚¹-1500`
 å°†æ˜¯ 1500 ä¸ªè®­ç»ƒæ­¥éª¤åä¿å­˜çš„æ£€æŸ¥ç‚¹ã€‚


### 


 ä»ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ


å¦‚æœä½ æƒ³ä»ä»»ä½•ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œä½ å¯ä»¥ä¼ é€’å‚æ•°
 `--resume_from_checkpoint`
 åˆ°è„šæœ¬å¹¶æŒ‡å®šè¦ä½¿ç”¨çš„æ£€æŸ¥ç‚¹çš„åç§°ã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ç‰¹æ®Šå­—ç¬¦ä¸²
 `â€œæœ€æ–°â€`
 ä»æœ€åä¿å­˜çš„æ£€æŸ¥ç‚¹ï¼ˆæ­¥æ•°æœ€å¤šçš„æ£€æŸ¥ç‚¹ï¼‰æ¢å¤ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å°†ä» 1500 æ­¥åä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼š



```
  --resume_from_checkpoint="checkpoint-1500"
```


å¦‚æœæ‚¨æ„¿æ„ï¼Œè¿™æ˜¯è°ƒæ•´ä¸€äº›è¶…å‚æ•°çš„å¥½æœºä¼šã€‚


### 


 ä»ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¨æ–­


ä¿å­˜çš„æ£€æŸ¥ç‚¹ä»¥é€‚åˆæ¢å¤è®­ç»ƒçš„æ ¼å¼å­˜å‚¨ã€‚å®ƒä»¬ä¸ä»…åŒ…æ‹¬æ¨¡å‹æƒé‡ï¼Œè¿˜åŒ…æ‹¬ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨å’Œå­¦ä¹ ç‡çš„çŠ¶æ€ã€‚


å¦‚æœä½ æœ‰
 **`â€œåŠ é€Ÿ>=0.16.0â€`**
 å®‰è£…å®Œæ¯•ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç è¿è¡Œ
ä»ä¸­é—´æ£€æŸ¥ç‚¹æ¨æ–­ã€‚



```
from diffusers import DiffusionPipeline, UNet2DConditionModel
from transformers import CLIPTextModel
import torch

# Load the pipeline with the same arguments (model, revision) that were used for training
model_id = "CompVis/stable-diffusion-v1-4"

unet = UNet2DConditionModel.from_pretrained("/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet")

# if you have trained with `--args.train\_text\_encoder` make sure to also load the text encoder
text_encoder = CLIPTextModel.from_pretrained("/sddata/dreambooth/daruma-v2-1/checkpoint-100/text\_encoder")

pipeline = DiffusionPipeline.from_pretrained(
    model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16, use_safetensors=True
)
pipeline.to("cuda")

# Perform inference, or save, or push to the hub
pipeline.save_pretrained("dreambooth-pipeline")
```


å¦‚æœä½ æœ‰
 **`â€œåŠ é€Ÿ<0.16.0â€`**
 å®‰è£…å®Œæ¯•åï¼Œéœ€è¦å…ˆå°†å…¶è½¬æ¢ä¸ºæ¨ç†ç®¡é“ï¼š



```
from accelerate import Accelerator
from diffusers import DiffusionPipeline

# Load the pipeline with the same arguments (model, revision) that were used for training
model_id = "CompVis/stable-diffusion-v1-4"
pipeline = DiffusionPipeline.from_pretrained(model_id, use_safetensors=True)

accelerator = Accelerator()

# Use text\_encoder if `--train\_text\_encoder` was used for the initial training
unet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)

# Restore state from a checkpoint path. You have to use the absolute path here.
accelerator.load_state("/sddata/dreambooth/daruma-v2-1/checkpoint-100")

# Rebuild the pipeline with the unwrapped models (assignment to .unet and .text\_encoder should work too)
pipeline = DiffusionPipeline.from_pretrained(
    model_id,
    unet=accelerator.unwrap_model(unet),
    text_encoder=accelerator.unwrap_model(text_encoder),
    use_safetensors=True,
)

# Perform inference, or save, or push to the hub
pipeline.save_pretrained("dreambooth-pipeline")
```


## é’ˆå¯¹ä¸åŒ GPU å¤§å°çš„ä¼˜åŒ–



æ ¹æ®æ‚¨çš„ç¡¬ä»¶ï¼Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥åœ¨ GPU ä¸Šä¼˜åŒ– DreamBoothï¼ˆä» 16GB åˆ° 8GBï¼‰ï¼


### 


 xFormers


[xFormers](https://github.com/facebookresearch/xformers)
 æ˜¯ä¸€ä¸ªç”¨äºä¼˜åŒ– Transformers çš„å·¥å…·ç®±ï¼Œå®ƒåŒ…æ‹¬
 [å†…å­˜æ•ˆç‡æ³¨æ„åŠ›](https://facebookresearch.github.io/xformers/components/ops.html#module-xformers.ops)
 ğŸ§¨ æ‰©æ•£å™¨ä¸­ä½¿ç”¨çš„æœºåˆ¶ã€‚ä½ éœ€è¦
 [å®‰è£… xFormers](./optimization/xformers)
 ç„¶åå°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°æ‚¨çš„è®­ç»ƒè„šæœ¬ä¸­ï¼š



```
  --enable_xformers_memory_efficient_attention
```


xFormers åœ¨ Flax ä¸­ä¸å¯ç”¨ã€‚


### 


 å°†æ¸å˜è®¾ç½®ä¸ºæ— 


é™ä½å†…å­˜å ç”¨çš„å¦ä¸€ç§æ–¹æ³•æ˜¯
 [è®¾ç½®æ¢¯åº¦](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)
 åˆ°
 `æ— `
 è€Œä¸æ˜¯é›¶ã€‚ä½†æ˜¯ï¼Œè¿™å¯èƒ½ä¼šæ”¹å˜æŸäº›è¡Œä¸ºï¼Œå› æ­¤å¦‚æœæ‚¨é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·å°è¯•åˆ é™¤æ­¤å‚æ•°ã€‚å°†ä»¥ä¸‹å‚æ•°æ·»åŠ åˆ°æ‚¨çš„è®­ç»ƒè„šæœ¬ä¸­ä»¥å°†æ¢¯åº¦è®¾ç½®ä¸º
 `æ— `
 ï¼š



```
  --set_grads_to_none
```


### 


 16GB GPU


å€ŸåŠ©æ¢¯åº¦æ£€æŸ¥ç‚¹å’Œ
 [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
 8 ä½ä¼˜åŒ–å™¨ï¼Œå¯ä»¥åœ¨ 16GB GPU ä¸Šè®­ç»ƒ DreamBoothã€‚ç¡®ä¿ä½ å·²ç»å®‰è£…äº†bitsandbytesï¼š



```
pip install bitsandbytes
```


ç„¶åé€šè¿‡
 `--use_8bit_adam`
 è®­ç»ƒè„šæœ¬çš„é€‰é¡¹ï¼š



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path\_to\_class\_images"
export OUTPUT_DIR="path\_to\_saved\_model"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=2 --gradient_checkpointing   --use_8bit_adam   --learning_rate=5e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


### 


 12GB GPU


è¦åœ¨ 12GB GPU ä¸Šè¿è¡Œ DreamBoothï¼Œæ‚¨éœ€è¦å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€8 ä½ä¼˜åŒ–å™¨ã€xFormersï¼Œå¹¶å°†æ¢¯åº¦è®¾ç½®ä¸º
 `æ— `
 ï¼š



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path-to-class-images"
export OUTPUT_DIR="path-to-save-model"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --gradient_accumulation_steps=1 --gradient_checkpointing   --use_8bit_adam   --enable_xformers_memory_efficient_attention   --set_grads_to_none   --learning_rate=2e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --num_class_images=200   --max_train_steps=800   --push_to_hub
```


### 


 8GB GPU


å¯¹äº 8GB GPUï¼Œæ‚¨éœ€è¦ä»¥ä¸‹å¸®åŠ©
 [DeepSpeed](https://www.deepspeed.ai/)
 å¸è½½ä¸€äº›
å¼ é‡ä» VRAM ä¼ è¾“åˆ° CPU æˆ– NVMEï¼Œä»è€Œå¯ä»¥ä½¿ç”¨æ›´å°‘çš„ GPU å†…å­˜è¿›è¡Œè®­ç»ƒã€‚


è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥é…ç½®æ‚¨çš„ ğŸ¤— Accelerate ç¯å¢ƒï¼š



```
accelerate config
```


åœ¨é…ç½®è¿‡ç¨‹ä¸­ï¼Œç¡®è®¤æ‚¨è¦ä½¿ç”¨ DeepSpeedã€‚ç°åœ¨ï¼Œå¯ä»¥é€šè¿‡ç»“åˆ DeepSpeed stage 2ã€fp16 æ··åˆç²¾åº¦ï¼Œå¹¶å°†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° CPUï¼Œåœ¨ 8GB VRAM ä»¥ä¸‹è¿›è¡Œè®­ç»ƒã€‚ç¼ºç‚¹æ˜¯è¿™éœ€è¦æ›´å¤šçš„ç³»ç»Ÿ RAMï¼Œå¤§çº¦ 25 GBã€‚çœ‹
 [DeepSpeed æ–‡æ¡£](https://huggingface.co/docs/accelerate/usage_guides/deepspeed)
 äº†è§£æ›´å¤šé…ç½®é€‰é¡¹ã€‚


æ‚¨è¿˜åº”è¯¥å°†é»˜è®¤çš„ Adam ä¼˜åŒ–å™¨æ›´æ”¹ä¸º DeepSpeed çš„ Adam ä¼˜åŒ–ç‰ˆæœ¬
 [`deepspeed.ops.adam.DeepSpeedCPUAdam`](https://deepspeed.readthedocs.io/en/latest/optimizers.html#adam-cpu)
 å¤§å¹…åŠ é€Ÿã€‚å¯ç”¨
 `DeepSpeedCPUAdam`
 è¦æ±‚æ‚¨ç³»ç»Ÿçš„ CUDA å·¥å…·é“¾ç‰ˆæœ¬ä¸éš PyTorch å®‰è£…çš„ç‰ˆæœ¬ç›¸åŒã€‚


8 ä½ä¼˜åŒ–å™¨ç›®å‰ä¼¼ä¹ä¸ DeepSpeed ä¸å…¼å®¹ã€‚


ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š



```
export MODEL_NAME="CompVis/stable-diffusion-v1-4"
export INSTANCE_DIR="./dog"
export CLASS_DIR="path\_to\_class\_images"
export OUTPUT_DIR="path\_to\_saved\_model"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME   --instance_data_dir=$INSTANCE\_DIR   --class_data_dir=$CLASS\_DIR   --output_dir=$OUTPUT\_DIR   --with_prior_preservation --prior_loss_weight=1.0   --instance_prompt="a photo of sks dog"   --class_prompt="a photo of dog"   --resolution=512   --train_batch_size=1   --sample_batch_size=1   --gradient_accumulation_steps=1 --gradient_checkpointing   --learning_rate=5e-6   --lr_scheduler="constant"   --lr_warmup_steps=0   --num_class_images=200   --max_train_steps=800   --mixed_precision=fp16   --push_to_hub
```


## æ¨ç†



è®­ç»ƒå®Œæ¨¡å‹åï¼ŒæŒ‡å®šæ¨¡å‹çš„ä¿å­˜è·¯å¾„ï¼Œå¹¶åœ¨æ¨¡å‹ä¸­ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†
 [StableDiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)
 ã€‚ç¡®ä¿æ‚¨çš„æç¤ºåŒ…å«ç‰¹æ®Šå†…å®¹
 `æ ‡è¯†ç¬¦`
 è®­ç»ƒæœŸé—´ä½¿ç”¨ï¼ˆ
 `sks`
 åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼‰ã€‚


å¦‚æœä½ æœ‰
 **`â€œåŠ é€Ÿ>=0.16.0â€`**
 å®‰è£…å®Œæ¯•åï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¿è¡Œ
ä»ä¸­é—´æ£€æŸ¥ç‚¹æ¨æ–­ï¼š



```
from diffusers import DiffusionPipeline
import torch

model_id = "path\_to\_saved\_model"
pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True).to("cuda")

prompt = "A photo of sks dog in a bucket"
image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]

image.save("dog-bucket.png")
```


æ‚¨è¿˜å¯ä»¥ä»ä»»ä½•ä¸€ä¸ªè¿›è¡Œæ¨æ–­
 [ä¿å­˜çš„è®­ç»ƒæ£€æŸ¥ç‚¹](#inference-from-a-saved-checkpoint)
 ã€‚


## å¦‚æœ



æ‚¨å¯ä»¥ä½¿ç”¨ lora å’Œ full dreambooth è„šæœ¬å°†æ–‡æœ¬è®­ç»ƒä¸ºå›¾åƒ
 [IFæ¨¡å‹](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0)
 å’Œç¬¬äºŒé˜¶æ®µå‡çº§å™¨
 [IFæ¨¡å‹](https://huggingface.co/DeepFloyd/IF-II-L-v1.0)
 ã€‚


è¯·æ³¨æ„ï¼ŒIF å…·æœ‰é¢„æµ‹æ–¹å·®ï¼Œè€Œæˆ‘ä»¬çš„å¾®è°ƒè„šæœ¬ä»…è®­ç»ƒæ¨¡å‹é¢„æµ‹è¯¯å·®ï¼Œå› æ­¤å¯¹äºå¾®è°ƒ IF æ¨¡å‹ï¼Œæˆ‘ä»¬åˆ‡æ¢åˆ°å›ºå®šçš„
å·®å¼‚è¡¨ã€‚å®Œæ•´çš„å¾®è°ƒè„šæœ¬å°†æ›´æ–°å®Œæ•´ä¿å­˜æ¨¡å‹çš„è°ƒåº¦ç¨‹åºé…ç½®ã€‚ç„¶è€Œï¼Œå½“åŠ è½½ä¿å­˜çš„ LoRA æƒé‡æ—¶ï¼Œæ‚¨
è¿˜å¿…é¡»æ›´æ–°ç®¡é“çš„è°ƒåº¦ç¨‹åºé…ç½®ã€‚



```
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("DeepFloyd/IF-I-XL-v1.0", use_safetensors=True)

pipe.load_lora_weights("<lora weights path>")

# Update scheduler config to fixed variance schedule
pipe.scheduler = pipe.scheduler.__class__.from_config(pipe.scheduler.config, variance_type="fixed\_small")
```


æ­¤å¤–ï¼ŒIF è¿˜éœ€è¦ä¸€äº›æ›¿ä»£çš„ cli æ ‡å¿—ã€‚


`--åˆ†è¾¨ç‡=64`
 ï¼šIFæ˜¯åƒç´ ç©ºé—´æ‰©æ•£æ¨¡å‹ã€‚ä¸ºäº†å¯¹æœªå‹ç¼©çš„åƒç´ è¿›è¡Œæ“ä½œï¼Œè¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡è¦å°å¾—å¤šã€‚


`--pre_compute_text_embeddings`
 : å¦‚æœä½¿ç”¨
 [T5](https://huggingface.co/docs/transformers/model_doc/t5)
 å¯¹äºå®ƒçš„æ–‡æœ¬ç¼–ç å™¨ã€‚ä¸ºäº†èŠ‚çœ GPU å†…å­˜ï¼Œæˆ‘ä»¬é¢„å…ˆè®¡ç®—æ‰€æœ‰æ–‡æœ¬åµŒå…¥ï¼Œç„¶åå–æ¶ˆåˆ†é…
T5ã€‚


`--tokenizer_max_length=77`
 ï¼šT5 çš„é»˜è®¤æ–‡æœ¬é•¿åº¦è¾ƒé•¿ï¼Œä½†é»˜è®¤ IF ç¼–ç è¿‡ç¨‹ä½¿ç”¨è¾ƒå°çš„æ•°å­—ã€‚


`--text_encoder_use_attention_mask`
 ï¼šT5 å°†æ³¨æ„åŠ›æ©ç ä¼ é€’ç»™æ–‡æœ¬ç¼–ç å™¨ã€‚


### 


 æŠ€å·§å’Œçªé—¨


æˆ‘ä»¬å‘ç° LoRA è¶³ä»¥å¾®è°ƒç¬¬ä¸€é˜¶æ®µæ¨¡å‹ï¼Œå› ä¸ºæ¨¡å‹çš„ä½åˆ†è¾¨ç‡ä½¿å¾—è¡¨ç¤ºç»†ç²’åº¦ç»†èŠ‚å˜å¾—å›°éš¾ã€‚


å¯¹äºå¸¸è§å’Œ/æˆ–è§†è§‰ä¸Šä¸å¤æ‚çš„å¯¹è±¡æ¦‚å¿µï¼Œæ‚¨å¯ä»¥ä¸å¾®è°ƒå‡çº§å™¨ã€‚è¯·åŠ¡å¿…è°ƒæ•´ä¼ é€’ç»™çš„æç¤º
upscaler ä»å®ä¾‹æç¤ºä¸­åˆ é™¤æ–°ä»¤ç‰Œã€‚ IEã€‚å¦‚æœæ‚¨çš„ç¬¬ä¸€é˜¶æ®µæç¤ºæ˜¯â€œä¸€åª sks ç‹—â€ï¼Œè¯·ä½¿ç”¨â€œä¸€åªç‹—â€ä½œä¸ºæ‚¨çš„ç¬¬äºŒé˜¶æ®µæç¤ºã€‚


å¯¹äºåŸå§‹è®­ç»ƒé›†ä¸­ä¸å­˜åœ¨çš„ç»†ç²’åº¦ç»†èŠ‚ï¼ˆä¾‹å¦‚äººè„¸ï¼‰ï¼Œæˆ‘ä»¬å‘ç°ç¬¬äºŒé˜¶æ®µå‡çº§å™¨çš„å…¨é¢å¾®è°ƒä¼˜äº
LoRA å¾®è°ƒé˜¶æ®µ IIã€‚


å¯¹äºåƒäººè„¸è¿™æ ·çš„ç»†ç²’åº¦ç»†èŠ‚ï¼Œæˆ‘ä»¬å‘ç°è¾ƒä½çš„å­¦ä¹ ç‡å’Œè¾ƒå¤§çš„æ‰¹é‡å¤§å°æ•ˆæœæœ€å¥½ã€‚


å¯¹äºç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬å‘ç°è¿˜éœ€è¦è¾ƒä½çš„å­¦ä¹ ç‡ã€‚


æˆ‘ä»¬é€šè¿‡å®éªŒå‘ç°ï¼Œå…·æœ‰é»˜è®¤è¾ƒå¤šå»å™ªæ­¥éª¤çš„ DDPM è°ƒåº¦ç¨‹åºæœ‰æ—¶æ¯” DPM Solver è°ƒåº¦ç¨‹åºå·¥ä½œå¾—æ›´å¥½
åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨ã€‚


### 


 ç¬¬äºŒé˜¶æ®µé™„åŠ éªŒè¯å›¾åƒ


ç¬¬äºŒé˜¶æ®µéªŒè¯éœ€è¦å¯¹å›¾åƒè¿›è¡Œæ”¾å¤§ï¼Œæˆ‘ä»¬å¯ä»¥ä¸‹è½½è®­ç»ƒé›†çš„ç¼©å°ç‰ˆæœ¬ï¼š



```
from huggingface_hub import snapshot_download

local_dir = "./dog\_downsized"
snapshot_download(
    "diffusers/dog-example-downsized",
    local_dir=local_dir,
    repo_type="dataset",
    ignore_patterns=".gitattributes",
)
```


### 


 IF ç¬¬ä¸€é˜¶æ®µ LoRA Dreambooth


æ­¤è®­ç»ƒé…ç½®éœ€è¦ ~28 GB VRAMã€‚



```
export MODEL_NAME="DeepFloyd/IF-I-XL-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth\_dog\_lora"

accelerate launch train_dreambooth_lora.py   --report_to wandb   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a sks dog"   --resolution=64   --train_batch_size=4   --gradient_accumulation_steps=1   --learning_rate=5e-6   --scale_lr   --max_train_steps=1200   --validation_prompt="a sks dog"   --validation_epochs=25   --checkpointing_steps=100   --pre_compute_text_embeddings   --tokenizer_max_length=77   --text_encoder_use_attention_mask
```


### 


 IF ç¬¬äºŒé˜¶æ®µ LoRA Dreambooth


`--validation_images`
 ï¼šè¿™äº›å›¾åƒåœ¨éªŒè¯æ­¥éª¤æœŸé—´è¢«æ”¾å¤§ã€‚


`--class_labels_conditioning=æ—¶é—´æ­¥é•¿`
 ï¼šå°†ç¬¬äºŒé˜¶æ®µæ‰€éœ€çš„é¢å¤–è°ƒèŠ‚ä¼ é€’ç»™ UNetã€‚


`--learning_rate=1e-6`
 ï¼šå­¦ä¹ ç‡ä½äºç¬¬ä¸€é˜¶æ®µã€‚


`--åˆ†è¾¨ç‡=256`
 ï¼šå‡çº§è€…æœŸæœ›æ›´é«˜åˆ†è¾¨ç‡çš„è¾“å…¥



```
export MODEL_NAME="DeepFloyd/IF-II-L-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth\_dog\_upscale"
export VALIDATION_IMAGES="dog\_downsized/image\_1.png dog\_downsized/image\_2.png dog\_downsized/image\_3.png dog\_downsized/image\_4.png"

python train_dreambooth_lora.py     --report_to wandb     --pretrained_model_name_or_path=$MODEL\_NAME     --instance_data_dir=$INSTANCE\_DIR     --output_dir=$OUTPUT\_DIR     --instance_prompt="a sks dog"     --resolution=256     --train_batch_size=4     --gradient_accumulation_steps=1     --learning_rate=1e-6 \ 
    --max_train_steps=2000     --validation_prompt="a sks dog"     --validation_epochs=100     --checkpointing_steps=500     --pre_compute_text_embeddings     --tokenizer_max_length=77     --text_encoder_use_attention_mask     --validation_images $VALIDATION\_IMAGES     --class_labels_conditioning=timesteps
```


### 


 IF ç¬¬ä¸€é˜¶æ®µ Full Dreambooth


`--skip_save_text_encoder`
 ï¼šè®­ç»ƒå®Œæ•´æ¨¡å‹æ—¶ï¼Œè¿™å°†è·³è¿‡ä½¿ç”¨å¾®è°ƒæ¨¡å‹ä¿å­˜æ•´ä¸ª T5ã€‚æ‚¨ä»ç„¶å¯ä»¥åŠ è½½ç®¡é“
å¸¦æœ‰ä»åŸå§‹æ¨¡å‹åŠ è½½çš„ T5ã€‚


`use_8bit_adam`
 ï¼šç”±äºä¼˜åŒ–å™¨çŠ¶æ€çš„å¤§å°ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ 8 ä½ adam è®­ç»ƒå®Œæ•´çš„ XL IF æ¨¡å‹ã€‚


`--learning_rate=1e-7`
 ï¼šå¯¹äºå®Œæ•´çš„ Dreamboothï¼ŒIF éœ€è¦éå¸¸ä½çš„å­¦ä¹ ç‡ã€‚å­¦ä¹ ç‡è¶Šé«˜ï¼Œæ¨¡å‹è´¨é‡å°±ä¼šä¸‹é™ã€‚è¯·æ³¨æ„ï¼Œå®ƒæ˜¯
å­¦ä¹ ç‡å¯èƒ½ä¼šéšç€æ‰¹é‡å¤§å°çš„å¢åŠ è€Œå¢åŠ ã€‚


ä½¿ç”¨ 8 ä½ adam å’Œæ‰¹é‡å¤§å° 4ï¼Œå¯ä»¥åœ¨ ~48 GB VRAM ä¸­è®­ç»ƒæ¨¡å‹ã€‚



```
export MODEL_NAME="DeepFloyd/IF-I-XL-v1.0"

export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth\_if"

accelerate launch train_dreambooth.py   --pretrained_model_name_or_path=$MODEL\_NAME    --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a photo of sks dog"   --resolution=64   --train_batch_size=4   --gradient_accumulation_steps=1   --learning_rate=1e-7   --max_train_steps=150   --validation_prompt "a photo of sks dog"   --validation_steps 25   --text_encoder_use_attention_mask   --tokenizer_max_length 77   --pre_compute_text_embeddings   --use_8bit_adam   --set_grads_to_none   --skip_save_text_encoder   --push_to_hub
```


### 


 IF Stage II å®Œæ•´æ¢¦æƒ³å±•å°


`--learning_rate=5e-6`
 ï¼šå½“æœ‰æ•ˆæ‰¹é‡å¤§å°ä¸º 4 æ—¶ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬éœ€è¦çš„å­¦ä¹ ç‡ä½è‡³
1e-8ã€‚


`--åˆ†è¾¨ç‡=256`
 ï¼šå‡çº§è€…æœŸæœ›æ›´é«˜åˆ†è¾¨ç‡çš„è¾“å…¥


`--train_batch_size=2`
 å’Œ
 `--gradient_accumulation_steps=6`
 ï¼šæˆ‘ä»¬å‘ç°ç¬¬äºŒé˜¶æ®µçš„å…¨é¢è®­ç»ƒå°¤å…¶æ˜¯
é¢éœ€è¦å¤§çš„æœ‰æ•ˆæ‰¹é‡å¤§å°ã€‚



```
export MODEL_NAME="DeepFloyd/IF-II-L-v1.0"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth\_dog\_upscale"
export VALIDATION_IMAGES="dog\_downsized/image\_1.png dog\_downsized/image\_2.png dog\_downsized/image\_3.png dog\_downsized/image\_4.png"

accelerate launch train_dreambooth.py   --report_to wandb   --pretrained_model_name_or_path=$MODEL\_NAME   --instance_data_dir=$INSTANCE\_DIR   --output_dir=$OUTPUT\_DIR   --instance_prompt="a sks dog"   --resolution=256   --train_batch_size=2   --gradient_accumulation_steps=6   --learning_rate=5e-6   --max_train_steps=2000   --validation_prompt="a sks dog"   --validation_steps=150   --checkpointing_steps=500   --pre_compute_text_embeddings   --tokenizer_max_length=77   --text_encoder_use_attention_mask   --validation_images $VALIDATION\_IMAGES   --class_labels_conditioning timesteps   --push_to_hub
```


## ç¨³å®šæ‰©æ•£XL



æˆ‘ä»¬æ”¯æŒå¯¹ UNet å’Œæ–‡æœ¬ç¼–ç å™¨è¿›è¡Œå¾®è°ƒ
 [ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 é€šè¿‡ DreamBooth å’Œ LoRA
 `train_dreambooth_lora_sdxl.py`
 è„šæœ¬ã€‚è¯·å‚è€ƒæ–‡æ¡£
 [æ­¤å¤„](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_sdxl.md)
 ã€‚