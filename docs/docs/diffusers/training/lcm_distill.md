# [](#latent-consistency-distillation)æ½œåœ¨ä¸€è‡´æ€§è’¸é¦ï¼ˆLatent Consistency Distillationï¼‰

> è¯‘è€…ï¼š[ç–¾é£å…”X](https://github.com/jifnegtu)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/training/lcm_distill>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/training/lcm_distill>



[æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ ï¼ˆLCMsï¼‰](https://hf.co/papers/2310.04378) åªéœ€å‡ ä¸ªæ­¥éª¤å³å¯ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œè¿™ä»£è¡¨äº†ä¸€ä¸ªå·¨å¤§çš„é£è·ƒï¼Œå› ä¸ºè®¸å¤šç®¡é“è‡³å°‘éœ€è¦ 25+ ä¸ªæ­¥éª¤ã€‚LCM æ˜¯é€šè¿‡å°†æ½œåœ¨ä¸€è‡´æ€§è’¸é¦æ–¹æ³•åº”ç”¨äºä»»ä½•ç¨³å®šæ‰©æ•£æ¨¡å‹æ¥ç”Ÿäº§çš„ã€‚è¯¥æ–¹æ³•çš„å·¥ä½œåŸç†æ˜¯å°† *å•é˜¶æ®µå¼•å¯¼è’¸é¦ï¼ˆone-stage guided distillationï¼‰* åº”ç”¨äºæ½œåœ¨ç©ºé—´ï¼Œå¹¶ç»“åˆ *è·³è¿‡æ­¥éª¤ï¼ˆskipping-stepï¼‰* æ–¹æ³•ä»¥ä¸€è‡´è·³è¿‡æ—¶é—´æ­¥é•¿ä»¥åŠ é€Ÿè’¸é¦è¿‡ç¨‹ï¼ˆæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è®ºæ–‡çš„ç¬¬ 4.1ã€4.2 å’Œ 4.3 èŠ‚ï¼‰ã€‚

å¦‚æœåœ¨ vRAM æœ‰é™çš„ GPU ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¯·å°è¯•å¯ç”¨ `gradient_checkpointing` ã€`gradient_accumulation_steps` å’Œ `mixed_precision` ä»¥å‡å°‘å†…å­˜ä½¿ç”¨å¹¶åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚é€šè¿‡ä½¿ç”¨ [xFormers](../optimization/xformers) å’Œ [bitsandbytes ](https://github.com/TimDettmers/bitsandbytes) çš„8 ä½ä¼˜åŒ–å™¨å®ç°å†…å­˜æ•ˆç‡é«˜çš„æ³¨æ„åŠ›ï¼Œæ‚¨å¯ä»¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜ä½¿ç”¨é‡ã€‚

æœ¬æŒ‡å—å°†æ¢è®¨ [train\_lcm\_distill\_sd\_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py) è„šæœ¬ï¼Œä»¥å¸®åŠ©æ‚¨æ›´åŠ ç†Ÿæ‚‰å®ƒï¼Œä»¥åŠå¦‚ä½•æ ¹æ®è‡ªå·±çš„ç”¨ä¾‹è°ƒæ•´å®ƒã€‚

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»æºä»£ç å®‰è£…åº“ï¼š

```py
git clone https://github.com/huggingface/diffusers
cd diffusers
pip install .
```
ç„¶åå¯¼èˆªåˆ°åŒ…å«è®­ç»ƒè„šæœ¬çš„ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…æ­£åœ¨ä½¿ç”¨çš„è„šæœ¬æ‰€éœ€çš„ä¾èµ–é¡¹ï¼š

```py
cd examples/consistency_distillation
pip install -r requirements.txt
```
>ğŸ¤— Accelerate æ˜¯ä¸€ä¸ªåº“ï¼Œå¯å¸®åŠ©æ‚¨åœ¨å¤šä¸ª GPU/TPU ä¸Šæˆ–ä»¥æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒã€‚å®ƒå°†æ ¹æ®æ‚¨çš„ç¡¬ä»¶å’Œç¯å¢ƒè‡ªåŠ¨é…ç½®æ‚¨çš„è®­ç»ƒè®¾ç½®ã€‚è¯·æŸ¥çœ‹ ğŸ¤— Accelerate [Quick æ•™ç¨‹](https://huggingface.co/docs/accelerate/quicktour)ä»¥äº†è§£æ›´å¤šä¿¡æ¯ã€‚

åˆå§‹åŒ– ğŸ¤— Accelerate ç¯å¢ƒï¼ˆå°è¯•å¯ç”¨`torch.compile`ä»¥æ˜¾è‘—åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼‰ï¼š

```py
accelerate config
```
è¦åœ¨ä¸é€‰æ‹©ä»»ä½•é…ç½®çš„æƒ…å†µä¸‹è®¾ç½®é»˜è®¤ğŸ¤—çš„ Accelerate ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
accelerate config default
```
æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ç¯å¢ƒä¸æ”¯æŒäº¤äº’å¼ shellï¼ˆå¦‚ç¬”è®°æœ¬ï¼‰ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ï¼š

```py
from accelerate.utils import write_basic_config

write_basic_config()
```
æœ€åï¼Œå¦‚æœè¦åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†ï¼ˆ Create a dataset for training ï¼‰](create_dataset)æŒ‡å—ï¼Œäº†è§£å¦‚ä½•åˆ›å»ºé€‚ç”¨äºè®­ç»ƒè„šæœ¬çš„æ•°æ®é›†ã€‚

## [](#script-parameters)è„šæœ¬å‚æ•°ï¼ˆScript parametersï¼‰

>ä»¥ä¸‹éƒ¨åˆ†é‡ç‚¹ä»‹ç»äº†è®­ç»ƒè„šæœ¬ä¸­å¯¹äºäº†è§£å¦‚ä½•ä¿®æ”¹å®ƒå¾ˆé‡è¦çš„éƒ¨åˆ†ï¼Œä½†å¹¶æœªè¯¦ç»†ä»‹ç»è„šæœ¬çš„å„ä¸ªæ–¹é¢ã€‚å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·éšæ—¶é€šè¯»[è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sd_wds.py)ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–ç–‘è™‘ï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ã€‚

è®­ç»ƒè„šæœ¬æä¾›äº†è®¸å¤šå‚æ•°æ¥å¸®åŠ©æ‚¨è‡ªå®šä¹‰è®­ç»ƒè¿è¡Œã€‚æ‰€æœ‰å‚æ•°åŠå…¶æè¿°éƒ½å¯ä»¥åœ¨ [`parse_argsï¼ˆï¼‰`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L419) å‡½æ•°ä¸­æ‰¾åˆ°ã€‚æ­¤å‡½æ•°ä¸ºæ¯ä¸ªå‚æ•°æä¾›é»˜è®¤å€¼ï¼Œä¾‹å¦‚è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼ˆtraining batch sizeï¼‰å’Œå­¦ä¹ ç‡ï¼ˆ learning rateï¼‰ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦åœ¨è®­ç»ƒå‘½ä»¤ä¸­è®¾ç½®è‡ªå·±çš„å€¼ã€‚

ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ fp16 æ ¼å¼ä»¥æ··åˆç²¾åº¦åŠ é€Ÿè®­ç»ƒï¼Œè¯·å°†å‚æ•°`--mixed_precision`æ·»åŠ åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼š

```py
accelerate launch train_lcm_distill_sd_wds.py \
  --mixed_precision="fp16"
```
å¤§å¤šæ•°å‚æ•°ä¸[æ–‡ç”Ÿå›¾](text2image#script-parameters)è®­ç»ƒæŒ‡å—ä¸­çš„å‚æ•°ç›¸åŒï¼Œå› æ­¤åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‚¨å°†é‡ç‚¹ä»‹ç»ä¸æ½œåœ¨ä¸€è‡´æ€§è’¸é¦ç›¸å…³çš„å‚æ•°ã€‚

+   `--pretrained_teacher_model`ï¼šç”¨ä½œæ•™å¸ˆæ¨¡å‹çš„é¢„è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„è·¯å¾„
+   `--pretrained_vae_model_name_or_path`ï¼šé€šå¾€é¢„è®­ç»ƒ VAE çš„è·¯å¾„;å·²çŸ¥ SDXL VAE å­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§ï¼Œå› æ­¤æ­¤å‚æ•°å…è®¸æ‚¨æŒ‡å®šæ›¿ä»£ VAEï¼ˆä¾‹å¦‚ madebyollin çš„ [VAE]((https://huggingface.co/madebyollin/sdxl-vae-fp16-fix))ï¼Œå®ƒåœ¨ fp16 ä¸­å·¥ä½œï¼‰
+   `--w_min`ä»¥åŠ`--w_max`ï¼šæŒ‡å¯¼æ ‡åº¦æŠ½æ ·çš„æœ€å°å’Œæœ€å¤§æŒ‡å¯¼æ ‡åº¦å€¼
+   `--num_ddim_timesteps`ï¼šDDIM é‡‡æ ·çš„æ—¶é—´æ­¥é•¿æ•°
+   `--loss_type`ï¼šè¦è®¡ç®—æ½œåœ¨ä¸€è‡´æ€§åº¦è’¸é¦çš„æŸå¤±ç±»å‹ï¼ˆL2æˆ–Huberï¼‰;Huber æŸå¤±é€šå¸¸æ˜¯é¦–é€‰ï¼Œå› ä¸ºå®ƒå¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥
+   `--huber_c`ï¼šHuber æŸå¤±å‚æ•°

## [](#training-script)è®­ç»ƒè„šæœ¬ï¼ˆTraining scriptï¼‰

è®­ç»ƒè„šæœ¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ•°æ®é›†ç±» [`Text2ImageDataset`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L141)ï¼Œç”¨äºé¢„å¤„ç†å›¾åƒå¹¶åˆ›å»ºè®­ç»ƒæ•°æ®é›†ã€‚

```py
def transform(example):
    image = example["image"]
    image = TF.resize(image, resolution, interpolation=transforms.InterpolationMode.BILINEAR)

    c_top, c_left, _, _ = transforms.RandomCrop.get_params(image, output_size=(resolution, resolution))
    image = TF.crop(image, c_top, c_left, resolution, resolution)
    image = TF.to_tensor(image)
    image = TF.normalize(image, [0.5], [0.5])

    example["image"] = image
    return example
```
ä¸ºäº†æé«˜è¯»å–å’Œå†™å…¥å­˜å‚¨åœ¨äº‘ä¸­çš„å¤§å‹æ•°æ®é›†çš„æ€§èƒ½ï¼Œæ­¤è„šæœ¬ä½¿ç”¨ [WebDataset](https://github.com/webdataset/webdataset) æ ¼å¼åˆ›å»ºé¢„å¤„ç†ç®¡é“ä»¥åº”ç”¨è½¬æ¢å¹¶åˆ›å»ºç”¨äºè®­ç»ƒçš„æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨ã€‚å›¾åƒç»è¿‡å¤„ç†å¹¶é¦ˆé€åˆ°è®­ç»ƒå¾ªç¯ï¼Œæ— éœ€å…ˆä¸‹è½½å®Œæ•´çš„æ•°æ®é›†ã€‚

```py
processing_pipeline = [
    wds.decode("pil", handler=wds.ignore_and_continue),
    wds.rename(image="jpg;png;jpeg;webp", text="text;txt;caption", handler=wds.warn_and_continue),
    wds.map(filter_keys({"image", "text"})),
    wds.map(transform),
    wds.to_tuple("image", "text"),
]
```
åœ¨ [`mainï¼ˆï¼‰`](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L768) å‡½æ•°ä¸­ï¼ŒåŠ è½½äº†æ‰€æœ‰å¿…è¦çš„ç»„ä»¶ï¼Œå¦‚å™ªå£°è°ƒåº¦å™¨ï¼ˆnoise schedulerï¼‰ã€åˆ†è¯å™¨ï¼ˆtokenizersï¼‰ã€æ–‡æœ¬ç¼–ç å™¨ï¼ˆtext encodersï¼‰å’Œ VAEã€‚æ•™å¸ˆ UNet ä¹ŸåŠ è½½åˆ°æ­¤å¤„ï¼Œç„¶åæ‚¨å¯ä»¥ä»æ•™å¸ˆ UNet åˆ›å»ºä¸€ä¸ªå­¦ç”Ÿ UNetã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰ä¼šæ›´æ–°å­¦ç”Ÿ UNetã€‚

```py
teacher_unet = UNet2DConditionModel.from_pretrained(
    args.pretrained_teacher_model, subfolder="unet", revision=args.teacher_revision
)

unet = UNet2DConditionModel(**teacher_unet.config)
unet.load_state_dict(teacher_unet.state_dict(), strict=False)
unet.train()
```
ç°åœ¨ï¼Œæ‚¨å¯ä»¥åˆ›å»º[ä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L979)æ¥æ›´æ–° UNet å‚æ•°ï¼š

```py
optimizer = optimizer_class(
    unet.parameters(),
    lr=args.learning_rate,
    betas=(args.adam_beta1, args.adam_beta2),
    weight_decay=args.adam_weight_decay,
    eps=args.adam_epsilon,
)
```
åˆ›å»º[æ•°æ®é›†](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L994)ï¼š

```py
dataset = Text2ImageDataset(
    train_shards_path_or_url=args.train_shards_path_or_url,
    num_train_examples=args.max_train_samples,
    per_gpu_batch_size=args.train_batch_size,
    global_batch_size=args.train_batch_size * accelerator.num_processes,
    num_workers=args.dataloader_num_workers,
    resolution=args.resolution,
    shuffle_buffer_size=1000,
    pin_memory=True,
    persistent_workers=True,
)
train_dataloader = dataset.train_dataloader
```
æ¥ä¸‹æ¥ï¼Œæ‚¨å·²å‡†å¤‡å¥½è®¾ç½®[è®­ç»ƒå¾ªç¯](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1049)å¹¶å®ç°æ½œåœ¨ä¸€è‡´æ€§è’¸é¦æ–¹æ³•ï¼ˆæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬æ–‡ä¸­çš„ç®—æ³• 1ï¼‰ã€‚è„šæœ¬çš„è¿™ä¸€éƒ¨åˆ†è´Ÿè´£å‘æ½œä¼æ·»åŠ å™ªå£°ã€é‡‡æ ·å’Œåˆ›å»ºå¼•å¯¼æ ‡åº¦åµŒå…¥ï¼Œä»¥åŠä»å™ªå£°ä¸­é¢„æµ‹åŸå§‹å›¾åƒã€‚

```py
pred_x_0 = predicted_origin(
    noise_pred,
    start_timesteps,
    noisy_model_input,
    noise_scheduler.config.prediction_type,
    alpha_schedule,
    sigma_schedule,
)

model_pred = c_skip_start * noisy_model_input + c_out_start * pred_x_0
```
å®ƒè·å–[æ•™å¸ˆæ¨¡å‹é¢„æµ‹ï¼ˆteacher model predictions ï¼‰](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1172)å’Œæ¥ä¸‹æ¥çš„ [LCM é¢„æµ‹ï¼ˆ LCM predictionsï¼‰](https://github.com/huggingface/diffusers/blob/3b37488fa3280aed6a95de044d7a42ffdcb565ef/examples/consistency_distillation/train_lcm_distill_sd_wds.py#L1209)ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åå°†å…¶åå‘ä¼ æ’­åˆ° LCMã€‚

```py
if args.loss_type == "l2":
    loss = F.mse_loss(model_pred.float(), target.float(), reduction="mean")
elif args.loss_type == "huber":
    loss = torch.mean(
        torch.sqrt((model_pred.float() - target.float()) ** 2 + args.huber_c**2) - args.huber_c
    )
```
å¦‚æœæ‚¨æƒ³äº†è§£æœ‰å…³è®­ç»ƒå¾ªç¯å·¥ä½œåŸç†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[äº†è§£ç®¡é“ã€æ¨¡å‹å’Œè°ƒåº¦ç¨‹åºæ•™ç¨‹ï¼ˆUnderstanding pipelines, models and schedulers tutorial ï¼‰](../using-diffusers/write_own_pipeline)ï¼Œè¯¥æ•™ç¨‹åˆ†è§£äº†å»å™ªè¿‡ç¨‹çš„åŸºæœ¬æ¨¡å¼ã€‚

## [](#launch-the-script)å¯åŠ¨è„šæœ¬ï¼ˆLaunch the scriptï¼‰

ç°åœ¨ï¼Œæ‚¨å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬å¹¶å¼€å§‹è’¸é¦äº†ï¼

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œä½ å°†ä½¿ç”¨ `--train_shards_path_or_url` æŒ‡å®šå­˜å‚¨åœ¨ Hub ä¸Šçš„ [Conceptual Captions 12M](https://github.com/google-research-datasets/conceptual-12m) æ•°æ®é›†çš„[è·¯å¾„ã€‚](https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset)å°†ç¯å¢ƒå˜é‡`MODEL_DIR`è®¾ç½®ä¸ºæ•™å¸ˆæ¨¡å‹çš„åç§°ï¼Œå¹¶å°†`OUTPUT_DIR`è®¾ç½®ä¸ºè¦ä¿å­˜æ¨¡å‹çš„ä½ç½®ã€‚

```py
export MODEL_DIR="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="path/to/saved/model"

accelerate launch train_lcm_distill_sd_wds.py \
    --pretrained_teacher_model=$MODEL_DIR \
    --output_dir=$OUTPUT_DIR \
    --mixed_precision=fp16 \
    --resolution=512 \
    --learning_rate=1e-6 --loss_type="huber" --ema_decay=0.95 --adam_weight_decay=0.0 \
    --max_train_steps=1000 \
    --max_train_samples=4000000 \
    --dataloader_num_workers=8 \
    --train_shards_path_or_url="pipe:curl -L -s https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset/resolve/main/data/{00000..01099}.tar?download=true" \
    --validation_steps=200 \
    --checkpointing_steps=200 --checkpoints_total_limit=10 \
    --train_batch_size=12 \
    --gradient_checkpointing --enable_xformers_memory_efficient_attention \
    --gradient_accumulation_steps=1 \
    --use_8bit_adam \
    --resume_from_checkpoint=latest \
    --report_to=wandb \
    --seed=453645634 \
    --push_to_hub
```
è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°çš„ LCM è¿›è¡Œæ¨ç†ã€‚

```py
from diffusers import UNet2DConditionModel, DiffusionPipeline, LCMScheduler
import torch

unet = UNet2DConditionModel.from_pretrained("your-username/your-model", torch_dtype=torch.float16, variant="fp16")
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", unet=unet, torch_dtype=torch.float16, variant="fp16")

pipeline.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
pipeline.to("cuda")

prompt = "sushi rolls in the form of panda heads, sushi platter"

image = pipeline(prompt, num_inference_steps=4, guidance_scale=1.0).images[0]
```
## [](#lora)LoRA

LoRA æ˜¯ä¸€ç§è®­ç»ƒæŠ€æœ¯ï¼Œç”¨äºæ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚å› æ­¤ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”æ›´å®¹æ˜“å­˜å‚¨ç”Ÿæˆçš„æƒé‡ï¼Œå› ä¸ºå®ƒä»¬è¦å°å¾—å¤šï¼ˆ~100MBï¼‰ã€‚ä½¿ç”¨ [train\_lcm\_distill\_lora\_sd\_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sd_wds.py) æˆ– [train\_lcm\_distill\_lora\_sdxl.wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_lora_sdxl_wds.py) è„šæœ¬ä½¿ç”¨ LoRA è¿›è¡Œè®­ç»ƒã€‚

[LoRA åŸ¹è®­](lora)æŒ‡å—ä¸­æ›´è¯¦ç»†åœ°è®¨è®ºäº† LoRA åŸ¹è®­è„šæœ¬ã€‚

## [](#stable-diffusion-xl)Stable Diffusion XL

Stable Diffusion XL ï¼ˆSDXLï¼‰ æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶åœ¨å…¶æ¶æ„ä¸­æ·»åŠ äº†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ã€‚ä½¿ç”¨ [train\_lcm\_distill\_sdxl\_wds.py](https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/train_lcm_distill_sdxl_wds.py) è„šæœ¬é€šè¿‡ LoRA è®­ç»ƒ SDXL æ¨¡å‹ã€‚

[SDXL åŸ¹è®­](sdxl)æŒ‡å—ä¸­æ›´è¯¦ç»†åœ°è®¨è®ºäº† SDXL åŸ¹è®­è„šæœ¬ã€‚

## [](#next-steps)åç»­æ­¥éª¤

æ­å–œæ‚¨è’¸é¦å‡º LCM æ¨¡å‹ï¼è¦äº†è§£æœ‰å…³ LCM çš„æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¸‹å†…å®¹å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼š

+   äº†è§£å¦‚ä½•ä½¿ç”¨ [LCM å¯¹](../using-diffusers/lcm)æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ä»¥åŠ LoRA æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†ã€‚
+   é˜…è¯» [SDXL in 4 Steps with Latent Consistency LoRAs](https://huggingface.co/blog/lcm_lora) åšå®¢æ–‡ç« ï¼Œäº†è§£æœ‰å…³ SDXL LCM-LoRA çš„æ›´å¤šä¿¡æ¯ï¼Œä»¥å®ç°è¶…å¿«é€Ÿæ¨ç†ã€è´¨é‡æ¯”è¾ƒã€åŸºå‡†æµ‹è¯•ç­‰ã€‚