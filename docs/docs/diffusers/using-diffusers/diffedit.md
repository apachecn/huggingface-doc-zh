# å·®å¼‚ç¼–è¾‘

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/diffedit>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/diffedit>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


å›¾åƒç¼–è¾‘é€šå¸¸éœ€è¦æä¾›è¦ç¼–è¾‘åŒºåŸŸçš„æ©æ¨¡ã€‚ DiffEdit æ ¹æ®æ–‡æœ¬æŸ¥è¯¢è‡ªåŠ¨ä¸ºæ‚¨ç”Ÿæˆè’™ç‰ˆï¼Œä»è€Œæ— éœ€å›¾åƒç¼–è¾‘è½¯ä»¶å³å¯æ›´è½»æ¾åœ°åˆ›å»ºè’™ç‰ˆã€‚ DiffEdit ç®—æ³•åˆ†ä¸‰ä¸ªæ­¥éª¤å·¥ä½œï¼š


1. æ‰©æ•£æ¨¡å‹ä»¥æŸäº›æŸ¥è¯¢æ–‡æœ¬å’Œå‚è€ƒæ–‡æœ¬ä¸ºæ¡ä»¶å¯¹å›¾åƒè¿›è¡Œå»å™ªï¼Œè¿™å¯¹å›¾åƒçš„ä¸åŒåŒºåŸŸäº§ç”Ÿä¸åŒçš„å™ªå£°ä¼°è®¡ï¼›å·®å¼‚ç”¨äºæ¨æ–­æ©ç ï¼Œä»¥è¯†åˆ«éœ€è¦æ›´æ”¹å›¾åƒçš„å“ªä¸ªåŒºåŸŸä»¥åŒ¹é…æŸ¥è¯¢æ–‡æœ¬
2.ä½¿ç”¨DDIMå°†è¾“å…¥å›¾åƒç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­
3. ä½¿ç”¨ä»¥æ–‡æœ¬æŸ¥è¯¢ä¸ºæ¡ä»¶çš„æ‰©æ•£æ¨¡å‹å¯¹æ½œä¼è¿›è¡Œè§£ç ï¼Œä½¿ç”¨æ©æ¨¡ä½œä¸ºæŒ‡å¯¼ï¼Œä½¿å¾—æ©æ¨¡å¤–çš„åƒç´ ä¿æŒä¸è¾“å…¥å›¾åƒä¸­çš„ç›¸åŒ


æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ DiffEdit ç¼–è¾‘å›¾åƒï¼Œè€Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºè’™ç‰ˆã€‚


åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š



```
# uncomment to install the necessary libraries in Colab
#!pip install diffusers transformers accelerate safetensors
```


è¿™
 [StableDiffusionDiffEditPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)
 éœ€è¦ä¸€ä¸ªå›¾åƒæ©æ¨¡å’Œä¸€ç»„éƒ¨åˆ†åè½¬çš„æ½œåœ¨å˜é‡ã€‚å›¾åƒæ©æ¨¡æ˜¯ä»ç”Ÿæˆçš„
 [generate\_mask()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
 å‡½æ•°ï¼Œå¹¶åŒ…å«ä¸¤ä¸ªå‚æ•°ï¼Œ
 `æºæç¤º`
 å’Œ
 `ç›®æ ‡æç¤º`
 ã€‚è¿™äº›å‚æ•°å†³å®šäº†è¦åœ¨å›¾åƒä¸­ç¼–è¾‘çš„å†…å®¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³æ¢ä¸€ç¢—
 *æ°´æœ*
 åˆ°ä¸€ç¢—
 *æ¢¨*
 ï¼Œ ç„¶åï¼š



```
source_prompt = "a bowl of fruits"
target_prompt = "a bowl of pears"
```


éƒ¨åˆ†åè½¬çš„æ½œä¼æ˜¯ä»
 [invert()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
 å‡½æ•°ï¼Œé€šå¸¸æœ€å¥½åŒ…å«ä¸€ä¸ª
 `æç¤º`
 æˆ–è€…
 *æ ‡é¢˜*
 æè¿°å›¾åƒä»¥å¸®åŠ©æŒ‡å¯¼é€†æ½œåœ¨é‡‡æ ·è¿‡ç¨‹ã€‚æ ‡é¢˜é€šå¸¸å¯ä»¥æ˜¯ä½ çš„
 `æºæç¤º`
 ï¼Œä½†è¯·éšæ„å°è¯•å…¶ä»–æ–‡å­—æè¿°ï¼


è®©æˆ‘ä»¬åŠ è½½ç®¡é“ã€è°ƒåº¦ç¨‹åºã€é€†è°ƒåº¦ç¨‹åºï¼Œå¹¶å¯ç”¨ä¸€äº›ä¼˜åŒ–ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼š



```
import torch
from diffusers import DDIMScheduler, DDIMInverseScheduler, StableDiffusionDiffEditPipeline

pipeline = StableDiffusionDiffEditPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1",
    torch_dtype=torch.float16,
    safety_checker=None,
    use_safetensors=True,
)
pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)
pipeline.enable_model_cpu_offload()
pipeline.enable_vae_slicing()
```


åŠ è½½å›¾åƒè¿›è¡Œç¼–è¾‘ï¼š



```
from diffusers.utils import load_image

img_url = "https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png"
raw_image = load_image(img_url).convert("RGB").resize((768, 768))
```


ä½¿ç”¨
 [generate\_mask()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
 å‡½æ•°æ¥ç”Ÿæˆå›¾åƒæ©æ¨¡ã€‚æ‚¨éœ€è¦å°†å…¶ä¼ é€’ç»™
 `æºæç¤º`
 å’Œ
 `ç›®æ ‡æç¤º`
 æŒ‡å®šè¦åœ¨å›¾åƒä¸­ç¼–è¾‘çš„å†…å®¹ï¼š



```
source_prompt = "a bowl of fruits"
target_prompt = "a basket of pears"
mask_image = pipeline.generate_mask(
    image=raw_image,
    source_prompt=source_prompt,
    target_prompt=target_prompt,
)
```


æ¥ä¸‹æ¥ï¼Œåˆ›å»ºåè½¬æ½œåœ¨å˜é‡å¹¶å‘å…¶ä¼ é€’æè¿°å›¾åƒçš„æ ‡é¢˜ï¼š



```
inv_latents = pipeline.invert(prompt=source_prompt, image=raw_image).latents
```


æœ€åï¼Œå°†å›¾åƒæ©æ¨¡å’Œåè½¬æ½œä¼ä¼ é€’åˆ°ç®¡é“ã€‚è¿™
 `ç›®æ ‡æç¤º`
 æˆä¸º
 `æç¤º`
 ç°åœ¨ï¼Œä»¥åŠ
 `æºæç¤º`
 è¢«ç”¨ä½œ
 `å¦å®šæç¤º`
 :



```
image = pipeline(
    prompt=target_prompt,
    mask_image=mask_image,
    image_latents=inv_latents,
    negative_prompt=source_prompt,
).images[0]
image.save("edited\_image.png")
```


![](https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png)

 åŸå§‹å›¾åƒ


![](https://github.com/Xiang-cd/DiffEdit-stable-diffusion/blob/main/assets/target.png?raw=true)

 ç¼–è¾‘åçš„å›¾åƒ


## ç”ŸæˆæºåµŒå…¥å’Œç›®æ ‡åµŒå…¥



æºåµŒå…¥å’Œç›®æ ‡åµŒå…¥å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è‡ªåŠ¨ç”Ÿæˆ
 [Flan-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5)
 æ¨¡å‹è€Œä¸æ˜¯æ‰‹åŠ¨åˆ›å»ºå®ƒä»¬ã€‚


ä» ğŸ¤— Transformers åº“åŠ è½½ Flan-T5 æ¨¡å‹å’Œåˆ†è¯å™¨ï¼š



```
import torch
from transformers import AutoTokenizer, T5ForConditionalGeneration

tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-xl")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-xl", device_map="auto", torch_dtype=torch.float16)
```


æä¾›ä¸€äº›åˆå§‹æ–‡æœ¬ä»¥æç¤ºæ¨¡å‹ç”Ÿæˆæºæç¤ºå’Œç›®æ ‡æç¤ºã€‚



```
source_concept = "bowl"
target_concept = "basket"

source_text = f"Provide a caption for images containing a {source\_concept}. "
"The captions should be in English and should be no longer than 150 characters."

target_text = f"Provide a caption for images containing a {target\_concept}. "
"The captions should be in English and should be no longer than 150 characters."
```


æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªå®ç”¨å‡½æ•°æ¥ç”Ÿæˆæç¤ºï¼š



```
@torch.no\_grad
def generate\_prompts(input\_prompt):
    input_ids = tokenizer(input_prompt, return_tensors="pt").input_ids.to("cuda")

    outputs = model.generate(
        input_ids, temperature=0.8, num_return_sequences=16, do_sample=True, max_new_tokens=128, top_k=10
    )
    return tokenizer.batch_decode(outputs, skip_special_tokens=True)

source_prompts = generate_prompts(source_text)
target_prompts = generate_prompts(target_text)
print(source_prompts)
print(target_prompts)
```


æŸ¥çœ‹
 [ç”Ÿæˆç­–ç•¥](https://huggingface.co/docs/transformers/main/en/Generation_strategies)
 å¦‚æœæ‚¨æœ‰å…´è¶£äº†è§£æœ‰å…³ç”Ÿæˆä¸åŒè´¨é‡æ–‡æœ¬çš„ç­–ç•¥çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æŒ‡å—ã€‚


åŠ è½½ä½¿ç”¨çš„æ–‡æœ¬ç¼–ç å™¨æ¨¡å‹
 [StableDiffusionDiffEditPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline)
 å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ã€‚æ‚¨å°†ä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨æ¥è®¡ç®—æ–‡æœ¬åµŒå…¥ï¼š



```
import torch 
from diffusers import StableDiffusionDiffEditPipeline 

pipeline = StableDiffusionDiffEditPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-1", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
pipeline.enable_vae_slicing()

@torch.no\_grad()
def embed\_prompts(sentences, tokenizer, text\_encoder, device="cuda"):
    embeddings = []
    for sent in sentences:
        text_inputs = tokenizer(
            sent,
            padding="max\_length",
            max_length=tokenizer.model_max_length,
            truncation=True,
            return_tensors="pt",
        )
        text_input_ids = text_inputs.input_ids
        prompt_embeds = text_encoder(text_input_ids.to(device), attention_mask=None)[0]
        embeddings.append(prompt_embeds)
    return torch.concatenate(embeddings, dim=0).mean(dim=0).unsqueeze(0)

source_embeds = embed_prompts(source_prompts, pipeline.tokenizer, pipeline.text_encoder)
target_embeds = embed_prompts(target_prompts, pipeline.tokenizer, pipeline.text_encoder)
```


æœ€åï¼Œå°†åµŒå…¥ä¼ é€’ç»™
 [generate\_mask()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.generate_mask)
 å’Œ
 [invert()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
 å‡½æ•°å’Œç”Ÿæˆå›¾åƒçš„ç®¡é“ï¼š



```
  from diffusers import DDIMInverseScheduler, DDIMScheduler
  from diffusers.utils import load_image

  pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
  pipeline.inverse_scheduler = DDIMInverseScheduler.from_config(pipeline.scheduler.config)

  img_url = "https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png"
  raw_image = load_image(img_url).convert("RGB").resize((768, 768))


  mask_image = pipeline.generate_mask(
      image=raw_image,
+ source\_prompt\_embeds=source\_embeds,
+ target\_prompt\_embeds=target\_embeds,
  )

  inv_latents = pipeline.invert(
+ prompt\_embeds=source\_embeds,
      image=raw_image,
  ).latents

  images = pipeline(
      mask_image=mask_image,
      image_latents=inv_latents,
+ prompt\_embeds=target\_embeds,
+ negative\_prompt\_embeds=source\_embeds,
  ).images
  images[0].save("edited_image.png")
```


## ç”Ÿæˆåè½¬æ ‡é¢˜



è™½ç„¶æ‚¨å¯ä»¥ä½¿ç”¨
 `æºæç¤º`
 ä½œä¸ºå¸®åŠ©ç”Ÿæˆéƒ¨åˆ†åè½¬æ½œåœ¨å˜é‡çš„æ ‡é¢˜ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨
 [BLIP](https://huggingface.co/docs/transformers/model_doc/blip)
 æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜ã€‚


ä» Transformers åº“åŠ è½½ BLIP æ¨¡å‹å’Œå¤„ç†å™¨ï¼š



```
import torch
from transformers import BlipForConditionalGeneration, BlipProcessor

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base", torch_dtype=torch.float16, low_cpu_mem_usage=True)
```


åˆ›å»ºä¸€ä¸ªå®ç”¨å‡½æ•°ä»¥ä»è¾“å…¥å›¾åƒç”Ÿæˆæ ‡é¢˜ï¼š



```
@torch.no\_grad()
def generate\_caption(images, caption\_generator, caption\_processor):
    text = "a photograph of"

    inputs = caption_processor(images, text, return_tensors="pt").to(device="cuda", dtype=caption_generator.dtype)
    caption_generator.to("cuda")
    outputs = caption_generator.generate(**inputs, max_new_tokens=128)

    # offload caption generator
    caption_generator.to("cpu")

    caption = caption_processor.batch_decode(outputs, skip_special_tokens=True)[0]
    return caption
```


åŠ è½½è¾“å…¥å›¾åƒå¹¶ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸ºå…¶ç”Ÿæˆæ ‡é¢˜
 `ç”Ÿæˆæ ‡é¢˜`
 åŠŸèƒ½ï¼š



```
from diffusers.utils import load_image

img_url = "https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png"
raw_image = load_image(img_url).convert("RGB").resize((768, 768))
caption = generate_caption(raw_image, model, processor)
```


![](https://github.com/Xiang-cd/DiffEdit-stable-diffusion/raw/main/assets/origin.png)

 ç”Ÿæˆçš„æ ‡é¢˜ï¼šâ€œæ¡Œå­ä¸Šä¸€ç¢—æ°´æœçš„ç…§ç‰‡â€


ç°åœ¨æ‚¨å¯ä»¥å°†æ ‡é¢˜æ”¾å…¥
 [invert()](/docs/diffusers/v0.23.0/en/api/pipelines/diffedit#diffusers.StableDiffusionDiffEditPipeline.invert)
 å‡½æ•°æ¥ç”Ÿæˆéƒ¨åˆ†åè½¬çš„æ½œåœ¨å˜é‡ï¼