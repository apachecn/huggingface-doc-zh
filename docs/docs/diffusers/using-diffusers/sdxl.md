# ç¨³å®šæ‰©æ•£XL

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/sdxl>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/sdxl>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


[ç¨³å®šæ‰©æ•£XL](https://huggingface.co/papers/2307.01952)
 (SDXL) æ˜¯ä¸€ç§å¼ºå¤§çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä»¥ä¸‰ç§å…³é”®æ–¹å¼è¿­ä»£ä»¥å‰çš„ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼š


1. UNet å¢å¤§ 3 å€ï¼ŒSDXL å°†ç¬¬äºŒä¸ªæ–‡æœ¬ç¼–ç å™¨ (OpenCLIP ViT-bigG/14) ä¸åŸå§‹æ–‡æœ¬ç¼–ç å™¨ç›¸ç»“åˆï¼Œæ˜¾ç€å¢åŠ å‚æ•°æ•°é‡
2. å¼•å…¥å°ºå¯¸å’Œè£å‰ªè°ƒèŠ‚ï¼Œä»¥é˜²æ­¢è®­ç»ƒæ•°æ®è¢«ä¸¢å¼ƒï¼Œå¹¶æ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆå›¾åƒçš„è£å‰ªæ–¹å¼
3.å¼•å…¥ä¸¤é˜¶æ®µæ¨¡å‹è¿‡ç¨‹ï¼›è¿™
 *æ ¹æ®*
 æ¨¡å‹ï¼ˆä¹Ÿå¯ä»¥ä½œä¸ºç‹¬ç«‹æ¨¡å‹è¿è¡Œï¼‰ç”Ÿæˆå›¾åƒä½œä¸ºè¾“å…¥
 *ç²¾ç‚¼æœº*
 æ·»åŠ é¢å¤–é«˜å“è´¨ç»†èŠ‚çš„æ¨¡å‹


æœ¬æŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨ SDXL è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤ã€‚


åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š



```
# uncomment to install the necessary libraries in Colab
#!pip install diffusers transformers accelerate safetensors omegaconf invisible-watermark>=0.2.0
```


æˆ‘ä»¬å»ºè®®å®‰è£…
 [éšå½¢æ°´å°](https://pypi.org/project/invisible-watermark/)
 åº“æ¥å¸®åŠ©è¯†åˆ«ç”Ÿæˆçš„å›¾åƒã€‚å¦‚æœå®‰è£…äº†invisible-watermarkåº“ï¼Œåˆ™é»˜è®¤ä½¿ç”¨å®ƒã€‚è¦ç¦ç”¨æ°´å°ï¼š



```
pipeline = StableDiffusionXLPipeline.from_pretrained(..., add_watermarker=False)
```


## åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹



æ¨¡å‹æƒé‡å¯èƒ½å­˜å‚¨åœ¨ Hub ä¸Šæˆ–æœ¬åœ°çš„å•ç‹¬å­æ–‡ä»¶å¤¹ä¸­ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨
 [æ¥è‡ª\_pretrained()](/docs/diffusers/v0.23.0/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained)
 æ–¹æ³•ï¼š



```
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, use_safetensors=True, variant="fp16"
).to("cuda")
```


æ‚¨è¿˜å¯ä»¥ä½¿ç”¨
 [æ¥è‡ª\_single\_file()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline.from_single_file)
 åŠ è½½ä»¥å•ä¸ªæ–‡ä»¶æ ¼å¼å­˜å‚¨çš„æ¨¡å‹æ£€æŸ¥ç‚¹çš„æ–¹æ³•ï¼ˆ
 `.ckpt`
 æˆ–è€…
 `.safetensors`
 ) ä»ä¸­å¿ƒæˆ–æœ¬åœ°ï¼š



```
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_single_file(
    "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd\_xl\_base\_1.0.safetensors", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLImg2ImgPipeline.from_single_file(
    "https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/blob/main/sd\_xl\_refiner\_1.0.safetensors", torch_dtype=torch.float16, use_safetensors=True, variant="fp16"
).to("cuda")
```


## æ–‡æœ¬è½¬å›¾åƒ



å¯¹äºæ–‡æœ¬åˆ°å›¾åƒï¼Œè¯·ä¼ é€’æ–‡æœ¬æç¤ºã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒSDXL ç”Ÿæˆ 1024x1024 å›¾åƒä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚æ‚¨å¯ä»¥å°è¯•è®¾ç½®
 `é«˜åº¦`
 å’Œ
 `å®½åº¦`
 å‚æ•°è®¾ç½®ä¸º 768x768 æˆ– 512x512ï¼Œä½†ä½äº 512x512 çš„ä»»ä½•å€¼éƒ½ä¸å¤ªå¯èƒ½å·¥ä½œã€‚



```
from diffusers import AutoPipelineForText2Image
import torch

pipeline_text2image = AutoPipelineForText2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipeline(prompt=prompt).images[0]
```


![ç”Ÿæˆçš„ä¸›æ—ä¸­å®‡èˆªå‘˜å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png)


## å›¾åƒåˆ°å›¾åƒ



å¯¹äºå›¾åƒåˆ°å›¾åƒï¼ŒSDXL ç‰¹åˆ«é€‚ç”¨äº 768x768 å’Œ 1024x1024 ä¹‹é—´çš„å›¾åƒå°ºå¯¸ã€‚ä¼ é€’åˆå§‹å›¾åƒå’Œæ–‡æœ¬æç¤ºä»¥è°ƒèŠ‚å›¾åƒï¼š



```
from diffusers import AutoPipelineForImg2Img
from diffusers.utils import load_image

# use from\_pipe to avoid consuming additional memory when loading a checkpoint
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline_text2image).to("cuda")
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-img2img.png"

init_image = load_image(url).convert("RGB")
prompt = "a dog catching a frisbee in the jungle"
image = pipeline(prompt, image=init_image, strength=0.8, guidance_scale=10.5).images[0]
```


![ç”Ÿæˆçš„ä¸€åªç‹—åœ¨ä¸›æ—ä¸­æŠ“é£ç›˜çš„å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-img2img.png)


## ä¿®å¤



å¯¹äºä¿®å¤ï¼Œæ‚¨éœ€è¦åŸå§‹å›¾åƒå’Œè¦åœ¨åŸå§‹å›¾åƒä¸­æ›¿æ¢çš„å†…å®¹çš„è’™ç‰ˆã€‚åˆ›å»ºä¸€ä¸ªæç¤ºæ¥æè¿°æ‚¨æƒ³è¦ç”¨ä»€ä¹ˆæ¥æ›¿æ¢é®ç½©åŒºåŸŸã€‚



```
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image

# use from\_pipe to avoid consuming additional memory when loading a checkpoint
pipeline = AutoPipelineForInpainting.from_pipe(pipeline_text2image).to("cuda")

img_url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png"
mask_url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png"

init_image = load_image(img_url).convert("RGB")
mask_image = load_image(mask_url).convert("RGB")

prompt = "A deep sea diver floating"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.85, guidance_scale=12.5).images[0]
```


![ä¸›æ—ä¸­æ·±æµ·æ½œæ°´å‘˜çš„ç”Ÿæˆå›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint.png)


## æé«˜å›¾åƒè´¨é‡



SDXL åŒ…æ‹¬ä¸€ä¸ª
 [ç²¾ç‚¼æ¨¡å‹](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0)
 ä¸“é—¨ç”¨äºå¯¹ä½å™ªå£°é˜¶æ®µå›¾åƒè¿›è¡Œå»å™ªï¼Œä»¥ä»åŸºç¡€æ¨¡å‹ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚ç²¾ç‚¼æœºæœ‰ä¸¤ç§ä½¿ç”¨æ–¹æ³•ï¼š


1. ç»“åˆä½¿ç”¨åŸºç¡€æ¨¡å‹å’Œç»†åŒ–å™¨æ¨¡å‹æ¥ç”Ÿæˆç»†åŒ–å›¾åƒ
2. ä½¿ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œéšåä½¿ç”¨ç»†åŒ–æ¨¡å‹ä¸ºå›¾åƒæ·»åŠ æ›´å¤šç»†èŠ‚ï¼ˆè¿™å°±æ˜¯ SDXL æœ€åˆçš„è®­ç»ƒæ–¹å¼ï¼‰


### 


 åŸºç¡€+ç²¾ç‚¼æœºæ¨¡å‹


å½“æ‚¨åŒæ—¶ä½¿ç”¨åŸºç¡€æ¨¡å‹å’Œç²¾åŒ–æ¨¡å‹æ¥ç”Ÿæˆå›¾åƒæ—¶ï¼Œè¿™ç§°ä¸º (
 [*ä¸“å®¶é™å™ªå™¨é›†åˆ*](https://research.nvidia.com/labs/dir/eDiff-I/)
 ï¼‰ã€‚ä¸å°†åŸºæœ¬æ¨¡å‹çš„è¾“å‡ºä¼ é€’ç»™ç²¾åŒ–å™¨æ¨¡å‹ç›¸æ¯”ï¼Œä¸“å®¶é™å™ªå™¨æ–¹æ³•çš„é›†åˆéœ€è¦æ›´å°‘çš„æ•´ä½“é™å™ªæ­¥éª¤ï¼Œå› æ­¤å®ƒçš„è¿è¡Œé€Ÿåº¦åº”è¯¥è¦å¿«å¾—å¤šã€‚ä½†æ˜¯ï¼Œæ‚¨å°†æ— æ³•æ£€æŸ¥åŸºæœ¬æ¨¡å‹çš„è¾“å‡ºï¼Œå› ä¸ºå®ƒä»ç„¶åŒ…å«å¤§é‡å™ªå£°ã€‚


ä½œä¸ºä¸“å®¶é™å™ªå™¨çš„é›†åˆï¼ŒåŸºç¡€æ¨¡å‹åœ¨é«˜å™ªå£°æ‰©æ•£é˜¶æ®µå……å½“ä¸“å®¶ï¼Œç»†åŒ–å™¨æ¨¡å‹åœ¨ä½å™ªå£°æ‰©æ•£é˜¶æ®µå……å½“ä¸“å®¶ã€‚åŠ è½½åŸºç¡€æ¨¡å‹å’Œä¼˜åŒ–å™¨æ¨¡å‹ï¼š



```
from diffusers import DiffusionPipeline
import torch

base = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")
```


è¦ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œæ‚¨éœ€è¦å®šä¹‰æ¯ä¸ªæ¨¡å‹è¿è¡Œå„è‡ªé˜¶æ®µçš„æ—¶é—´æ­¥æ•°ã€‚å¯¹äºåŸºæœ¬æ¨¡å‹ï¼Œè¿™æ˜¯ç”±
 [`denoising_end`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.denoising_end)
 å‚æ•°ï¼Œå¯¹äºç²¾ç‚¼æœºæ¨¡å‹ï¼Œå®ƒç”±
 [`denoising_start`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline.__call__.denoising_start)
 èŒƒå›´ã€‚


è¿™
 `å»å™ªç»“æŸ`
 å’Œ
 `å»å™ª_å¼€å§‹`
 å‚æ•°åº”è¯¥æ˜¯ 0 åˆ° 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚è¿™äº›å‚æ•°è¡¨ç¤ºä¸ºè°ƒåº¦ç¨‹åºå®šä¹‰çš„ç¦»æ•£æ—¶é—´æ­¥é•¿çš„æ¯”ä¾‹ã€‚å¦‚æœæ‚¨ä¹Ÿä½¿ç”¨
 â€˜åŠ›é‡â€™
 å‚æ•°ï¼Œå®ƒå°†è¢«å¿½ç•¥ï¼Œå› ä¸ºå»å™ªæ­¥éª¤çš„æ•°é‡æ˜¯ç”±æ¨¡å‹è®­ç»ƒçš„ç¦»æ•£æ—¶é—´æ­¥é•¿å’Œå£°æ˜çš„åˆ†æ•°æˆªæ­¢å€¼å†³å®šçš„ã€‚


è®©æˆ‘ä»¬è®¾ç½®ä¸€ä¸‹
 `å»å™ªç»“æŸ=0.8`
 æ‰€ä»¥åŸºç¡€æ¨¡å‹æ‰§è¡Œå‰ 80% çš„å»å™ª
 **é«˜å™ªéŸ³**
 æ—¶é—´æ­¥é•¿å’Œè®¾ç½®
 `å»å™ª_å¼€å§‹=0.8`
 å› æ­¤ï¼Œç²¾ç‚¼æ¨¡å‹æ‰§è¡Œæœ€å 20% çš„å»å™ª
 **ä½å™ªå£°**
 æ—¶é—´æ­¥é•¿ã€‚åŸºæœ¬æ¨¡å‹è¾“å‡ºåº”è¯¥æ˜¯
 **æ½œ**
 ç©ºé—´è€Œä¸æ˜¯ PIL å›¾åƒã€‚



```
prompt = "A majestic lion jumping from a big stone at night"

image = base(
    prompt=prompt,
    num_inference_steps=40,
    denoising_end=0.8,
    output_type="latent",
).images
image = refiner(
    prompt=prompt,
    num_inference_steps=40,
    denoising_start=0.8,
    image=image,
).images[0]
```


![ç”Ÿæˆçš„å¤œé—´å²©çŸ³ä¸Šçš„ç‹®å­å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lion_base.png)

 åŸºç¡€æ¨¡å‹


![ä»¥æ›´é«˜çš„è´¨é‡ç”Ÿæˆå¤œé—´å²©çŸ³ä¸Šçš„ç‹®å­å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lion_refined.png)

 ä¸“å®¶é™å™ªå™¨é›†åˆ


ç²¾ç‚¼æœºæ¨¡å‹è¿˜å¯ç”¨äºä¿®å¤
 [StableDiffusionXLInpaintPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline)
 :



```
from diffusers import StableDiffusionXLInpaintPipeline
from diffusers.utils import load_image

base = StableDiffusionXLInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = StableDiffusionXLInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=pipe.text_encoder_2,
    vae=pipe.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo\_mask.png"

init_image = load_image(img_url).convert("RGB")
mask_image = load_image(mask_url).convert("RGB")

prompt = "A majestic tiger sitting on a bench"
num_inference_steps = 75
high_noise_frac = 0.7

image = base(
    prompt=prompt,
    image=init_image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_end=high_noise_frac,
    output_type="latent",
).images
image = refiner(
    prompt=prompt,
    image=image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_start=high_noise_frac,
).images[0]
```


è¿™ç§ä¸“å®¶é™å™ªæ–¹æ³•çš„é›†åˆé€‚ç”¨äºæ‰€æœ‰å¯ç”¨çš„è°ƒåº¦ç¨‹åºï¼


### 


 ä»åŸºç¡€åˆ°ç²¾ç‚¼æ¨¡å‹


SDXL é€šè¿‡åœ¨å›¾åƒåˆ°å›¾åƒè®¾ç½®ä¸­ä½¿ç”¨ç»†åŒ–å™¨æ¨¡å‹å‘åŸºæœ¬æ¨¡å‹çš„å®Œå…¨å»å™ªå›¾åƒæ·»åŠ é¢å¤–çš„é«˜è´¨é‡ç»†èŠ‚ï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡ã€‚


åŠ è½½åŸºç¡€æ¨¡å‹å’Œç²¾ç‚¼æ¨¡å‹ï¼š



```
from diffusers import DiffusionPipeline
import torch

base = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

refiner = DiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0",
    text_encoder_2=pipe.text_encoder_2,
    vae=pipe.vae,
    torch_dtype=torch.float16,
    use_safetensors=True,
    variant="fp16",
).to("cuda")
```


ä»åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œå¹¶å°†æ¨¡å‹è¾“å‡ºè®¾ç½®ä¸º
 **æ½œ**
 ç©ºé—´ï¼š



```
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

image = base(prompt=prompt, output_type="latent").images[0]
```


å°†ç”Ÿæˆçš„å›¾åƒä¼ é€’ç»™ç»†åŒ–å™¨æ¨¡å‹ï¼š



```
image = refiner(prompt=prompt, image=image[None, :]).images[0]
```


![ç”Ÿæˆçš„å®‡èˆªå‘˜åœ¨ç«æ˜Ÿä¸Šéª‘ç€ç»¿é©¬çš„å›¾åƒ](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/init_image.png)

 åŸºç¡€æ¨¡å‹


![åœ¨ç«æ˜Ÿä¸Šéª‘ç€ç»¿é©¬çš„å®‡èˆªå‘˜çš„æ›´é«˜è´¨é‡å›¾åƒ](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/refined_image.png)

 åŸºç¡€æ¨¡å‹+ç²¾ç‚¼æ¨¡å‹


å¯¹äºä¿®å¤ï¼Œå°†ç²¾ç‚¼å™¨æ¨¡å‹åŠ è½½åˆ°
 [StableDiffusionXLInpaintPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline)
 ï¼Œ å»é™¤
 `å»å™ªç»“æŸ`
 å’Œ
 `å»å™ª_å¼€å§‹`
 å‚æ•°ï¼Œå¹¶ä¸ºç»†åŒ–å™¨é€‰æ‹©è¾ƒå°‘æ•°é‡çš„æ¨ç†æ­¥éª¤ã€‚


## å¾®è°ƒèŠ‚



SDXL è®­ç»ƒæ¶‰åŠå‡ ç§é¢å¤–çš„è°ƒèŠ‚æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯è¢«ç§°ä¸º
 *å¾®è°ƒèŠ‚*
 ã€‚å…¶ä¸­åŒ…æ‹¬åŸå§‹å›¾åƒå¤§å°ã€ç›®æ ‡å›¾åƒå¤§å°å’Œè£å‰ªå‚æ•°ã€‚å¾®è°ƒèŠ‚å¯åœ¨æ¨ç†æ—¶ç”¨äºåˆ›å»ºé«˜è´¨é‡çš„å±…ä¸­å›¾åƒã€‚


å€ŸåŠ©æ— åˆ†ç±»å™¨çš„æŒ‡å¯¼ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å¾®è°ƒèŠ‚å’Œè´Ÿå¾®è°ƒèŠ‚å‚æ•°ã€‚å®ƒä»¬å¯ä»¥åœ¨
 [StableDiffusionXLPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline)
 ,
 [StableDiffusionXLImg2ImgPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline)
 ,
 [StableDiffusionXLInpaintPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline)
 ï¼Œ å’Œ
 [StableDiffusionXLControlNetPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/controlnet_sdxl#diffusers.StableDiffusionXLControlNetPipeline)
 ã€‚



### 


 å°ºå¯¸è°ƒèŠ‚


å°ºå¯¸è°ƒèŠ‚æœ‰ä¸¤ç§ç±»å‹ï¼š


* [`original_size`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.original_size)
 è°ƒèŠ‚æ¥è‡ªè®­ç»ƒæ‰¹æ¬¡ä¸­çš„æ”¾å¤§å›¾åƒï¼ˆå› ä¸ºä¸¢å¼ƒå æ€»è®­ç»ƒæ•°æ®è¿‘ 40% çš„è¾ƒå°å›¾åƒä¼šå¾ˆæµªè´¹ï¼‰ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒSDXL äº†è§£åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒä¸­ä¸åº”å‡ºç°æ”¾å¤§ä¼ªå½±ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨
 `åŸå§‹å¤§å°`
 è¡¨ç¤ºåŸå§‹å›¾åƒçš„åˆ†è¾¨ç‡ã€‚ä½¿ç”¨é»˜è®¤å€¼
 `(1024, 1024)`
 ç”Ÿæˆç±»ä¼¼äºæ•°æ®é›†ä¸­çš„ 1024x1024 å›¾åƒçš„æ›´é«˜è´¨é‡çš„å›¾åƒã€‚å¦‚æœæ‚¨é€‰æ‹©ä½¿ç”¨è¾ƒä½çš„åˆ†è¾¨ç‡ï¼Œä¾‹å¦‚
 `(256, 256)`
 ï¼Œæ¨¡å‹ä»ç„¶ç”Ÿæˆ 1024x1024 å›¾åƒï¼Œä½†å®ƒä»¬çœ‹èµ·æ¥åƒæ•°æ®é›†ä¸­çš„ä½åˆ†è¾¨ç‡å›¾åƒï¼ˆæ›´ç®€å•çš„å›¾æ¡ˆï¼Œæ¨¡ç³Šï¼‰ã€‚
* [`target_size`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.target_size)
 è°ƒèŠ‚æ¥è‡ªå¾®è°ƒ SDXL ä»¥æ”¯æŒä¸åŒçš„å›¾åƒé•¿å®½æ¯”ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¦‚æœä½¿ç”¨é»˜è®¤å€¼
 `(1024, 1024)`
 ï¼Œæ‚¨å°†è·å¾—ç±»ä¼¼äºæ•°æ®é›†ä¸­æ–¹å½¢å›¾åƒç»„æˆçš„å›¾åƒã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨ç›¸åŒçš„å€¼
 `ç›®æ ‡å¤§å°`
 å’Œ
 `åŸå§‹å¤§å°`
 ï¼Œä½†è¯·éšæ„å°è¯•å…¶ä»–é€‰é¡¹ï¼


ğŸ¤— Diffusers è¿˜å…è®¸æ‚¨æŒ‡å®šæœ‰å…³å›¾åƒå¤§å°çš„è´Ÿé¢æ¡ä»¶ï¼Œä»¥å¼•å¯¼ç”Ÿæˆè¿œç¦»æŸäº›å›¾åƒåˆ†è¾¨ç‡ï¼š



```
from diffusers import StableDiffusionXLPipeline
import torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipe(
    prompt=prompt,
    negative_original_size=(512, 512),
    negative_target_size=(1024, 1024),
).images[0]
```


![](https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/negative_conditions.png)

 è´Ÿç‰‡å›¾åƒçš„å›¾åƒåˆ†è¾¨ç‡ä¸º (128, 128)ã€(256, 256) å’Œ (512, 512)ã€‚
 

###


 ä½œç‰©è°ƒç†


ä»¥å‰çš„ç¨³å®šæ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒæœ‰æ—¶å¯èƒ½ä¼šè¢«è£å‰ªã€‚è¿™æ˜¯å› ä¸ºå›¾åƒå®é™…ä¸Šåœ¨è®­ç»ƒæœŸé—´è¢«è£å‰ªï¼Œä»¥ä¾¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å›¾åƒå…·æœ‰ç›¸åŒçš„å¤§å°ã€‚é€šè¿‡è°ƒæ•´è£å‰ªåæ ‡ï¼ŒSDXL
 *å­¦ä¹ *
 æ²¡æœ‰è£å‰ª - åæ ‡
 `(0, 0)`
 - é€šå¸¸ä¸å±…ä¸­ä¸»ä½“å’Œå®Œæ•´é¢éƒ¨ç›¸å…³ï¼ˆè¿™æ˜¯ ğŸ¤— æ¼«å°„å™¨ä¸­çš„é»˜è®¤å€¼ï¼‰ã€‚å¦‚æœæ‚¨æƒ³ç”Ÿæˆåå¿ƒçš„æ„å›¾ï¼Œæ‚¨å¯ä»¥å°è¯•ä¸åŒçš„åæ ‡ï¼



```
from diffusers import StableDiffusionXLPipeline
import torch


pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipeline(prompt=prompt, crops_coords_top_left=(256,0)).images[0]
```


![ç”Ÿæˆçš„ä¸›æ—ä¸­å®‡èˆªå‘˜å›¾åƒï¼Œç¨ä½œè£å‰ª](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-cropped.png)


 æ‚¨è¿˜å¯ä»¥æŒ‡å®šè´Ÿè£å‰ªåæ ‡ä»¥å¼•å¯¼ç”Ÿæˆè¿œç¦»æŸäº›è£å‰ªå‚æ•°ï¼š



```
from diffusers import StableDiffusionXLPipeline
import torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image = pipe(
    prompt=prompt,
    negative_original_size=(512, 512),
    negative_crops_coords_top_left=(0, 0),
    negative_target_size=(1024, 1024),
).images[0]
```


## ä¸ºæ¯ä¸ªæ–‡æœ¬ç¼–ç å™¨ä½¿ç”¨ä¸åŒçš„æç¤º



SDXL ä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œå› æ­¤å¯ä»¥å‘æ¯ä¸ªæ–‡æœ¬ç¼–ç å™¨ä¼ é€’ä¸åŒçš„æç¤ºï¼Œè¿™å¯ä»¥
 [æé«˜è´¨é‡](https://github.com/huggingface/diffusers/issues/4004#issuecomment-1627764201)
 ã€‚å°†æ‚¨çš„åŸå§‹æç¤ºä¼ é€’ç»™
 `æç¤º`
 ç¬¬äºŒä¸ªæç¤º
 `æç¤º_2`
 ï¼ˆä½¿ç”¨
 `å¦å®šæç¤º`
 å’Œ
 `å¦å®šæç¤º_2`
 å¦‚æœæ‚¨ä½¿ç”¨å¦å®šæç¤ºï¼‰ï¼š



```
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")

# prompt is passed to OAI CLIP-ViT/L-14
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
# prompt\_2 is passed to OpenCLIP-ViT/bigG-14
prompt_2 = "Van Gogh painting"
image = pipeline(prompt=prompt, prompt_2=prompt_2).images[0]
```


![ä»¥æ¢µé«˜ç»˜ç”»é£æ ¼ç”Ÿæˆçš„ä¸›æ—ä¸­å®‡èˆªå‘˜å›¾åƒ](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-double-prompt.png)


 åŒæ–‡æœ¬ç¼–ç å™¨è¿˜æ”¯æŒéœ€è¦å•ç‹¬åŠ è½½çš„æ–‡æœ¬åè½¬åµŒå…¥ï¼Œå¦‚ [SDXL æ–‡æœ¬åè½¬](textual\_inversion\_inference#stable-diffusion-xl] éƒ¨åˆ†ä¸­æ‰€è¿°ã€‚


## ä¼˜åŒ–



SDXL æ˜¯ä¸€ä¸ªå¤§å‹æ¨¡å‹ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¼˜åŒ–å†…å­˜æ‰èƒ½ä½¿å…¶åœ¨æ‚¨çš„ç¡¬ä»¶ä¸Šè¿è¡Œã€‚ä»¥ä¸‹æ˜¯ä¸€äº›èŠ‚çœå†…å­˜å’ŒåŠ å¿«æ¨ç†é€Ÿåº¦çš„æŠ€å·§ã€‚


1. å°†æ¨¡å‹å¸è½½åˆ° CPU
 [å¯ç”¨\_model\_cpu\_offload()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
 å¯¹äºå†…å­˜ä¸è¶³é”™è¯¯ï¼š



```
- base.to("cuda")
- refiner.to("cuda")
+ base.enable\_model\_cpu\_offload
+ refiner.enable\_model\_cpu\_offload
```


2. ä½¿ç”¨
 `torch.ç¼–è¯‘`
 å¤§çº¦ 20% çš„åŠ é€Ÿï¼ˆä½ éœ€è¦
 `torch>2.0`
 ï¼‰ï¼š



```
+ base.unet = torch.compile(base.unet, mode="reduce-overhead", fullgraph=True)
+ refiner.unet = torch.compile(refiner.unet, mode="reduce-overhead", fullgraph=True)
```


3. å¯ç”¨
 [xFormers](/ä¼˜åŒ–/xformers)
 è¿è¡Œ SDXL å¦‚æœ
 `torch<2.0`
 :



```
+ base.enable\_xformers\_memory\_efficient\_attention()
+ refiner.enable\_xformers\_memory\_efficient\_attention()
```


## å…¶ä»–èµ„æº



å¦‚æœæ‚¨æœ‰å…´è¶£å°è¯•æœ€å°ç‰ˆæœ¬
 [UNet2DConditionModel](/docs/diffusers/v0.23.0/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel)
 åœ¨ SDXL ä¸­ä½¿ç”¨ï¼Œçœ‹çœ‹
 [minSDXL](https://github.com/cloneofsimo/minSDXL)
 ç”¨ PyTorch ç¼–å†™çš„å®ç°ï¼Œä¸ ğŸ¤— Diffusers ç›´æ¥å…¼å®¹ã€‚