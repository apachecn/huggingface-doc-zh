# è°ƒåº¦ç¨‹åº

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/schedulers>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/schedulers>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


æ‰©æ•£ç®¡é“æœ¬è´¨ä¸Šæ˜¯å½¼æ­¤éƒ¨åˆ†ç‹¬ç«‹çš„æ‰©æ•£æ¨¡å‹å’Œè°ƒåº¦å™¨çš„é›†åˆã€‚è¿™æ„å‘³ç€äººä»¬èƒ½å¤Ÿåˆ‡æ¢éƒ¨åˆ†ç®¡é“ä»¥æ›´å¥½åœ°å®šåˆ¶
é€šå¾€æŸä¸ªç”¨ä¾‹çš„ç®¡é“ã€‚æœ€å¥½çš„ä¾‹å­å°±æ˜¯
 [è°ƒåº¦ç¨‹åº](../api/schedulers/æ¦‚è¿°)
 ã€‚


è€Œæ‰©æ•£æ¨¡å‹é€šå¸¸ç®€å•åœ°å®šä¹‰ä»å™ªå£°åˆ°å™ªå£°è¾ƒå°æ ·æœ¬çš„å‰å‘ä¼ æ’­ï¼Œ
è°ƒåº¦ç¨‹åºå®šä¹‰æ•´ä¸ªå»å™ªè¿‡ç¨‹ï¼Œ
 *IEã€‚*
 :


* é™å™ªæ­¥éª¤æœ‰å¤šå°‘ï¼Ÿ
* éšæœºæ€§è¿˜æ˜¯ç¡®å®šæ€§ï¼Ÿ
* ä½¿ç”¨ä»€ä¹ˆç®—æ³•æ¥æŸ¥æ‰¾å»å™ªæ ·æœ¬ï¼Ÿ


å®ƒä»¬å¯èƒ½éå¸¸å¤æ‚ï¼Œå¹¶ä¸”ç»å¸¸å®šä¹‰ä¹‹é—´çš„æƒè¡¡
 **å»å™ªé€Ÿåº¦**
 å’Œ
 **é™å™ªè´¨é‡**
 ã€‚
å®šé‡æµ‹é‡å“ªä¸ªè°ƒåº¦ç¨‹åºæœ€é€‚åˆç»™å®šçš„æ‰©æ•£ç®¡é“æ˜¯æå…¶å›°éš¾çš„ï¼Œå› æ­¤é€šå¸¸å»ºè®®ç®€å•åœ°å°è¯•å“ªä¸ªæœ€æœ‰æ•ˆã€‚


ä»¥ä¸‹æ®µè½å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ ğŸ§¨ Diffusers åº“æ‰§è¡Œæ­¤æ“ä½œã€‚


## åŠ è½½ç®¡é“



è®©æˆ‘ä»¬ä»åŠ è½½å¼€å§‹
 [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 æ¨¡å‹ä¸­çš„
 [DiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 :



```
from huggingface_hub import login
from diffusers import DiffusionPipeline
import torch

login()

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
```


æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å…¶ç§»è‡³ GPUï¼š



```
pipeline.to("cuda")
```


## è®¿é—®è°ƒåº¦ç¨‹åº



è°ƒåº¦å™¨å§‹ç»ˆæ˜¯ç®¡é“çš„ç»„ä»¶ä¹‹ä¸€ï¼Œé€šå¸¸ç§°ä¸º
 `â€œè°ƒåº¦ç¨‹åºâ€`
 ã€‚
å› æ­¤å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®å®ƒ
 `â€œè°ƒåº¦ç¨‹åºâ€`
 è´¢äº§ã€‚



```
pipeline.scheduler
```


**è¾“å‡º**
 :



```
PNDMScheduler {
  "\_class\_name": "PNDMScheduler",
  "\_diffusers\_version": "0.21.4",
  "beta\_end": 0.012,
  "beta\_schedule": "scaled\_linear",
  "beta\_start": 0.00085,
  "clip\_sample": false,
  "num\_train\_timesteps": 1000,
  "set\_alpha\_to\_one": false,
  "skip\_prk\_steps": true,
  "steps\_offset": 1,
  "timestep\_spacing": "leading",
  "trained\_betas": null
}
```


æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è°ƒåº¦å™¨çš„ç±»å‹æ˜¯
 [PNDMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/pndm#diffusers.PNDMScheduler)
 ã€‚
å¤ªé…·äº†ï¼Œç°åœ¨è®©æˆ‘ä»¬å°†è°ƒåº¦ç¨‹åºçš„æ€§èƒ½ä¸å…¶ä»–è°ƒåº¦ç¨‹åºè¿›è¡Œæ¯”è¾ƒã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæç¤ºï¼Œæˆ‘ä»¬å°†åœ¨å…¶ä¸Šæµ‹è¯•æ‰€æœ‰ä¸åŒçš„è°ƒåº¦ç¨‹åºï¼š



```
prompt = "A photograph of an astronaut riding a horse on Mars, high resolution, high definition."
```


æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»éšæœºç§å­åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨ï¼Œè¿™å°†ç¡®ä¿æˆ‘ä»¬å¯ä»¥ç”Ÿæˆç›¸ä¼¼çš„å›¾åƒå¹¶è¿è¡Œç®¡é“ï¼š



```
generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_pndm.png)


## æ›´æ”¹è°ƒåº¦ç¨‹åº



ç°åœ¨æˆ‘ä»¬å±•ç¤ºæ›´æ”¹ç®¡é“çš„è°ƒåº¦ç¨‹åºæ˜¯å¤šä¹ˆå®¹æ˜“ã€‚æ¯ä¸ªè°ƒåº¦ç¨‹åºéƒ½æœ‰ä¸€ä¸ªå±æ€§
 `å…¼å®¹æœº`
 å®ƒå®šä¹‰äº†æ‰€æœ‰å…¼å®¹çš„è°ƒåº¦ç¨‹åºã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ç¨³å®šæ‰©æ•£ç®¡é“çš„æ‰€æœ‰å¯ç”¨ã€å…¼å®¹çš„è°ƒåº¦ç¨‹åºï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚



```
pipeline.scheduler.compatibles
```


**è¾“å‡º**
 :



```
[diffusers.utils.dummy\_torch\_and\_torchsde\_objects.DPMSolverSDEScheduler,
 diffusers.schedulers.scheduling\_euler\_discrete.EulerDiscreteScheduler,
 diffusers.schedulers.scheduling\_lms\_discrete.LMSDiscreteScheduler,
 diffusers.schedulers.scheduling\_ddim.DDIMScheduler,
 diffusers.schedulers.scheduling\_ddpm.DDPMScheduler,
 diffusers.schedulers.scheduling\_heun\_discrete.HeunDiscreteScheduler,
 diffusers.schedulers.scheduling\_dpmsolver\_multistep.DPMSolverMultistepScheduler,
 diffusers.schedulers.scheduling\_deis\_multistep.DEISMultistepScheduler,
 diffusers.schedulers.scheduling\_pndm.PNDMScheduler,
 diffusers.schedulers.scheduling\_euler\_ancestral\_discrete.EulerAncestralDiscreteScheduler,
 diffusers.schedulers.scheduling\_unipc\_multistep.UniPCMultistepScheduler,
 diffusers.schedulers.scheduling\_k\_dpm\_2\_discrete.KDPM2DiscreteScheduler,
 diffusers.schedulers.scheduling\_dpmsolver\_singlestep.DPMSolverSinglestepScheduler,
 diffusers.schedulers.scheduling\_k\_dpm\_2\_ancestral\_discrete.KDPM2AncestralDiscreteScheduler]
```


å¾ˆé…·ï¼Œæœ‰å¾ˆå¤šè°ƒåº¦ç¨‹åºå¯ä¾›æŸ¥çœ‹ã€‚è¯·éšæ„æŸ¥çœ‹å®ƒä»¬å„è‡ªçš„ç±»å®šä¹‰ï¼š


* [EulerDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
 ,
* [LMSDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)
 ,
* [DDIMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/ddim#diffusers.DDIMScheduler)
 ,
* [DDPMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/ddpm#diffusers.DDPMScheduler)
 ,
* [HeunDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/heun#diffusers.HeunDiscreteScheduler)
 ,
* [DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)
 ,
* [DEISMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/deis#diffusers.DEISMultistepScheduler)
 ,
* [PNDMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/pndm#diffusers.PNDMScheduler)
 ,
* [EulerAncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler_ancestral#diffusers.EulerAncestralDiscreteScheduler)
 ,
* [UniPCMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/unipc#diffusers.UniPCMultistepScheduler)
 ,
* [KDPM2DiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete#diffusers.KDPM2DiscreteScheduler)
 ,
* [DPMSolverSinglestepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/singlestep_dpm_solver#diffusers.DPMSolverSinglestepScheduler)
 ,
* [KDPM2AncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/dpm_discrete_ancestral#diffusers.KDPM2AncestralDiscreteScheduler)
 ã€‚


æˆ‘ä»¬ç°åœ¨å°†è¾“å…¥æç¤ºä¸æ‰€æœ‰å…¶ä»–è°ƒåº¦ç¨‹åºè¿›è¡Œæ¯”è¾ƒã€‚è¦æ›´æ”¹ç®¡é“çš„è°ƒåº¦ç¨‹åºï¼Œæ‚¨å¯ä»¥ä½¿ç”¨
æ–¹ä¾¿çš„
 `é…ç½®`
 å±æ€§ç»“åˆ
 [from\_config()](/docs/diffusers/v0.23.0/en/api/configuration#diffusers.ConfigMixin.from_config)
 åŠŸèƒ½ã€‚



```
pipeline.scheduler.config
```


è¿”å›è°ƒåº¦ç¨‹åºé…ç½®çš„å­—å…¸ï¼š


**è¾“å‡º**
 :



```
FrozenDict([('num\_train\_timesteps', 1000),
            ('beta\_start', 0.00085),
            ('beta\_end', 0.012),
            ('beta\_schedule', 'scaled\_linear'),
            ('trained\_betas', None),
            ('skip\_prk\_steps', True),
            ('set\_alpha\_to\_one', False),
            ('prediction\_type', 'epsilon'),
            ('timestep\_spacing', 'leading'),
            ('steps\_offset', 1),
            ('\_use\_default\_values', ['timestep\_spacing', 'prediction\_type']),
            ('\_class\_name', 'PNDMScheduler'),
            ('\_diffusers\_version', '0.21.4'),
            ('clip\_sample', False)])
```


ç„¶åå¯ä»¥ä½¿ç”¨æ­¤é…ç½®æ¥å®ä¾‹åŒ–è°ƒåº¦ç¨‹åº
ä¸ç®¡é“å…¼å®¹çš„ä¸åŒç±»ã€‚è¿™é‡Œï¼Œ
æˆ‘ä»¬å°†è°ƒåº¦ç¨‹åºæ›´æ”¹ä¸º
 [DDIMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/ddim#diffusers.DDIMScheduler)
 ã€‚



```
from diffusers import DDIMScheduler

pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)
```


å¤ªé…·äº†ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å†æ¬¡è¿è¡Œç®¡é“æ¥æ¯”è¾ƒç”Ÿæˆè´¨é‡ã€‚



```
generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_ddim.png)


 å¦‚æœæ‚¨æ˜¯ JAX/Flax ç”¨æˆ·ï¼Œè¯·æ£€æŸ¥
 [æœ¬èŠ‚](#change-the-scheduler-in-flax)
 åè€Œã€‚


## æ¯”è¾ƒè°ƒåº¦ç¨‹åº



åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å°è¯•ä½¿ç”¨ä¸¤ä¸ªè°ƒåº¦ç¨‹åºè¿è¡Œç¨³å®šçš„æ‰©æ•£ç®¡é“ï¼š
 [PNDMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/pndm#diffusers.PNDMScheduler)
 å’Œ
 [DDIMScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/ddim#diffusers.DDIMScheduler)
 ã€‚
è®¸å¤šæ›´å¥½çš„è°ƒåº¦ç¨‹åºå·²ç»å‘å¸ƒï¼Œå¯ä»¥ç”¨æ›´å°‘çš„æ­¥éª¤è¿è¡Œï¼›è®©æˆ‘ä»¬åœ¨è¿™é‡Œæ¯”è¾ƒä¸€ä¸‹å®ƒä»¬ï¼š


[LMSDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/lms_discrete#diffusers.LMSDiscreteScheduler)
 é€šå¸¸ä¼šå¸¦æ¥æ›´å¥½çš„ç»“æœï¼š



```
from diffusers import LMSDiscreteScheduler

pipeline.scheduler = LMSDiscreteScheduler.from_config(pipeline.scheduler.config)

generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_lms.png)


[EulerDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler#diffusers.EulerDiscreteScheduler)
 å’Œ
 [EulerAncestralDiscreteScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/euler_ancestral#diffusers.EulerAncestralDiscreteScheduler)
 åªéœ€ 30 ä¸ªæ­¥éª¤å³å¯ç”Ÿæˆé«˜è´¨é‡ç»“æœã€‚



```
from diffusers import EulerDiscreteScheduler

pipeline.scheduler = EulerDiscreteScheduler.from_config(pipeline.scheduler.config)

generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator, num_inference_steps=30).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_euler_discrete.png)


 å’Œï¼š



```
from diffusers import EulerAncestralDiscreteScheduler

pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)

generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator, num_inference_steps=30).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_euler_ancestral.png)


[DPMSolverMultistepScheduler](/docs/diffusers/v0.23.0/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)
 ç»™å‡ºäº†åˆç†çš„é€Ÿåº¦/è´¨é‡æƒè¡¡ï¼Œå¹¶ä¸”åªéœ€ 20 ä¸ªæ­¥éª¤å³å¯è¿è¡Œã€‚



```
from diffusers import DPMSolverMultistepScheduler

pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)

generator = torch.Generator(device="cuda").manual_seed(8)
image = pipeline(prompt, generator=generator, num_inference_steps=20).images[0]
image
```


![](https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/diffusers_docs/astronaut_dpm.png)


 æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œå¤§å¤šæ•°å›¾åƒçœ‹èµ·æ¥éå¸¸ç›¸ä¼¼ï¼Œè€Œä¸”è´¨é‡ä¹Ÿå¯ä»¥è¯´éå¸¸ç›¸ä¼¼ã€‚è¿™é€šå¸¸å®é™…ä¸Šå–å†³äºé€‰æ‹©å“ªä¸ªè°ƒåº¦ç¨‹åºçš„å…·ä½“ç”¨ä¾‹ã€‚ä¸€ä¸ªå¥½çš„æ–¹æ³•å§‹ç»ˆæ˜¯è¿è¡Œå¤šä¸ªä¸åŒçš„
è°ƒåº¦ç¨‹åºæ¥æ¯”è¾ƒç»“æœã€‚


## æ›´æ”¹ Flax ä¸­çš„è°ƒåº¦ç¨‹åº



å¦‚æœæ‚¨æ˜¯ JAX/Flax ç”¨æˆ·ï¼Œè¿˜å¯ä»¥æ›´æ”¹é»˜è®¤ç®¡é“è°ƒåº¦ç¨‹åºã€‚è¿™æ˜¯å¦‚ä½•ä½¿ç”¨ Flax Stable Diffusion pipeline å’Œè¶…å¿«è¿è¡Œæ¨ç†çš„å®Œæ•´ç¤ºä¾‹
 [DPM-Solver++ è°ƒåº¦ç¨‹åº](../api/schedulers/multistep_dpm_solver)
 :



```
import jax
import numpy as np
from flax.jax_utils import replicate
from flax.training.common_utils import shard

from diffusers import FlaxStableDiffusionPipeline, FlaxDPMSolverMultistepScheduler

model_id = "runwayml/stable-diffusion-v1-5"
scheduler, scheduler_state = FlaxDPMSolverMultistepScheduler.from_pretrained(
    model_id,
    subfolder="scheduler"
)
pipeline, params = FlaxStableDiffusionPipeline.from_pretrained(
    model_id,
    scheduler=scheduler,
    revision="bf16",
    dtype=jax.numpy.bfloat16,
)
params["scheduler"] = scheduler_state

# Generate 1 image per parallel device (8 on TPUv2-8 or TPUv3-8)
prompt = "a photo of an astronaut riding a horse on mars"
num_samples = jax.device_count()
prompt_ids = pipeline.prepare_inputs([prompt] * num_samples)

prng_seed = jax.random.PRNGKey(0)
num_inference_steps = 25

# shard inputs and rng
params = replicate(params)
prng_seed = jax.random.split(prng_seed, jax.device_count())
prompt_ids = shard(prompt_ids)

images = pipeline(prompt_ids, params, prng_seed, num_inference_steps, jit=True).images
images = pipeline.numpy_to_pil(np.asarray(images.reshape((num_samples,) + images.shape[-3:])))
```


ä»¥ä¸‹ Flax è°ƒåº¦ç¨‹åºæ˜¯
 *å°šä¸å…¼å®¹*
 ä½¿ç”¨äºšéº»ç¨³å®šæ‰©æ•£ç®¡é“ï¼š


* `FlaxLMSç¦»æ•£è°ƒåº¦å™¨`
* `FlaxDDPMScheduler`