# åˆ›å»ºå¯é‡å¤çš„ç®¡é“

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/reproducibility>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/reproducibility>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


å†ç°æ€§å¯¹äºæµ‹è¯•ã€å¤åˆ¶ç»“æœéå¸¸é‡è¦ï¼Œç”šè‡³å¯ä»¥ç”¨äº
 [æé«˜å›¾åƒè´¨é‡](reusing_seeds)
 ã€‚ç„¶è€Œï¼Œæ‰©æ•£æ¨¡å‹ä¸­çš„éšæœºæ€§æ˜¯ä¸€ä¸ªç†æƒ³çš„å±æ€§ï¼Œå› ä¸ºå®ƒå…è®¸ç®¡é“æ¯æ¬¡è¿è¡Œæ—¶ç”Ÿæˆä¸åŒçš„å›¾åƒã€‚è™½ç„¶æ‚¨ä¸èƒ½æœŸæœ›è·¨å¹³å°è·å¾—å®Œå…¨ç›¸åŒçš„ç»“æœï¼Œä½†æ‚¨å¯ä»¥æœŸæœ›ç»“æœåœ¨ä¸€å®šçš„å®¹å·®èŒƒå›´å†…è·¨ç‰ˆæœ¬å’Œå¹³å°å¯é‡ç°ã€‚å³ä¾¿å¦‚æ­¤ï¼Œå®¹å¿åº¦ä¹Ÿä¼šæ ¹æ®æ‰©æ•£ç®¡é“å’Œæ£€æŸ¥ç‚¹çš„ä¸åŒè€Œæœ‰æ‰€ä¸åŒã€‚


è¿™å°±æ˜¯ä¸ºä»€ä¹ˆäº†è§£å¦‚ä½•æ§åˆ¶æ‰©æ•£æ¨¡å‹ä¸­çš„éšæœºæºæˆ–ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•å¾ˆé‡è¦ã€‚


ğŸ’¡ æˆ‘ä»¬å¼ºçƒˆå»ºè®®é˜…è¯» PyTorch çš„
 [å…³äºå†ç°æ€§çš„å£°æ˜](https://pytorch.org/docs/stable/notes/randomness.html)
 :


>
>
> ä¸ä¿è¯åœ¨ PyTorch ç‰ˆæœ¬ã€å•ç‹¬æäº¤æˆ–ä¸åŒå¹³å°ä¸Šè·å¾—å®Œå…¨å¯é‡ç°çš„ç»“æœã€‚æ­¤å¤–ï¼Œå³ä½¿ä½¿ç”¨ç›¸åŒçš„ç§å­ï¼ŒCPU å’Œ GPU æ‰§è¡Œä¹‹é—´çš„ç»“æœä¹Ÿå¯èƒ½æ— æ³•é‡ç°ã€‚
>
>
>
>


## æ§åˆ¶éšæœºæ€§



åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç®¡é“ä¸¥é‡ä¾èµ–éšæœºé‡‡æ ·æ“ä½œï¼Œå…¶ä¸­åŒ…æ‹¬åˆ›å»º
é«˜æ–¯å™ªå£°å¼ é‡ç”¨äºå»å™ªå¹¶å‘è°ƒåº¦æ­¥éª¤æ·»åŠ å™ªå£°ã€‚


çœ‹ä¸€ä¸‹ä¸­çš„å¼ é‡å€¼
 [DDIMPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/ddim#diffusers.DDIMPipeline)
 ç»è¿‡ä¸¤ä¸ªæ¨ç†æ­¥éª¤åï¼š



```
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np").images
print(np.abs(image).sum())
```


è¿è¡Œä¸Šé¢çš„ä»£ç ä¼šæ‰“å°ä¸€ä¸ªå€¼ï¼Œä½†å¦‚æœå†æ¬¡è¿è¡Œå®ƒï¼Œæ‚¨ä¼šå¾—åˆ°ä¸€ä¸ªä¸åŒçš„å€¼ã€‚è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ


æ¯æ¬¡è¿è¡Œç®¡é“æ—¶ï¼Œ
 [`torch.randn`](https://pytorch.org/docs/stable/generated/torch.randn.html)
 ä½¿ç”¨ä¸åŒçš„éšæœºç§å­æ¥åˆ›å»ºé€æ­¥å»å™ªçš„é«˜æ–¯å™ªå£°ã€‚è¿™ä¼šå¯¼è‡´æ¯æ¬¡è¿è¡Œæ—¶éƒ½ä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œè¿™å¯¹äºæ‰©æ•£ç®¡é“éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒæ¯æ¬¡éƒ½ä¼šç”Ÿæˆä¸åŒçš„éšæœºå›¾åƒã€‚


ä½†å¦‚æœæ‚¨éœ€è¦å¯é åœ°ç”Ÿæˆç›¸åŒçš„å›¾åƒï¼Œè¿™å°†å–å†³äºæ‚¨æ˜¯åœ¨ CPU è¿˜æ˜¯ GPU ä¸Šè¿è¡Œç®¡é“ã€‚


### 


 ä¸­å¤®å¤„ç†å™¨


è¦åœ¨ CPU ä¸Šç”Ÿæˆå¯é‡ç°çš„ç»“æœï¼Œæ‚¨éœ€è¦ä½¿ç”¨ PyTorch
 [`ç”Ÿæˆå™¨`](https://pytorch.org/docs/stable/generated/torch.randn.html)
 å¹¶è®¾ç½®ç§å­ï¼š



```
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)

# create a generator for reproducibility
generator = torch.Generator(device="cpu").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```


ç°åœ¨ï¼Œå½“æ‚¨è¿è¡Œä¸Šé¢çš„ä»£ç æ—¶ï¼Œå®ƒæ€»æ˜¯æ‰“å°ä¸€ä¸ªå€¼
 `1491.1711`
 æ— è®ºå¦‚ä½•ï¼Œå› ä¸º
 `å‘ç”µæœº`
 å¸¦æœ‰ç§å­çš„å¯¹è±¡è¢«ä¼ é€’ç»™ç®¡é“çš„æ‰€æœ‰éšæœºå‡½æ•°ã€‚


å¦‚æœæ‚¨åœ¨ç‰¹å®šç¡¬ä»¶å’Œ PyTorch ç‰ˆæœ¬ä¸Šè¿è¡Œæ­¤ä»£ç ç¤ºä¾‹ï¼Œæ‚¨åº”è¯¥ä¼šå¾—åˆ°ç±»ä¼¼ï¼ˆå¦‚æœä¸ç›¸åŒï¼‰çš„ç»“æœã€‚


ğŸ’¡ ä¸€å¼€å§‹é€šè¿‡å¯èƒ½æœ‰ç‚¹ä¸ç›´è§‚
 `å‘ç”µæœº`
 å¯¹è±¡åˆ°ç®¡é“è€Œä¸æ˜¯
åªæ˜¯ä»£è¡¨ç§å­çš„æ•´æ•°å€¼ï¼Œä½†è¿™æ˜¯å¤„ç†æ—¶æ¨èçš„è®¾è®¡
PyTorch ä¸­çš„æ¦‚ç‡æ¨¡å‹ä¸º
 `å‘ç”µæœº`
 æ˜¯
 *éšæœºçŠ¶æ€*
 é‚£å¯ä»¥æ˜¯
æŒ‰é¡ºåºä¼ é€’åˆ°å¤šä¸ªç®¡é“ã€‚



### 


 å›¾å½¢å¤„ç†å™¨


åœ¨ GPU ä¸Šç¼–å†™å¯é‡ç°çš„ç®¡é“æœ‰ç‚¹æ£˜æ‰‹ï¼Œå¹¶ä¸”æ— æ³•ä¿è¯è·¨ä¸åŒç¡¬ä»¶çš„å®Œå…¨é‡ç°æ€§ï¼Œå› ä¸ºçŸ©é˜µä¹˜æ³•ï¼ˆæ‰©æ•£ç®¡é“éœ€è¦å¤§é‡è¿ç®—ï¼‰åœ¨ GPU ä¸Šçš„ç¡®å®šæ€§ä¸å¦‚ CPUã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åœ¨ GPU ä¸Šè¿è¡Œä¸Šé¢ç›¸åŒçš„ä»£ç ç¤ºä¾‹ï¼š



```
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility
generator = torch.Generator(device="cuda").manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```


å³ä½¿æ‚¨ä½¿ç”¨ç›¸åŒçš„ç§å­ï¼Œç»“æœä¹Ÿä¸ä¸€æ ·ï¼Œå› ä¸º GPU ä½¿ç”¨ä¸ CPU ä¸åŒçš„éšæœºæ•°ç”Ÿæˆå™¨ã€‚


ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼ŒğŸ§¨ Diffusers æœ‰ä¸€ä¸ª
 `randn_tensor()`
 ç”¨äºåœ¨ CPU ä¸Šåˆ›å»ºéšæœºå™ªå£°çš„å‡½æ•°ï¼Œç„¶ååœ¨å¿…è¦æ—¶å°†å¼ é‡ç§»åŠ¨åˆ° GPUã€‚è¿™
 `randn_å¼ é‡`
 å‡½æ•°åœ¨ç®¡é“å†…çš„ä»»ä½•åœ°æ–¹ä½¿ç”¨ï¼Œå…è®¸ç”¨æˆ·
 **æ€»æ˜¯**
 é€šè¿‡CPU
 `å‘ç”µæœº`
 å³ä½¿ç®¡é“åœ¨ GPU ä¸Šè¿è¡Œã€‚


æ‚¨ä¼šå‘ç°ç»“æœç°åœ¨æ›´åŠ æ¥è¿‘äº†ï¼



```
import torch
from diffusers import DDIMPipeline
import numpy as np

model_id = "google/ddpm-cifar10-32"

# load model and scheduler
ddim = DDIMPipeline.from_pretrained(model_id, use_safetensors=True)
ddim.to("cuda")

# create a generator for reproducibility; notice you don't place it on the GPU!
generator = torch.manual_seed(0)

# run pipeline for just two steps and return numpy tensor
image = ddim(num_inference_steps=2, output_type="np", generator=generator).images
print(np.abs(image).sum())
```


ğŸ’¡ å¦‚æœå¯é‡å¤æ€§å¾ˆé‡è¦ï¼Œæˆ‘ä»¬å»ºè®®å§‹ç»ˆé€šè¿‡ CPU ç”Ÿæˆå™¨ã€‚
æ€§èƒ½æŸå¤±é€šå¸¸å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå¹¶ä¸”æ‚¨ä¼šç”Ÿæˆæ›´å¤šç±»ä¼¼çš„ç»“æœ
å€¼ä¸ç®¡é“åœ¨ GPU ä¸Šè¿è¡Œæ—¶çš„å€¼ç›¸æ¯”ã€‚


æœ€åï¼Œå¯¹äºæ›´å¤æ‚çš„ç®¡é“ï¼Œä¾‹å¦‚
 [UnCLIPPipeline](/docs/diffusers/v0.23.1/en/api/pipelines/unclip#diffusers.UnCLIPPipeline)
 ï¼Œè¿™äº›å¾€å¾€æ˜¯æå…¶
å®¹æ˜“å—åˆ°ç²¾åº¦è¯¯å·®ä¼ æ’­çš„å½±å“ã€‚ä¸è¦æŒ‡æœ›ä¼šå‡ºç°ç±»ä¼¼çš„ç»“æœ
ä¸åŒçš„ GPU ç¡¬ä»¶æˆ– PyTorch ç‰ˆæœ¬ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦è¿è¡Œ
å®Œå…¨ç›¸åŒçš„ç¡¬ä»¶å’Œ PyTorch ç‰ˆæœ¬ï¼Œå¯å®ç°å®Œå…¨é‡ç°æ€§ã€‚


## ç¡®å®šæ€§ç®—æ³•



æ‚¨è¿˜å¯ä»¥å°† PyTorch é…ç½®ä¸ºä½¿ç”¨ç¡®å®šæ€§ç®—æ³•æ¥åˆ›å»ºå¯é‡ç°çš„ç®¡é“ã€‚ä½†æ˜¯ï¼Œæ‚¨åº”è¯¥æ„è¯†åˆ°ç¡®å®šæ€§ç®—æ³•å¯èƒ½æ¯”éç¡®å®šæ€§ç®—æ³•æ…¢ï¼Œå¹¶ä¸”æ‚¨å¯èƒ½ä¼šè§‚å¯Ÿåˆ°æ€§èƒ½ä¸‹é™ã€‚ä½†å¦‚æœå¯é‡å¤æ€§å¯¹æ‚¨æ¥è¯´å¾ˆé‡è¦ï¼Œé‚£ä¹ˆè¿™å°±æ˜¯æ­£ç¡®çš„é€‰æ‹©ï¼


å½“åœ¨å¤šä¸ª CUDA æµä¸­å¯åŠ¨æ“ä½œæ—¶ï¼Œä¼šå‡ºç°ä¸ç¡®å®šæ€§è¡Œä¸ºã€‚ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
 [`CUBLAS_WORKSPACE_CONFIG`](https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility)
 åˆ°
 `:16:8`
 åœ¨è¿è¡Œæ—¶ä»…ä½¿ç”¨ä¸€ç§ç¼“å†²åŒºå¤§å°ã€‚


PyTorch é€šå¸¸ä¼šå¯¹å¤šç§ç®—æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ä»¥é€‰æ‹©æœ€å¿«çš„ç®—æ³•ï¼Œä½†å¦‚æœæ‚¨æƒ³è¦å¯é‡å¤æ€§ï¼Œåˆ™åº”è¯¥ç¦ç”¨æ­¤åŠŸèƒ½ï¼Œå› ä¸ºåŸºå‡†æµ‹è¯•å¯èƒ½æ¯æ¬¡éƒ½ä¼šé€‰æ‹©ä¸åŒçš„ç®—æ³•ã€‚æœ€åï¼Œé€šè¿‡
 'çœŸå®'
 åˆ°
 [`torch.use_definistic_algorithms`](https://pytorch.org/docs/stable/generated/torch.use_definistic_algorithms.html)
 å¯ç”¨ç¡®å®šæ€§ç®—æ³•ã€‚



```
import os

os.environ["CUBLAS\_WORKSPACE\_CONFIG"] = ":16:8"

torch.backends.cudnn.benchmark = False
torch.use_deterministic_algorithms(True)
```


ç°åœ¨ï¼Œå½“æ‚¨è¿è¡Œç›¸åŒçš„ç®¡é“ä¸¤æ¬¡æ—¶ï¼Œæ‚¨å°†è·å¾—ç›¸åŒçš„ç»“æœã€‚



```
import torch
from diffusers import DDIMScheduler, StableDiffusionPipeline
import numpy as np

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True).to("cuda")
pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
g = torch.Generator(device="cuda")

prompt = "A bear is playing a guitar on Times Square"

g.manual_seed(0)
result1 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

g.manual_seed(0)
result2 = pipe(prompt=prompt, num_inference_steps=50, generator=g, output_type="latent").images

print("L\_inf dist = ", abs(result1 - result2).max())
"L\_inf dist = tensor(0., device='cuda:0')"
```