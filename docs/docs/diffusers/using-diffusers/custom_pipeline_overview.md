# åŠ è½½ç¤¾åŒºç®¡é“å’Œç»„ä»¶

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/custom_pipeline_overview>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


## ç¤¾åŒºç®¡é“



ç¤¾åŒºç®¡é“æ˜¯ä»»ä½•
 [DiffusionPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/overview#diffusers.DiffusionPipeline)
 ä¸è®ºæ–‡ä¸­æŒ‡å®šçš„åŸå§‹å®ç°ä¸åŒçš„ç±»ï¼ˆä¾‹å¦‚ï¼Œ
 [StableDiffusionControlNetPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/controlnet#diffusers.StableDiffusionControlNetPipeline)
 å¯¹åº”äº
 [ä½¿ç”¨ ControlNet è°ƒèŠ‚ç”Ÿæˆæ–‡æœ¬åˆ°å›¾åƒ](https://arxiv.org/abs/2302.05543)
 çº¸ï¼‰ã€‚å®ƒä»¬æä¾›é™„åŠ åŠŸèƒ½æˆ–æ‰©å±•ç®¡é“çš„åŸå§‹å®ç°ã€‚


æœ‰è®¸å¤šå¾ˆé…·çš„ç¤¾åŒºç®¡é“ï¼Œä¾‹å¦‚
 [è¯­éŸ³è½¬å›¾åƒ](https://github.com/huggingface/diffusers/tree/main/examples/community#speech-to-image)
 æˆ–è€…
 [å¯ç»„åˆç¨³å®šæ‰©æ•£](https://github.com/huggingface/diffusers/tree/main/examples/community#composable-stable-diffusion)
 ï¼Œä½ å¯ä»¥æ‰¾åˆ°æ‰€æœ‰å®˜æ–¹ç¤¾åŒºç®¡é“
 [æ­¤å¤„](https://github.com/huggingface/diffusers/tree/main/examples/community)
 ã€‚


è¦åŠ è½½ Hub ä¸Šçš„ä»»ä½•ç¤¾åŒºç®¡é“ï¼Œè¯·å°†ç¤¾åŒºç®¡é“çš„å­˜å‚¨åº“ ID ä¼ é€’ç»™
 `è‡ªå®šä¹‰ç®¡é“`
 å‚æ•°ä»¥åŠæ‚¨è¦ä»ä¸­åŠ è½½ç®¡é“æƒé‡å’Œç»„ä»¶çš„æ¨¡å‹å­˜å‚¨åº“ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢çš„ç¤ºä¾‹ä»åŠ è½½è™šæ‹Ÿç®¡é“
 [`hf-internal-testing/diffusers-dummy-pipeline`](https://huggingface.co/hf-internal-testing/diffusers-dummy-pipeline/blob/main/pipeline.py)
 ä»¥åŠç®¡é“é‡é‡å’Œç»„ä»¶
 [`google/ddpm-cifar10-32`](https://huggingface.co/google/ddpm-cifar10-32)
 :


ğŸ”’ é€šè¿‡ä» Hugging Face Hub åŠ è½½ç¤¾åŒºç®¡é“ï¼Œæ‚¨å°±ç›¸ä¿¡æ‚¨æ­£åœ¨åŠ è½½çš„ä»£ç æ˜¯å®‰å…¨çš„ã€‚ç¡®ä¿åœ¨è‡ªåŠ¨åŠ è½½å’Œè¿è¡Œä»£ç ä¹‹å‰åœ¨çº¿æ£€æŸ¥ä»£ç ï¼



```
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    "google/ddpm-cifar10-32", custom_pipeline="hf-internal-testing/diffusers-dummy-pipeline", use_safetensors=True
)
```


åŠ è½½å®˜æ–¹ç¤¾åŒºç®¡é“ç±»ä¼¼ï¼Œä½†æ‚¨å¯ä»¥æ··åˆä»å®˜æ–¹å­˜å‚¨åº“ ID åŠ è½½æƒé‡å¹¶ç›´æ¥ä¼ é€’ç®¡é“ç»„ä»¶ã€‚ä¸‹é¢çš„ç¤ºä¾‹åŠ è½½ç¤¾åŒº
 [CLIPå¼•å¯¼ç¨³å®šæ‰©æ•£](https://github.com/huggingface/diffusers/tree/main/examples/community#clip-guided-stable-diffusion)
 ç®¡é“ï¼Œæ‚¨å¯ä»¥å°† CLIP æ¨¡å‹ç»„ä»¶ç›´æ¥ä¼ é€’ç»™å®ƒï¼š



```
from diffusers import DiffusionPipeline
from transformers import CLIPImageProcessor, CLIPModel

clip_model_id = "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"

feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)
clip_model = CLIPModel.from_pretrained(clip_model_id)

pipeline = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    custom_pipeline="clip\_guided\_stable\_diffusion",
    clip_model=clip_model,
    feature_extractor=feature_extractor,
    use_safetensors=True,
)
```


æœ‰å…³ç¤¾åŒºç®¡é“çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹
 [ç¤¾åŒºç®¡é“](custom_pipeline_examples)
 æœ‰å…³å¦‚ä½•ä½¿ç”¨å®ƒä»¬çš„æŒ‡å—ï¼Œå¦‚æœæ‚¨æœ‰å…´è¶£æ·»åŠ ç¤¾åŒºç®¡é“ï¼Œè¯·æŸ¥çœ‹
 [å¦‚ä½•è´¡çŒ®ç¤¾åŒºç®¡é“](contribute_pipeline)
 æŒ‡å¯¼ï¼


## ç¤¾åŒºç»„ä»¶



å¦‚æœæ‚¨çš„ç®¡é“å…·æœ‰ Diffusers å°šä¸æ”¯æŒçš„è‡ªå®šä¹‰ç»„ä»¶ï¼Œåˆ™éœ€è¦é™„å¸¦å®ç°å®ƒä»¬çš„ Python æ¨¡å—ã€‚è¿™äº›å®šåˆ¶ç»„ä»¶å¯ä»¥æ˜¯ VAEã€UNetã€è°ƒåº¦ç¨‹åºç­‰ã€‚å¯¹äºæ–‡æœ¬ç¼–ç å™¨ï¼Œæˆ‘ä»¬ä¾èµ–
 `å˜å½¢é‡‘åˆš`
 åæ­£ã€‚å› æ­¤ï¼Œåº”è¯¥å•ç‹¬å¤„ç†ï¼ˆæ›´å¤šä¿¡æ¯è¯·å‚è§æ­¤å¤„ï¼‰ã€‚ç®¡é“ä»£ç æœ¬èº«ä¹Ÿå¯ä»¥å®šåˆ¶ã€‚


ç¤¾åŒºç»„ä»¶å…è®¸ç”¨æˆ·æ„å»ºå¯èƒ½å…·æœ‰ä¸å±äº Diffuser çš„è‡ªå®šä¹‰ç»„ä»¶çš„ç®¡é“ã€‚æœ¬èŠ‚å±•ç¤ºç”¨æˆ·åº”å¦‚ä½•ä½¿ç”¨ç¤¾åŒºç»„ä»¶æ¥æ„å»ºç¤¾åŒºç®¡é“ã€‚


æ‚¨å°†ä½¿ç”¨
 [showlab/show-1-base](https://huggingface.co/showlab/show-1-base)
 è¿™é‡Œä»¥ç®¡é“æ£€æŸ¥ç‚¹ä¸ºä¾‹ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨æœ‰ä¸€ä¸ªè‡ªå®šä¹‰çš„ UNet å’Œä¸€ä¸ªè‡ªå®šä¹‰çš„ç®¡é“ï¼ˆ
 `æ–‡æœ¬åˆ°è§†é¢‘IFç®¡é“`
 ï¼‰ã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºUNet
 `ShowOneUNet3DConditionModel`
 ã€‚


â€œshowlab/show-1-baseâ€å·²ç»æä¾›äº† Diffusers æ ¼å¼çš„æ£€æŸ¥ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹åŠ è½½å·²ç»å¾—åˆ°è‰¯å¥½æ”¯æŒçš„ç»„ä»¶ï¼š


1. **æ–‡æœ¬ç¼–ç å™¨**



```
from transformers import T5Tokenizer, T5EncoderModel

pipe_id = "showlab/show-1-base"
tokenizer = T5Tokenizer.from_pretrained(pipe_id, subfolder="tokenizer")
text_encoder = T5EncoderModel.from_pretrained(pipe_id, subfolder="text\_encoder")
```


2. **è°ƒåº¦ç¨‹åº**



```
from diffusers import DPMSolverMultistepScheduler

scheduler = DPMSolverMultistepScheduler.from_pretrained(pipe_id, subfolder="scheduler")
```


3. **å›¾åƒå¤„ç†å™¨**



```
from transformers import CLIPFeatureExtractor

feature_extractor = CLIPFeatureExtractor.from_pretrained(pipe_id, subfolder="feature\_extractor")
```


ç°åœ¨ï¼Œæ‚¨éœ€è¦å®ç°è‡ªå®šä¹‰ UNetã€‚å®æ–½å¯ç”¨
 [æ­¤å¤„](https://github.com/showlab/Show-1/blob/main/showone/models/unet_3d_condition.py)
 ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåä¸ºçš„ Python è„šæœ¬
 `showone_unet_3d_condition.py`
 å¹¶å¤åˆ¶å®ç°ï¼Œæ”¹å˜
 `UNet3Dæ¡ä»¶æ¨¡å‹`
 ç±»ååˆ°
 `ShowOneUNet3DConditionModel`
 ä»¥é¿å…ä¸æ‰©æ•£å™¨å‘ç”Ÿä»»ä½•å†²çªã€‚è¿™æ˜¯å› ä¸º Diffuser å·²ç»æœ‰ä¸€ä¸ª
 `UNet3Dæ¡ä»¶æ¨¡å‹`
 ã€‚æˆ‘ä»¬å°†å®ç°è¯¥ç±»æ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶æ”¾å…¥
 `showone_unet_3d_condition.py`
 ä»…æœ‰çš„ã€‚ä½ å¯ä»¥æ‰¾åˆ°æ•´ä¸ªæ–‡ä»¶
 [æ­¤å¤„](https://huggingface.co/sayakpaul/show-1-base-with-code/blob/main/unet/showone_unet_3d_condition.py)
 ã€‚


å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥åˆå§‹åŒ– UNetï¼š



```
from showone_unet_3d_condition import ShowOneUNet3DConditionModel

unet = ShowOneUNet3DConditionModel.from_pretrained(pipe_id, subfolder="unet")
```


ç„¶åå®ç°è‡ªå®šä¹‰
 `æ–‡æœ¬åˆ°è§†é¢‘IFç®¡é“`
 åœ¨å¦ä¸€ä¸ªPythonè„šæœ¬ä¸­ï¼š
 `pipeline_t2v_base_pixel.py`
 ã€‚è¿™å·²ç»å¯ç”¨äº†
 [æ­¤å¤„](https://github.com/showlab/Show-1/blob/main/showone/pipelines/pipeline_t2v_base_pixel.py)
 ã€‚


ç°åœ¨æ‚¨å·²ç»æ‹¥æœ‰äº†æ‰€æœ‰ç»„ä»¶ï¼Œè¯·åˆå§‹åŒ–
 `æ–‡æœ¬åˆ°è§†é¢‘IFç®¡é“`
 :



```
from pipeline_t2v_base_pixel import TextToVideoIFPipeline
import torch

pipeline = TextToVideoIFPipeline(
    unet=unet, 
    text_encoder=text_encoder, 
    tokenizer=tokenizer, 
    scheduler=scheduler, 
    feature_extractor=feature_extractor
)
pipeline = pipeline.to(device="cuda")
pipeline.torch_dtype = torch.float16
```


å°†ç®¡é“æ¨é€åˆ° Hub ä»¥ä¸ç¤¾åŒºå…±äº«ï¼š



```
pipeline.push_to_hub("custom-t2v-pipeline")
```


æˆåŠŸæ¨é€ç®¡é“åï¼Œæ‚¨éœ€è¦è¿›è¡Œä¸€äº›æ›´æ”¹ï¼š


1. åœ¨
 `model_index.json`
 æ–‡ä»¶ï¼Œæ›´æ”¹
 `_class_name`
 å±æ€§ã€‚åº”è¯¥æ˜¯è¿™æ ·çš„
 [æ‰€ä»¥](https://huggingface.co/sayakpaul/show-1-base-with-code/blob/main/model_index.json#L2)
 ã€‚
2. ä¸Šä¼ 
 `showone_unet_3d_condition.py`
 åˆ°
 `ä¹Œå†…ç‰¹`
 ç›®å½• ï¼ˆ
 [ç¤ºä¾‹](https://huggingface.co/sayakpaul/show-1-base-with-code/blob/main/unet/showone_unet_3d_condition.py)
 ï¼‰ã€‚
3. ä¸Šä¼ 
 `pipeline_t2v_base_pixel.py`
 åˆ°ç®¡é“åŸºç›®å½•ï¼ˆ
 [ç¤ºä¾‹](https://huggingface.co/sayakpaul/show-1-base-with-code/blob/main/unet/showone_unet_3d_condition.py)
 ï¼‰ã€‚


è¦è¿è¡Œæ¨ç†ï¼Œåªéœ€æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š



```
from diffusers import DiffusionPipeline
import torch

pipeline = DiffusionPipeline.from_pretrained(
    "<change-username>/<change-id>", trust_remote_code=True, torch_dtype=torch.float16
).to("cuda")

prompt = "hello"

# Text embeds
prompt_embeds, negative_embeds = pipeline.encode_prompt(prompt)

# Keyframes generation (8x64x40, 2fps)
video_frames = pipeline(
    prompt_embeds=prompt_embeds,
    negative_prompt_embeds=negative_embeds,
    num_frames=8,
    height=40,
    width=64,
    num_inference_steps=2,
    guidance_scale=9.0,
    output_type="pt"
).frames
```


åœ¨è¿™é‡Œï¼Œè¯·æ³¨æ„ä½¿ç”¨
 `ä¿¡ä»»è¿œç¨‹ä»£ç `
 åˆå§‹åŒ–ç®¡é“æ—¶çš„å‚æ•°ã€‚å®ƒè´Ÿè´£å¤„ç†å¹•åçš„æ‰€æœ‰â€œé­”æ³•â€ã€‚