# ä¿®å¤

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/inpaint>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/inpaint>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


ä¿®å¤ä¼šæ›¿æ¢æˆ–ç¼–è¾‘å›¾åƒçš„ç‰¹å®šåŒºåŸŸã€‚è¿™ä½¿å…¶æˆä¸ºå›¾åƒä¿®å¤çš„æœ‰ç”¨å·¥å…·ï¼Œä¾‹å¦‚æ¶ˆé™¤ç¼ºé™·å’Œä¼ªå½±ï¼Œç”šè‡³ç”¨å…¨æ–°çš„ä¸œè¥¿æ›¿æ¢å›¾åƒåŒºåŸŸã€‚ä¿®å¤ä¾é è’™ç‰ˆæ¥ç¡®å®šè¦å¡«å……å›¾åƒçš„å“ªäº›åŒºåŸŸï¼›è¦ä¿®å¤çš„åŒºåŸŸç”±ç™½è‰²åƒç´ è¡¨ç¤ºï¼Œè¦ä¿ç•™çš„åŒºåŸŸç”±é»‘è‰²åƒç´ è¡¨ç¤ºã€‚ç™½è‰²åƒç´ ç”±æç¤ºå¡«å……ã€‚


ä½¿ç”¨ ğŸ¤— æ‰©æ•£å™¨ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼è¿›è¡Œä¿®å¤ï¼š


1. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åŠ è½½ä¿®å¤æ£€æŸ¥ç‚¹
 [AutoPipelineForInpainting](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 ç­çº§ã€‚è¿™å°†æ ¹æ®æ£€æŸ¥ç‚¹è‡ªåŠ¨æ£€æµ‹è¦åŠ è½½çš„é€‚å½“ç®¡é“ç±»ï¼š



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```


æ‚¨ä¼šåœ¨æ•´ä¸ªæŒ‡å—ä¸­æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬ä½¿ç”¨
 [å¯ç”¨\_model\_cpu\_offload()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
 å’Œ
 [å¯ç”¨\_xformers\_memory\_efficient\_attention()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/image_variation#diffusers.StableDiffusionImageVariationPipeline.enable_xformers_memory_efficient_attention)
 ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜æ¨ç†é€Ÿåº¦ã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ PyTorch 2.0ï¼Œåˆ™æ— éœ€è°ƒç”¨
 [å¯ç”¨\_xformers\_memory\_efficient\_attention()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/image_variation#diffusers.StableDiffusionImageVariationPipeline.enable_xformers_memory_efficient_attention)
 åœ¨ä½ çš„ç®¡é“ä¸Šï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 çš„åŸç”Ÿ
 [ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)
 ã€‚


2. åŠ è½½åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒï¼š



```
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")
```


3. åˆ›å»ºä¸€ä¸ªæç¤ºæ¥ä¿®å¤å›¾åƒï¼Œå¹¶å°†å…¶ä¸åŸºç¡€å›¾åƒå’Œè’™ç‰ˆå›¾åƒä¸€èµ·ä¼ é€’åˆ°ç®¡é“ï¼š



```
prompt = "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k"
negative_prompt = "bad anatomy, deformed, ugly, disfigured"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png)

 åŸºç¡€å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png)

 æ©æ¨¡å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-cat.png)

 ç”Ÿæˆçš„å›¾åƒ


## åˆ›å»ºè’™ç‰ˆå›¾åƒ



ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œåœ¨æœ¬æŒ‡å—ä¸­ï¼Œæ‰€æœ‰ä»£ç ç¤ºä¾‹ä¸­éƒ½æä¾›äº†é®ç½©å›¾åƒã€‚æ‚¨å¯ä»¥ä¿®å¤è‡ªå·±çš„å›¾åƒï¼Œä½†éœ€è¦ä¸ºå…¶åˆ›å»ºè’™ç‰ˆå›¾åƒã€‚ä½¿ç”¨ä¸‹é¢çš„ç©ºé—´è½»æ¾åˆ›å»ºè’™ç‰ˆå›¾åƒã€‚


ä¸Šä¼ è¦ä¿®å¤çš„åŸºæœ¬å›¾åƒï¼Œç„¶åä½¿ç”¨è‰å›¾å·¥å…·ç»˜åˆ¶è’™ç‰ˆã€‚å®Œæˆåï¼Œå•å‡»
 **è·‘æ­¥**
 ç”Ÿæˆå¹¶ä¸‹è½½æ©æ¨¡å›¾åƒã€‚


## çƒ­é—¨è½¦å‹



[ç¨³å®šæ‰©æ•£ä¿®å¤](https://huggingface.co/runwayml/stable-diffusion-inpainting)
 ,
 [ç¨³å®šæ‰©æ•£ XL (SDXL) ä¿®å¤](https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1)
 ï¼Œ å’Œ
 [åº·å®šæ–¯åŸº2.2ä¿®å¤](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint)
 æ˜¯æœ€å—æ¬¢è¿çš„ä¿®å¤æ¨¡å‹ä¹‹ä¸€ã€‚ SDXL é€šå¸¸ä¼šç”Ÿæˆæ¯” Stable Diffusion v1.5 æ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼ŒKandinsky 2.2 ä¹Ÿèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚


### 


 ç¨³å®šæ‰©æ•£ä¿®å¤


ç¨³å®šæ‰©æ•£ä¿®å¤æ˜¯ä¸€ç§åœ¨ä¿®å¤æ—¶å¯¹ 512x512 å›¾åƒè¿›è¡Œå¾®è°ƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå› ä¸ºå®ƒç›¸å¯¹è¾ƒå¿«å¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚è¦ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œä¿®å¤ï¼Œæ‚¨éœ€è¦å°†æç¤ºã€åŸºç¡€å›¾åƒå’Œé®ç½©å›¾åƒä¼ é€’åˆ°ç®¡é“ï¼š



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


### 


 ç¨³å®šæ‰©æ•£ XL (SDXL) ä¿®å¤


SDXL æ˜¯ Stable Diffusion v1.5 çš„æ›´å¤§ã€æ›´å¼ºå¤§çš„ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹å¯ä»¥éµå¾ªä¸¤é˜¶æ®µæ¨¡å‹è¿‡ç¨‹ï¼ˆå°½ç®¡æ¯ä¸ªæ¨¡å‹ä¹Ÿå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼‰ï¼›åŸºç¡€æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œç²¾ç‚¼æ¨¡å‹è·å–è¯¥å›¾åƒå¹¶è¿›ä¸€æ­¥å¢å¼ºå…¶ç»†èŠ‚å’Œè´¨é‡ã€‚çœ‹çœ‹
 [SDXL](sdxl)
 æŒ‡å—ï¼Œè·å–æœ‰å…³å¦‚ä½•ä½¿ç”¨ SDXL åŠå…¶å‚æ•°é…ç½®çš„æ›´å…¨é¢æŒ‡å—ã€‚



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "diffusers/stable-diffusion-xl-1.0-inpainting-0.1", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


### 


 åº·å®šæ–¯åŸº2.2 ä¿®å¤


åº·å®šæ–¯åŸºæ¨¡å‹ç³»åˆ—ä¸ SDXL ç±»ä¼¼ï¼Œå› ä¸ºå®ƒä¹Ÿä½¿ç”¨ä¸¤ç§æ¨¡å‹ï¼›å›¾åƒå…ˆéªŒæ¨¡å‹åˆ›å»ºå›¾åƒåµŒå…¥ï¼Œæ‰©æ•£æ¨¡å‹ä»ä¸­ç”Ÿæˆå›¾åƒã€‚æ‚¨å¯ä»¥åˆ†åˆ«åŠ è½½å›¾åƒå…ˆéªŒå’Œæ‰©æ•£æ¨¡å‹ï¼Œä½†ä½¿ç”¨ Kandinsky 2.2 æœ€ç®€å•çš„æ–¹æ³•æ˜¯å°†å…¶åŠ è½½åˆ°
 [AutoPipelineForInpainting](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 ä½¿ç”¨çš„ç±»
 [KandinskyV22InpaintCombinedPipeline](/docs/diffusers/v0.23.0/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline)
 åœ¨å¼•æ“ç›–ä¸‹ã€‚



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

generator = torch.Generator("cuda").manual_seed(92)
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png)

 åŸºç¡€å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdv1.5.png)

 ç¨³å®šæ‰©æ•£ä¿®å¤


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdxl.png)

 ç¨³å®šæ‰©æ•£ XL ä¿®å¤


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-kandinsky.png)

 åº·å®šæ–¯åŸº2.2 ä¿®å¤


## é…ç½®ç®¡é“å‚æ•°



å›¾åƒç‰¹å¾ï¼ˆä¾‹å¦‚è´¨é‡å’Œâ€œåˆ›é€ åŠ›â€ï¼‰å–å†³äºç®¡é“å‚æ•°ã€‚äº†è§£è¿™äº›å‚æ•°çš„ä½œç”¨å¯¹äºè·å¾—æ‚¨æƒ³è¦çš„ç»“æœéå¸¸é‡è¦ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æœ€é‡è¦çš„å‚æ•°ï¼Œçœ‹çœ‹æ›´æ”¹å®ƒä»¬å¦‚ä½•å½±å“è¾“å‡ºã€‚


### 


 åŠ›é‡


â€˜åŠ›é‡â€™
 æ˜¯å¯¹åŸºç¡€å›¾åƒæ·»åŠ äº†å¤šå°‘å™ªå£°çš„åº¦é‡ï¼Œè¿™ä¼šå½±å“è¾“å‡ºä¸åŸºç¡€å›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ã€‚


*ğŸ“ˆé«˜
 â€˜åŠ›é‡â€™
 å€¼æ„å‘³ç€å›¾åƒä¸­æ·»åŠ äº†æ›´å¤šå™ªå£°ï¼Œå¹¶ä¸”å»å™ªè¿‡ç¨‹éœ€è¦æ›´é•¿çš„æ—¶é—´ï¼Œä½†æ‚¨å°†è·å¾—ä¸åŸºç¡€å›¾åƒå·®å¼‚æ›´å¤§çš„æ›´é«˜è´¨é‡çš„å›¾åƒ
* ğŸ“‰ ä½
 â€˜åŠ›é‡â€™
 å€¼æ„å‘³ç€å‘å›¾åƒæ·»åŠ çš„å™ªå£°æ›´å°‘ï¼Œå»å™ªè¿‡ç¨‹æ›´å¿«ï¼Œä½†å›¾åƒè´¨é‡å¯èƒ½ä¸å¤ªå¥½ï¼Œç”Ÿæˆçš„å›¾åƒæ›´ç±»ä¼¼äºåŸºç¡€å›¾åƒ



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=0.6).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.6.png)

 å¼ºåº¦=0.6


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.8.png)

 å¼ºåº¦=0.8


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-1.0.png)

 å¼ºåº¦=1.0


### 


 æŒ‡å¯¼å°ºåº¦


`æŒ‡å¯¼è§„æ¨¡`
 å½±å“æ–‡æœ¬æç¤ºå’Œç”Ÿæˆå›¾åƒçš„å¯¹é½æ–¹å¼ã€‚


*ğŸ“ˆé«˜
 `æŒ‡å¯¼è§„æ¨¡`
 value è¡¨ç¤ºæç¤ºå’Œç”Ÿæˆçš„å›¾åƒç´§å¯†å¯¹é½ï¼Œå› æ­¤è¾“å‡ºæ˜¯å¯¹æç¤ºçš„æ›´ä¸¥æ ¼çš„è§£é‡Š
* ğŸ“‰ ä½
 `æŒ‡å¯¼è§„æ¨¡`
 å€¼æ„å‘³ç€æç¤ºå’Œç”Ÿæˆçš„å›¾åƒæ›´åŠ æ¾æ•£åœ°å¯¹é½ï¼Œå› æ­¤è¾“å‡ºå¯èƒ½ä¸æç¤ºæ›´åŠ ä¸åŒ


æ‚¨å¯ä»¥ä½¿ç”¨
 â€˜åŠ›é‡â€™
 å’Œ
 `æŒ‡å¯¼è§„æ¨¡`
 ä¸€èµ·æ›´å¥½åœ°æ§åˆ¶æ¨¡å‹çš„è¡¨ç°åŠ›ã€‚ä¾‹å¦‚ï¼Œç»„åˆé«˜
 â€˜åŠ›é‡â€™
 å’Œ
 `æŒ‡å¯¼è§„æ¨¡`
 å€¼èµ‹äºˆæ¨¡å‹æœ€å¤§çš„åˆ›ä½œè‡ªç”±åº¦ã€‚



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=2.5).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-2.5.png)

 æŒ‡å¯¼è§„æ¨¡= 2.5


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-7.5.png)

 æŒ‡å¯¼è§„æ¨¡= 7.5


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-12.5.png)

 æŒ‡å¯¼è§„æ¨¡= 12.5


### 


 è´Ÿé¢æç¤º


å¦å®šæç¤ºæ‰¿æ‹…ä¸æç¤ºç›¸åçš„è§’è‰²ï¼›å®ƒå¼•å¯¼æ¨¡å‹è¿œç¦»åœ¨å›¾åƒä¸­ç”ŸæˆæŸäº›ä¸œè¥¿ã€‚è¿™å¯¹äºå¿«é€Ÿæé«˜å›¾åƒè´¨é‡å¹¶é˜²æ­¢æ¨¡å‹ç”Ÿæˆæ‚¨ä¸æƒ³è¦çš„ä¸œè¥¿éå¸¸æœ‰ç”¨ã€‚



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
negative_prompt = "bad architecture, unstable, poor details, blurry"
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-negative.png)

 negative\_prompt =â€œç³Ÿç³•çš„æ¶æ„ï¼Œä¸ç¨³å®šï¼Œç»†èŠ‚å·®ï¼Œæ¨¡ç³Šâ€


## ä¿ç•™æœªé®ç›–çš„åŒºåŸŸ



è¿™
 [AutoPipelineForInpainting](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 ï¼ˆå’Œå…¶ä»–ä¿®å¤ç®¡é“ï¼‰é€šå¸¸ä¼šæ›´æ”¹å›¾åƒçš„æœªå±è”½éƒ¨åˆ†ï¼Œä»¥åœ¨å±è”½å’Œæœªå±è”½åŒºåŸŸä¹‹é—´åˆ›å»ºæ›´è‡ªç„¶çš„è¿‡æ¸¡ã€‚å¦‚æœè¿™ç§è¡Œä¸ºæ˜¯ä¸å¯å–çš„ï¼Œæ‚¨å¯ä»¥å¼ºåˆ¶æœªé®è”½çš„åŒºåŸŸä¿æŒä¸å˜ã€‚ç„¶è€Œï¼Œå¼ºåˆ¶å›¾åƒçš„æœªé®è”½éƒ¨åˆ†ä¿æŒä¸å˜å¯èƒ½ä¼šå¯¼è‡´æœªé®è”½åŒºåŸŸå’Œé®è”½åŒºåŸŸä¹‹é—´å‡ºç°ä¸€äº›ä¸å¯»å¸¸çš„è¿‡æ¸¡ã€‚



```
import PIL
import numpy as np
import torch

from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

device = "cuda"
pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    torch_dtype=torch.float16,
)
pipeline = pipeline.to(device)

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting\_examples/overture-creations-5sI6fQgYIuo\_mask.png"

init_image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
repainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]
repainted_image.save("repainted\_image.png")

# Convert mask to grayscale NumPy array
mask_image_arr = np.array(mask_image.convert("L"))
# Add a channel dimension to the end of the grayscale mask
mask_image_arr = mask_image_arr[:, :, None]
# Binarize the mask: 1s correspond to the pixels which are repainted
mask_image_arr = mask_image_arr.astype(np.float32) / 255.0
mask_image_arr[mask_image_arr < 0.5] = 0
mask_image_arr[mask_image_arr >= 0.5] = 1

# Take the masked pixels from the repainted image and the unmasked pixels from the initial image
unmasked_unchanged_image_arr = (1 - mask_image_arr) * init_image + mask_image_arr * repainted_image
unmasked_unchanged_image = PIL.Image.fromarray(unmasked_unchanged_image_arr.round().astype("uint8"))
unmasked_unchanged_image.save("force\_unmasked\_unchanged.png")
make_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=2, cols=2)
```


## è¿é”ä¿®è¡¥ç®¡é“



[AutoPipelineForInpainting](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 å¯ä»¥ä¸å…¶ä»– ğŸ¤— Diffusers ç®¡é“é“¾æ¥ä»¥ç¼–è¾‘å…¶è¾“å‡ºã€‚è¿™å¯¹äºæé«˜å…¶ä»–æ‰©æ•£ç®¡é“çš„è¾“å‡ºè´¨é‡é€šå¸¸å¾ˆæœ‰ç”¨ï¼Œå¹¶ä¸”å¦‚æœæ‚¨ä½¿ç”¨å¤šä¸ªç®¡é“ï¼Œåˆ™å°†å®ƒä»¬é“¾æ¥åœ¨ä¸€èµ·ä»¥å°†è¾“å‡ºä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­å¹¶é‡ç”¨ç›¸åŒçš„ç®¡é“ç»„ä»¶å¯ä»¥æ›´èŠ‚çœå†…å­˜ã€‚


### 


 æ–‡æœ¬åˆ°å›¾åƒåˆ°ä¿®å¤


é“¾æ¥æ–‡æœ¬åˆ°å›¾åƒå’Œä¿®å¤ç®¡é“å…è®¸æ‚¨ä¿®å¤ç”Ÿæˆçš„å›¾åƒï¼Œå¹¶ä¸”æ‚¨ä¸å¿…é¦–å…ˆæä¾›åŸºç¡€å›¾åƒã€‚è¿™ä½¿å¾—æ‚¨å¯ä»¥æ–¹ä¾¿åœ°ç¼–è¾‘æ‚¨å–œæ¬¢çš„æ–‡æœ¬åˆ°å›¾åƒè¾“å‡ºï¼Œè€Œæ— éœ€ç”Ÿæˆå…¨æ–°çš„å›¾åƒã€‚


ä»æ–‡æœ¬åˆ°å›¾åƒç®¡é“å¼€å§‹åˆ›å»ºä¸€åº§åŸå ¡ï¼š



```
import torch
from diffusers import AutoPipelineForText2Image, AutoPipelineForInpainting
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k").images[0]
```


åŠ è½½ä¸Šé¢è¾“å‡ºçš„æ©æ¨¡å›¾åƒï¼š



```
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_text-chain-mask.png")
```


è®©æˆ‘ä»¬ç”¨ç€‘å¸ƒä¿®å¤é®ç½©åŒºåŸŸï¼š



```
pipeline = AutoPipelineForInpainting.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder-inpaint", torch_dtype=torch.float16
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "digital painting of a fantasy waterfall, cloudy"
image = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[0]
make_image_grid([text2image, mask_image, image], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain.png)

 æ–‡æœ¬åˆ°å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain-out.png)

 ä¿®å¤


### 


 ä¿®å¤åˆ°å›¾åƒåˆ°å›¾åƒ


æ‚¨è¿˜å¯ä»¥å°†ä¿®å¤ç®¡é“é“¾æ¥åˆ°å¦ä¸€ä¸ªç®¡é“ï¼ˆä¾‹å¦‚å›¾åƒåˆ°å›¾åƒæˆ–å‡çº§å™¨ï¼‰ä¹‹å‰ï¼Œä»¥æé«˜è´¨é‡ã€‚


é¦–å…ˆä¿®å¤å›¾åƒï¼š



```
import torch
from diffusers import AutoPipelineForInpainting, AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[0]

# resize image to 1024x1024 for SDXL
image_inpainting = image_inpainting.resize((1024, 1024))
```


ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ SDXL çš„ç»†åŒ–å™¨æ¨¡å‹å°†å›¾åƒä¼ é€’åˆ°å¦ä¸€ä¸ªä¿®å¤ç®¡é“ï¼Œä»¥å¢å¼ºå›¾åƒç»†èŠ‚å’Œè´¨é‡ï¼š



```
pipeline = AutoPipelineForInpainting.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type="latent").images[0]
```


é‡è¦çš„æ˜¯è¦æŒ‡å®š
 `output_type="æ½œåœ¨"`
 åœ¨ç®¡é“ä¸­å°†æ‰€æœ‰è¾“å‡ºä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œä»¥é¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚ä»…å½“é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„ VAE æ—¶ï¼Œè¿™æ‰æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼Œåœ¨
 [æ–‡æœ¬è½¬å›¾åƒä¿®å¤](#æ–‡æœ¬è½¬å›¾åƒä¿®å¤)
 éƒ¨åˆ†ï¼ŒKandinsky 2.2 ä½¿ç”¨ä¸ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸åŒçš„ VAE ç±»ï¼Œå› æ­¤å®ƒä¸èµ·ä½œç”¨ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨å¯¹ä¸¤ä¸ªç®¡é“éƒ½ä½¿ç”¨ Stable Diffusion v1.5ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥å°†æ‰€æœ‰å†…å®¹ä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä½¿ç”¨
 [AutoencoderKL](/docs/diffusers/v0.23.0/en/api/models/autoencoderkl#diffusers.AutoencoderKL)
 ã€‚


æœ€åï¼Œæ‚¨å¯ä»¥å°†æ­¤å›¾åƒä¼ é€’åˆ°å›¾åƒåˆ°å›¾åƒç®¡é“ä»¥å¯¹å…¶è¿›è¡Œæœ€åçš„ä¿®é¥°ã€‚ä½¿ç”¨æ›´æœ‰æ•ˆ
 [from\_pipe()](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe)
 æ–¹æ³•é‡ç”¨ç°æœ‰çš„ç®¡é“ç»„ä»¶ï¼Œå¹¶é¿å…ä¸å¿…è¦åœ°å†æ¬¡å°†æ‰€æœ‰ç®¡é“ç»„ä»¶åŠ è½½â€‹â€‹åˆ°å†…å­˜ä¸­ã€‚



```
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline)
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image_inpainting, image], rows=2, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-chain.png)

 ä¿®å¤


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-final.png)

 å›¾åƒåˆ°å›¾åƒ


å›¾åƒåˆ°å›¾åƒå’Œä¿®å¤å®é™…ä¸Šæ˜¯éå¸¸ç›¸ä¼¼çš„ä»»åŠ¡ã€‚å›¾åƒåˆ°å›¾åƒç”Ÿæˆç±»ä¼¼äºç°æœ‰æä¾›çš„å›¾åƒçš„æ–°å›¾åƒã€‚ä¿®å¤åšåŒæ ·çš„äº‹æƒ…ï¼Œä½†å®ƒåªå˜æ¢ç”±è’™ç‰ˆå®šä¹‰çš„å›¾åƒåŒºåŸŸï¼Œå›¾åƒçš„å…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜ã€‚æ‚¨å¯ä»¥å°†ä¿®å¤è§†ä¸ºè¿›è¡Œç‰¹å®šæ›´æ”¹çš„æ›´ç²¾ç¡®çš„å·¥å…·ï¼Œè€Œå›¾åƒåˆ°å›¾åƒå…·æœ‰æ›´å¹¿æ³›çš„èŒƒå›´æ¥è¿›è¡Œæ›´å½»åº•çš„æ›´æ”¹ã€‚


## æ§åˆ¶å›¾åƒç”Ÿæˆ



è®©å›¾åƒçœ‹èµ·æ¥å®Œå…¨ç¬¦åˆæ‚¨æƒ³è¦çš„æ–¹å¼æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå› ä¸ºå»å™ªè¿‡ç¨‹æ˜¯éšæœºçš„ã€‚è™½ç„¶æ‚¨å¯ä»¥é€šè¿‡é…ç½®å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆçš„æŸäº›æ–¹é¢ï¼Œä¾‹å¦‚
 `å¦å®šæç¤º`
 ï¼Œæœ‰æ›´å¥½ã€æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æ§åˆ¶å›¾åƒç”Ÿæˆã€‚


### 


 æç¤ºç§°é‡


æç¤ºæƒé‡æä¾›äº†ä¸€ç§å¯é‡åŒ–çš„æ–¹æ³•æ¥è¡¡é‡æç¤ºä¸­æ¦‚å¿µçš„è¡¨ç¤ºã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥å¢åŠ æˆ–å‡å°‘æç¤ºä¸­æ¯ä¸ªæ¦‚å¿µçš„æ–‡æœ¬åµŒå…¥å‘é‡çš„å¤§å°ï¼Œè¿™éšåå†³å®šäº†æ¯ä¸ªæ¦‚å¿µçš„ç”Ÿæˆé‡ã€‚è¿™
 [å¼ºåˆ¶](https://github.com/damian0815/compel)
 åº“æä¾›äº†ä¸€ç§ç›´è§‚çš„è¯­æ³•æ¥ç¼©æ”¾æç¤ºæƒé‡å’Œç”ŸæˆåµŒå…¥ã€‚äº†è§£å¦‚ä½•åœ¨ä¸­åˆ›å»ºåµŒå…¥
 [æç¤ºæƒé‡](../using-diffusers/weighted_prompts)
 æŒ‡å¯¼ã€‚


ç”ŸæˆåµŒå…¥åï¼Œå°†å®ƒä»¬ä¼ é€’ç»™
 `æç¤ºåµŒå…¥`
 ï¼ˆå’Œ
 `å¦å®šæç¤ºåµŒå…¥`
 å¦‚æœæ‚¨ä½¿ç”¨å¦å®šæç¤ºï¼‰å‚æ•°
 [AutoPipelineForInpainting](/docs/diffusers/v0.23.0/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting)
 ã€‚åµŒå…¥å–ä»£äº†
 `æç¤º`
 èŒƒå›´ï¼š



```
import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    "runwayml/stable-diffusion-inpainting", torch_dtype=torch.float16,
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
    mask_image=mask_image
).images[0]
make_image_grid([init_image, mask_image, image], rows=1, cols=3)
```


### 


 æ§åˆ¶ç½‘


ControlNet æ¨¡å‹ä¸ç¨³å®šæ‰©æ•£ç­‰å…¶ä»–æ‰©æ•£æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼Œå®ƒä»¬æä¾›äº†ä¸€ç§æ›´çµæ´»ã€æ›´å‡†ç¡®çš„æ–¹æ³•æ¥æ§åˆ¶å›¾åƒçš„ç”Ÿæˆæ–¹å¼ã€‚ ControlNet æ¥å—é¢å¤–çš„è°ƒèŠ‚å›¾åƒè¾“å…¥ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹ä¿ç•™å…¶ä¸­çš„ç‰¹å¾ã€‚


ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨åœ¨ä¿®å¤å›¾åƒä¸Šé¢„è®­ç»ƒçš„ ControlNet æ¥è°ƒèŠ‚å›¾åƒï¼š



```
import torch
import numpy as np
from diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline
from diffusers.utils import load_image, make_image_grid

# load ControlNet
controlnet = ControlNetModel.from_pretrained("lllyasviel/control\_v11p\_sd15\_inpaint", torch_dtype=torch.float16, variant="fp16")

# pass ControlNet to the pipeline
pipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16"
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# load base and mask image
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png")
mask_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint\_mask.png")

# prepare control image
def make\_inpaint\_condition(init\_image, mask\_image):
    init_image = np.array(init_image.convert("RGB")).astype(np.float32) / 255.0
    mask_image = np.array(mask_image.convert("L")).astype(np.float32) / 255.0

    assert init_image.shape[0:1] == mask_image.shape[0:1], "image and image\_mask must have the same image size"
    init_image[mask_image > 0.5] = -1.0  # set as masked pixel
    init_image = np.expand_dims(init_image, 0).transpose(0, 3, 1, 2)
    init_image = torch.from_numpy(init_image)
    return init_image

control_image = make_inpaint_condition(init_image, mask_image)
```


ç°åœ¨ä»åŸºç¡€å›¾åƒã€è’™ç‰ˆå›¾åƒå’Œæ§åˆ¶å›¾åƒç”Ÿæˆå›¾åƒã€‚æ‚¨ä¼šæ³¨æ„åˆ°ç”Ÿæˆçš„å›¾åƒä¸­å……åˆ†ä¿ç•™äº†åŸºç¡€å›¾åƒçš„ç‰¹å¾ã€‚



```
prompt = "concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k"
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[0]
make_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[0][0])).convert('RGB'), image], rows=2, cols=2)
```


æ‚¨å¯ä»¥æ›´è¿›ä¸€æ­¥ï¼Œå°†å…¶ä¸å›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥èµ·æ¥ä»¥åº”ç”¨æ–°çš„
 [é£æ ¼](https://huggingface.co/nitrosocke/elden-ring-diffusion)
 :



```
from diffusers import AutoPipelineForImage2Image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style castle" # include the token "elden ring style" in the prompt
negative_prompt = "bad architecture, deformed, disfigured, poor details"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[0]
make_image_grid([init_image, mask_image, image, image_elden_ring], rows=2, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-controlnet.png)

 ControlNetä¿®å¤


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-img2img.png)

 å›¾åƒåˆ°å›¾åƒ


## ä¼˜åŒ–



å¦‚æœèµ„æºæœ‰é™ï¼Œè¿è¡Œæ‰©æ•£æ¨¡å‹å¯èƒ½ä¼šå¾ˆå›°éš¾ä¸”ç¼“æ…¢ï¼Œä½†ä¸ä¸€å®šéœ€è¦ä¸€äº›ä¼˜åŒ–æŠ€å·§ã€‚æ‚¨å¯ä»¥å¯ç”¨çš„æœ€å¤§ï¼ˆä¹Ÿæ˜¯æœ€ç®€å•ï¼‰çš„ä¼˜åŒ–ä¹‹ä¸€æ˜¯åˆ‡æ¢åˆ°å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›ã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ PyTorch 2.0ï¼Œ
 [ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)
 ä¼šè‡ªåŠ¨å¯ç”¨ï¼Œæ‚¨æ— éœ€æ‰§è¡Œä»»ä½•å…¶ä»–æ“ä½œã€‚å¯¹äºéPyTorch 2.0ç”¨æˆ·ï¼Œæ‚¨å¯ä»¥å®‰è£…å¹¶ä½¿ç”¨
 [xFormers](../ä¼˜åŒ–/xformers)
 å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›çš„å®ç°ã€‚è¿™ä¸¤ä¸ªé€‰é¡¹éƒ½å¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨å¹¶åŠ é€Ÿæ¨ç†ã€‚


æ‚¨è¿˜å¯ä»¥å°†æ¨¡å‹å¸è½½åˆ° CPU ä»¥èŠ‚çœæ›´å¤šå†…å­˜ï¼š



```
+ pipeline.enable\_xformers\_memory\_efficient\_attention()
+ pipeline.enable\_model\_cpu\_offload()
```


è¦è¿›ä¸€æ­¥åŠ å¿«æ¨ç†ä»£ç çš„é€Ÿåº¦ï¼Œè¯·ä½¿ç”¨
 [`torch_compile`](../optimization/torch2.0#torchcompile)
 ã€‚ä½ åº”è¯¥åŒ…è£¹
 `torch.ç¼–è¯‘`
 å›´ç»•ç®¡é“ä¸­æœ€å¯†é›†çš„ç»„ä»¶ï¼ˆé€šå¸¸æ˜¯ UNetï¼‰ï¼š



```
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```


äº†è§£æ›´å¤šä¿¡æ¯
 [å‡å°‘å†…å­˜ä½¿ç”¨](../ä¼˜åŒ–/å†…å­˜)
 å’Œ
 [torch2.0](../ä¼˜åŒ–/torch2.0)
 æŒ‡å—ã€‚