# å›¾åƒåˆ°å›¾åƒ

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/using-diffusers/img2img>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/using-diffusers/img2img>


![åœ¨ Colab ä¸­æ‰“å¼€](https://colab.research.google.com/assets/colab-badge.svg)


![åœ¨ Studio Lab ä¸­æ‰“å¼€](https://studiolab.sagemaker.aws/studiolab.svg)


å›¾åƒåˆ°å›¾åƒç±»ä¼¼äº
 [æ–‡æœ¬åˆ°å›¾åƒ]ï¼ˆæ¡ä»¶å›¾åƒç”Ÿæˆï¼‰
 ï¼Œä½†é™¤äº†æç¤ºä¹‹å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä¼ é€’åˆå§‹å›¾åƒä½œä¸ºæ‰©æ•£è¿‡ç¨‹çš„èµ·ç‚¹ã€‚åˆå§‹å›¾åƒè¢«ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ï¼Œå¹¶å‘å…¶ä¸­æ·»åŠ å™ªå£°ã€‚ç„¶åï¼Œæ½œåœ¨æ‰©æ•£æ¨¡å‹é‡‡ç”¨æç¤ºå’Œå™ªå£°æ½œåœ¨å›¾åƒï¼Œé¢„æµ‹æ·»åŠ çš„å™ªå£°ï¼Œå¹¶ä»åˆå§‹æ½œåœ¨å›¾åƒä¸­å»é™¤é¢„æµ‹çš„å™ªå£°ä»¥è·å¾—æ–°çš„æ½œåœ¨å›¾åƒã€‚æœ€åï¼Œè§£ç å™¨å°†æ–°çš„æ½œåœ¨å›¾åƒè§£ç å›å›¾åƒã€‚


ä½¿ç”¨ ğŸ¤— æ‰©æ•£å™¨ï¼Œè¿™å°±åƒ 1-2-3 ä¸€æ ·ç®€å•ï¼š


1. å°†æ£€æŸ¥ç‚¹åŠ è½½åˆ°
 [AutoPipelineForImage2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)
 ç­çº§;è¯¥ç®¡é“æ ¹æ®æ£€æŸ¥ç‚¹è‡ªåŠ¨å¤„ç†åŠ è½½æ­£ç¡®çš„ç®¡é“ç±»ï¼š



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import load_image, make_image_grid

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```


æ‚¨ä¼šåœ¨æ•´ä¸ªæŒ‡å—ä¸­æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬ä½¿ç”¨
 [å¯ç”¨\_model\_cpu\_offload()](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/gligen#diffusers.StableDiffusionGLIGENTextImagePipeline.enable_model_cpu_offload)
 å’Œ
 [å¯ç”¨\_xformers\_memory\_efficient\_attention()](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/adapter#diffusers.StableDiffusionXLAdapterPipeline.enable_xformers_memory_efficient_attention)
 ï¼Œä»¥èŠ‚çœå†…å­˜å¹¶æé«˜æ¨ç†é€Ÿåº¦ã€‚å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ PyTorch 2.0ï¼Œé‚£ä¹ˆæ‚¨ä¸éœ€è¦è°ƒç”¨
 [å¯ç”¨\_xformers\_memory\_efficient\_attention()](/docs/diffusers/v0.23.1/en/api/pipelines/stable_diffusion/adapter#diffusers.StableDiffusionXLAdapterPipeline.enable_xformers_memory_efficient_attention)
 åœ¨ä½ çš„ç®¡é“ä¸Šï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ä½¿ç”¨ PyTorch 2.0 çš„åŸç”Ÿ
 [ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)
 ã€‚


2. åŠ è½½å›¾åƒä»¥ä¼ é€’åˆ°ç®¡é“ï¼š



```
init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")
```


3. å°†æç¤ºå’Œå›¾åƒä¼ é€’åˆ°ç®¡é“ä»¥ç”Ÿæˆå›¾åƒï¼š



```
prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img.png)

 ç”Ÿæˆçš„å›¾åƒ


## çƒ­é—¨è½¦å‹



æœ€æµè¡Œçš„å›¾åƒåˆ°å›¾åƒæ¨¡å‹æ˜¯
 [ç¨³å®šæ‰©æ•£ v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
 ,
 [ç¨³å®šæ‰©æ•£ XL (SDXL)](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
 ï¼Œ å’Œ
 [åº·å®šæ–¯åŸº2.2](https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder)
 ã€‚ç¨³å®šæ‰©æ•£æ¨¡å‹å’Œåº·å®šæ–¯åŸºæ¨¡å‹çš„ç»“æœå› å…¶æ¶æ„å·®å¼‚å’Œè®­ç»ƒè¿‡ç¨‹è€Œæœ‰æ‰€ä¸åŒï¼›é€šå¸¸ï¼Œæ‚¨å¯ä»¥æœŸæœ› SDXL ç”Ÿæˆæ¯” Stable Diffusion v1.5 æ›´é«˜è´¨é‡çš„å›¾åƒã€‚è®©æˆ‘ä»¬å¿«é€Ÿäº†è§£ä¸€ä¸‹å¦‚ä½•ä½¿ç”¨æ¯ä¸ªæ¨¡å‹å¹¶æ¯”è¾ƒå®ƒä»¬çš„ç»“æœã€‚


### 


 ç¨³å®šæ‰©æ•£ v1.5


Stable Diffusion v1.5 æ˜¯ä»æ—©æœŸæ£€æŸ¥ç‚¹åˆå§‹åŒ–çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹ 512x512 å›¾åƒä¸Šçš„ 595K æ­¥éª¤è¿›è¡Œäº†è¿›ä¸€æ­¥å¾®è°ƒã€‚è¦ä½¿ç”¨æ­¤ç®¡é“è¿›è¡Œå›¾åƒåˆ°å›¾åƒï¼Œæ‚¨éœ€è¦å‡†å¤‡ä¸€ä¸ªåˆå§‹å›¾åƒä»¥ä¼ é€’åˆ°ç®¡é“ã€‚ç„¶åæ‚¨å¯ä»¥å°†æç¤ºå’Œå›¾åƒä¼ é€’åˆ°ç®¡é“ä»¥ç”Ÿæˆæ–°å›¾åƒï¼š



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdv1.5.png)

 ç”Ÿæˆçš„å›¾åƒ


### 


 ç¨³å®šæ‰©æ•£ XL (SDXL)


SDXL æ˜¯ç¨³å®šæ‰©æ•£æ¨¡å‹çš„æ›´å¼ºå¤§ç‰ˆæœ¬ã€‚å®ƒä½¿ç”¨æ›´å¤§çš„åŸºç¡€æ¨¡å‹å’Œé™„åŠ çš„ç²¾ç‚¼æ¨¡å‹æ¥æé«˜åŸºç¡€æ¨¡å‹è¾“å‡ºçš„è´¨é‡ã€‚é˜…è¯»
 [SDXL](sdxl)
 æŒ‡å—ï¼Œæ›´è¯¦ç»†åœ°ä»‹ç»å¦‚ä½•ä½¿ç”¨æ­¤æ¨¡å‹ä»¥åŠå®ƒç”¨äºç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„å…¶ä»–æŠ€æœ¯ã€‚



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, strength=0.5).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl-init.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-sdxl.png)

 ç”Ÿæˆçš„å›¾åƒ


### 


 åº·å®šæ–¯åŸº2.2


åº·å®šæ–¯åŸºæ¨¡å‹ä¸ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸åŒï¼Œå› ä¸ºå®ƒä½¿ç”¨å›¾åƒå…ˆéªŒæ¨¡å‹æ¥åˆ›å»ºå›¾åƒåµŒå…¥ã€‚åµŒå…¥æœ‰åŠ©äºåœ¨æ–‡æœ¬å’Œå›¾åƒä¹‹é—´åˆ›å»ºæ›´å¥½çš„å¯¹é½ï¼Œä»è€Œå…è®¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ›´å¥½çš„å›¾åƒã€‚


ä½¿ç”¨ Kandinsky 2.2 æœ€ç®€å•çš„æ–¹æ³•æ˜¯ï¼š



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-kandinsky.png)

 ç”Ÿæˆçš„å›¾åƒ


## é…ç½®ç®¡é“å‚æ•°



æ‚¨å¯ä»¥åœ¨ç®¡é“ä¸­é…ç½®å‡ ä¸ªé‡è¦å‚æ•°ï¼Œè¿™äº›å‚æ•°ä¼šå½±å“å›¾åƒç”Ÿæˆè¿‡ç¨‹å’Œå›¾åƒè´¨é‡ã€‚è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹è¿™äº›å‚æ•°çš„ä½œç”¨ä»¥åŠæ›´æ”¹å®ƒä»¬å¦‚ä½•å½±å“è¾“å‡ºã€‚


### 


 åŠ›é‡


â€˜åŠ›é‡â€™
 æ˜¯éœ€è¦è€ƒè™‘çš„æœ€é‡è¦çš„å‚æ•°ä¹‹ä¸€ï¼Œå®ƒå°†å¯¹æ‚¨ç”Ÿæˆçš„å›¾åƒäº§ç”Ÿå·¨å¤§å½±å“ã€‚å®ƒç¡®å®šç”Ÿæˆçš„å›¾åƒä¸åˆå§‹å›¾åƒçš„ç›¸ä¼¼ç¨‹åº¦ã€‚æ¢å¥è¯è¯´ï¼š


* ğŸ“ˆ æ›´é«˜
 â€˜åŠ›é‡â€™
 value èµ‹äºˆæ¨¡å‹æ›´å¤šçš„â€œåˆ›é€ åŠ›â€æ¥ç”Ÿæˆä¸åˆå§‹å›¾åƒä¸åŒçš„å›¾åƒï¼› A
 â€˜åŠ›é‡â€™
 å€¼ä¸º 1.0 æ„å‘³ç€åˆå§‹å›¾åƒæˆ–å¤šæˆ–å°‘è¢«å¿½ç•¥
* ğŸ“‰ è¾ƒä½
 â€˜åŠ›é‡â€™
 value è¡¨ç¤ºç”Ÿæˆçš„å›¾åƒä¸åˆå§‹å›¾åƒæ›´ç›¸ä¼¼


è¿™
 â€˜åŠ›é‡â€™
 å’Œ
 `num_inference_steps`
 å‚æ•°æ˜¯ç›¸å…³çš„ï¼Œå› ä¸º
 â€˜åŠ›é‡â€™
 ç¡®å®šè¦æ·»åŠ çš„å™ªå£°æ­¥æ•°ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ
 `num_inference_steps`
 æ˜¯ 50 å¹¶ä¸”
 â€˜åŠ›é‡â€™
 æ˜¯ 0.8ï¼Œé‚£ä¹ˆè¿™æ„å‘³ç€å‘åˆå§‹å›¾åƒæ·»åŠ  40 (50 \* 0.8) æ­¥çš„å™ªå£°ï¼Œç„¶åå†è¿›è¡Œ 40 æ­¥çš„å»å™ªä»¥è·å¾—æ–°ç”Ÿæˆçš„å›¾åƒã€‚



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, strength=0.8).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-0.4.png)

 å¼ºåº¦=0.4


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-0.6.png)

 å¼ºåº¦=0.6


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-strength-1.0.png)

 å¼ºåº¦=1.0


### 


 æŒ‡å¯¼å°ºåº¦


è¿™
 `æŒ‡å¯¼è§„æ¨¡`
 å‚æ•°ç”¨äºæ§åˆ¶ç”Ÿæˆçš„å›¾åƒå’Œæ–‡æœ¬æç¤ºçš„å¯¹é½ç¨‹åº¦ã€‚æ›´é«˜çš„
 `æŒ‡å¯¼è§„æ¨¡`
 å€¼æ„å‘³ç€æ‚¨ç”Ÿæˆçš„å›¾åƒä¸æç¤ºæ›´åŠ ä¸€è‡´ï¼Œè€Œè¾ƒä½
 `æŒ‡å¯¼è§„æ¨¡`
 å€¼æ„å‘³ç€æ‚¨ç”Ÿæˆçš„å›¾åƒæœ‰æ›´å¤šç©ºé—´åç¦»æç¤ºã€‚


ä½ å¯ä»¥ç»“åˆ
 `æŒ‡å¯¼è§„æ¨¡`
 å’Œ
 â€˜åŠ›é‡â€™
 æ›´ç²¾ç¡®åœ°æ§åˆ¶æ¨¡å‹çš„è¡¨ç°åŠ›ã€‚ä¾‹å¦‚ï¼Œç»“åˆé«˜
 `å¼ºåº¦+æŒ‡å¯¼è§„æ¨¡`
 ä»¥è·å¾—æœ€å¤§çš„åˆ›é€ åŠ›æˆ–ä½¿ç”¨ä½çš„ç»„åˆ
 â€˜åŠ›é‡â€™
 å’Œä½
 `æŒ‡å¯¼è§„æ¨¡`
 ç”Ÿæˆç±»ä¼¼äºåˆå§‹å›¾åƒä½†ä¸ä¸¥æ ¼ç»‘å®šåˆ°æç¤ºçš„å›¾åƒã€‚



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, guidance_scale=8.0).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-0.1.png)

 æŒ‡å¯¼\_scale = 0.1


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-3.0.png)

 æŒ‡å¯¼è§„æ¨¡= 5.0


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-guidance-7.5.png)

 æŒ‡å¯¼\_scale = 10.0


### 


 è´Ÿé¢æç¤º


è´Ÿé¢æç¤ºæ¡ä»¶ä½¿æ¨¡å‹
 *ä¸æ˜¯*
 å°†äº‹ç‰©åŒ…å«åœ¨å›¾åƒä¸­ï¼Œå®ƒå¯ç”¨äºæé«˜å›¾åƒè´¨é‡æˆ–ä¿®æ”¹å›¾åƒã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ·»åŠ â€œç»†èŠ‚è¾ƒå·®â€æˆ–â€œæ¨¡ç³Šâ€ç­‰è´Ÿé¢æç¤ºæ¥é¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡æŒ‡å®šè¦ä»å›¾åƒä¸­æ’é™¤çš„å†…å®¹æ¥ä¿®æ”¹å›¾åƒã€‚



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "stabilityai/stable-diffusion-xl-refiner-1.0", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

# pass prompt and image to pipeline
image = pipeline(prompt, negative_prompt=negative_prompt, image=init_image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-negative-1.png)

 negative\_prompt =â€œä¸‘é™‹ã€å˜å½¢ã€æ¯å®¹ã€ç»†èŠ‚å·®ã€è§£å‰–ç»“æ„ä¸è‰¯â€


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-negative-2.png)

 å¦å®š\_prompt =â€œä¸›æ—â€


## é“¾æ¥çš„å›¾åƒåˆ°å›¾åƒç®¡é“



é™¤äº†ç”Ÿæˆå›¾åƒä¹‹å¤–ï¼Œè¿˜æœ‰å…¶ä»–ä¸€äº›æœ‰è¶£çš„æ–¹æ³•å¯ä»¥ä½¿ç”¨å›¾åƒåˆ°å›¾åƒç®¡é“ï¼ˆå°½ç®¡è¿™ä¹Ÿå¾ˆé…·ï¼‰ã€‚æ‚¨å¯ä»¥æ›´è¿›ä¸€æ­¥ï¼Œå°†å…¶ä¸å…¶ä»–ç®¡é“é“¾æ¥èµ·æ¥ã€‚


### 


 æ–‡æœ¬åˆ°å›¾åƒåˆ°å›¾åƒ


é€šè¿‡é“¾æ¥æ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒç®¡é“ï¼Œæ‚¨å¯ä»¥ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼Œå¹¶å°†ç”Ÿæˆçš„å›¾åƒç”¨ä½œå›¾åƒåˆ°å›¾åƒç®¡é“çš„åˆå§‹å›¾åƒã€‚å¦‚æœæ‚¨æƒ³å®Œå…¨ä»å¤´å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬é“¾æ¥ä¸€ä¸ªç¨³å®šæ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªåº·å®šæ–¯åŸºæ¨¡å‹ã€‚


é¦–å…ˆä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒç®¡é“ç”Ÿæˆå›¾åƒï¼š



```
from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image
import torch
from diffusers.utils import make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k").images[0]
text2image
```


ç°åœ¨æ‚¨å¯ä»¥å°†æ­¤ç”Ÿæˆçš„å›¾åƒä¼ é€’åˆ°å›¾åƒåˆ°å›¾åƒç®¡é“ï¼š



```
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kandinsky-community/kandinsky-2-2-decoder", torch_dtype=torch.float16, use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image2image = pipeline("Astronaut in a jungle, cold color palette, muted colors, detailed, 8k", image=text2image).images[0]
make_image_grid([text2image, image2image], rows=1, cols=2)
```


### 


 å›¾åƒåˆ°å›¾åƒåˆ°å›¾åƒ


æ‚¨è¿˜å¯ä»¥å°†å¤šä¸ªå›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥åœ¨ä¸€èµ·ä»¥åˆ›å»ºæ›´æœ‰è¶£çš„å›¾åƒã€‚è¿™å¯¹äºåœ¨å›¾åƒä¸Šè¿­ä»£æ‰§è¡Œæ ·å¼è½¬æ¢ã€ç”ŸæˆçŸ­ GIFã€æ¢å¤å›¾åƒé¢œè‰²æˆ–æ¢å¤å›¾åƒçš„ç¼ºå¤±åŒºåŸŸéå¸¸æœ‰ç”¨ã€‚


é¦–å…ˆç”Ÿæˆå›¾åƒï¼š



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image = pipeline(prompt, image=init_image, output_type="latent").images[0]
```


é‡è¦çš„æ˜¯è¦æŒ‡å®š
 `output_type="æ½œåœ¨"`
 åœ¨ç®¡é“ä¸­å°†æ‰€æœ‰è¾“å‡ºä¿ç•™åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œä»¥é¿å…ä¸å¿…è¦çš„è§£ç -ç¼–ç æ­¥éª¤ã€‚ä»…å½“é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„ VAE æ—¶ï¼Œè¿™æ‰æœ‰æ•ˆã€‚


å°†æ­¤ç®¡é“çš„æ½œåœ¨è¾“å‡ºä¼ é€’åˆ°ä¸‹ä¸€ä¸ªç®¡é“ä»¥ç”Ÿæˆå›¾åƒ
 [æ¼«ç”»è‰ºæœ¯é£æ ¼](https://huggingface.co/ogkalu/Comic-Diffusion)
 :



```
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "ogkalu/Comic-Diffusion", torch_dtype=torch.float16
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# need to include the token "charliebo artstyle" in the prompt to use this checkpoint
image = pipeline("Astronaut in a jungle, charliebo artstyle", image=image, output_type="latent").images[0]
```


å†é‡å¤ä¸€æ¬¡ä»¥ç”Ÿæˆæœ€ç»ˆå›¾åƒ
 [åƒç´ è‰ºæœ¯é£æ ¼](https://huggingface.co/kohbanye/pixel-art-style)
 :



```
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "kohbanye/pixel-art-style", torch_dtype=torch.float16
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# need to include the token "pixelartstyle" in the prompt to use this checkpoint
image = pipeline("Astronaut in a jungle, pixelartstyle", image=image).images[0]
make_image_grid([init_image, image], rows=1, cols=2)
```


### 


 å›¾åƒåˆ°æ”¾å¤§å™¨åˆ°è¶…åˆ†è¾¨ç‡


é“¾æ¥å›¾åƒåˆ°å›¾åƒç®¡é“çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å‡çº§å™¨å’Œè¶…åˆ†è¾¨ç‡ç®¡é“æ¥çœŸæ­£æé«˜å›¾åƒçš„ç»†èŠ‚æ°´å¹³ã€‚


ä»å›¾åƒåˆ°å›¾åƒçš„ç®¡é“å¼€å§‹ï¼š



```
import torch
from diffusers import AutoPipelineForImage2Image
from diffusers.utils import make_image_grid, load_image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)

prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"

# pass prompt and image to pipeline
image_1 = pipeline(prompt, image=init_image, output_type="latent").images[0]
```


é‡è¦çš„æ˜¯è¦æŒ‡å®š
 `output_type="æ½œåœ¨"`
 åœ¨ç®¡é“ä¸­ä»¥ä¿ç•™æ‰€æœ‰è¾“å‡º
 *æ½œ*
 ç©ºé—´ä»¥é¿å…ä¸å¿…è¦çš„è§£ç ç¼–ç æ­¥éª¤ã€‚ä»…å½“é“¾æ¥çš„ç®¡é“ä½¿ç”¨ç›¸åŒçš„ VAE æ—¶ï¼Œè¿™æ‰æœ‰æ•ˆã€‚


å°†å…¶é“¾æ¥åˆ°å‡çº§ç®¡é“ä»¥æé«˜å›¾åƒåˆ†è¾¨ç‡ï¼š



```
from diffusers import StableDiffusionLatentUpscalePipeline

upscaler = StableDiffusionLatentUpscalePipeline.from_pretrained(
    "stabilityai/sd-x2-latent-upscaler", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
upscaler.enable_model_cpu_offload()
upscaler.enable_xformers_memory_efficient_attention()

image_2 = upscaler(prompt, image=image_1, output_type="latent").images[0]
```


æœ€åï¼Œå°†å…¶é“¾æ¥åˆ°è¶…åˆ†è¾¨ç‡ç®¡é“ä»¥è¿›ä¸€æ­¥æé«˜åˆ†è¾¨ç‡ï¼š



```
from diffusers import StableDiffusionUpscalePipeline

super_res = StableDiffusionUpscalePipeline.from_pretrained(
    "stabilityai/stable-diffusion-x4-upscaler", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
super_res.enable_model_cpu_offload()
super_res.enable_xformers_memory_efficient_attention()

image_3 = super_res(prompt, image=image_2).images[0]
make_image_grid([init_image, image_3.resize((512, 512))], rows=1, cols=2)
```


## æ§åˆ¶å›¾åƒç”Ÿæˆ



å°è¯•ç”Ÿæˆçœ‹èµ·æ¥å®Œå…¨ç¬¦åˆæ‚¨æƒ³è¦çš„æ–¹å¼çš„å›¾åƒå¯èƒ½å¾ˆå›°éš¾ï¼Œè¿™å°±æ˜¯æ§åˆ¶ç”ŸæˆæŠ€æœ¯å’Œæ¨¡å‹å¦‚æ­¤æœ‰ç”¨çš„åŸå› ã€‚è™½ç„¶æ‚¨å¯ä»¥ä½¿ç”¨
 `å¦å®šæç¤º`
 ä¸ºäº†éƒ¨åˆ†æ§åˆ¶å›¾åƒç”Ÿæˆï¼Œæœ‰æ›´å¼ºå¤§çš„æ–¹æ³•ï¼Œä¾‹å¦‚æç¤ºåŠ æƒå’Œ ControlNetã€‚


### 


 æç¤ºç§°é‡


æç¤ºæƒé‡å…è®¸æ‚¨ç¼©æ”¾æç¤ºä¸­æ¯ä¸ªæ¦‚å¿µçš„è¡¨ç¤ºã€‚ä¾‹å¦‚ï¼Œåœ¨â€œä¸›æ—ä¸­çš„å®‡èˆªå‘˜ï¼Œå†·è‰²è°ƒï¼ŒæŸ”å’Œçš„é¢œè‰²ï¼Œè¯¦ç»†ï¼Œ8kâ€è¿™æ ·çš„æç¤ºä¸­ï¼Œæ‚¨å¯ä»¥é€‰æ‹©å¢åŠ æˆ–å‡å°‘â€œå®‡èˆªå‘˜â€å’Œâ€œä¸›æ—â€çš„åµŒå…¥ã€‚è¿™
 [å¼ºåˆ¶](https://github.com/damian0815/compel)
 åº“æä¾›äº†ä¸€ä¸ªç®€å•çš„è¯­æ³•æ¥è°ƒæ•´æç¤ºæƒé‡å’Œç”ŸæˆåµŒå…¥ã€‚æ‚¨å¯ä»¥å­¦ä¹ å¦‚ä½•åœ¨ä¸­åˆ›å»ºåµŒå…¥
 [æç¤ºæƒé‡](weighted_prompts)
 æŒ‡å¯¼ã€‚


[AutoPipelineForImage2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)
 æœ‰ä¸€ä¸ª
 `æç¤ºåµŒå…¥`
 ï¼ˆå’Œ
 `å¦å®šæç¤ºåµŒå…¥`
 å¦‚æœæ‚¨ä½¿ç”¨å¦å®šæç¤ºï¼‰å‚æ•°ï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­ä¼ é€’æ›¿æ¢çš„åµŒå…¥
 `æç¤º`
 èŒƒå›´ã€‚



```
from diffusers import AutoPipelineForImage2Image
import torch

pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, # generated from Compel
    negative_prompt_embeds=negative_prompt_embeds, # generated from Compel
    image=init_image,
).images[0]
```


### 


 æ§åˆ¶ç½‘


ControlNet æä¾›äº†ä¸€ç§æ›´çµæ´»ã€æ›´å‡†ç¡®çš„æ–¹æ³•æ¥æ§åˆ¶å›¾åƒç”Ÿæˆï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨é¢å¤–çš„è°ƒèŠ‚å›¾åƒã€‚è°ƒèŠ‚å›¾åƒå¯ä»¥æ˜¯ç²¾æ˜çš„å›¾åƒã€æ·±åº¦å›¾ã€å›¾åƒåˆ†å‰²ï¼Œç”šè‡³æ˜¯æ¶‚é¸¦ï¼æ— è®ºæ‚¨é€‰æ‹©å“ªç§ç±»å‹çš„è°ƒèŠ‚å›¾åƒï¼ŒControlNet éƒ½ä¼šç”Ÿæˆä¸€ä¸ªä¿ç•™å…¶ä¸­ä¿¡æ¯çš„å›¾åƒã€‚


ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ç”¨æ·±åº¦å›¾æ¥è°ƒèŠ‚å›¾åƒä»¥ä¿ç•™å›¾åƒä¸­çš„ç©ºé—´ä¿¡æ¯ã€‚



```
from diffusers.utils import load_image, make_image_grid

# prepare image
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png"
init_image = load_image(url)
init_image = init_image.resize((958, 960)) # resize to depth image dimensions
depth_image = load_image("https://huggingface.co/lllyasviel/control\_v11f1p\_sd15\_depth/resolve/main/images/control.png")
make_image_grid([init_image, depth_image], rows=1, cols=2)
```


åŠ è½½ä»¥æ·±åº¦å›¾ä¸ºæ¡ä»¶çš„ ControlNet æ¨¡å‹ä»¥åŠ
 [AutoPipelineForImage2Image](/docs/diffusers/v0.23.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image)
 :



```
from diffusers import ControlNetModel, AutoPipelineForImage2Image
import torch

controlnet = ControlNetModel.from_pretrained("lllyasviel/control\_v11f1p\_sd15\_depth", torch_dtype=torch.float16, variant="fp16", use_safetensors=True)
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16, variant="fp16", use_safetensors=True
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()
```


ç°åœ¨ç”Ÿæˆä¸€ä¸ªä»¥æ·±åº¦å›¾ã€åˆå§‹å›¾åƒå’Œæç¤ºä¸ºæ¡ä»¶çš„æ–°å›¾åƒï¼š



```
prompt = "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k"
image_control_net = pipeline(prompt, image=init_image, control_image=depth_image).images[0]
make_image_grid([init_image, depth_image, image_control_net], rows=1, cols=3)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-init.png)

 åˆå§‹å›¾åƒ


![](https://huggingface.co/lllyasviel/control_v11f1p_sd15_depth/resolve/main/images/control.png)

 æ·±åº¦å›¾åƒ


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-controlnet.png)

 ControlNet å›¾åƒ


è®©æˆ‘ä»¬åº”ç”¨ä¸€ä¸ªæ–°çš„
 [é£æ ¼](https://huggingface.co/nitrosocke/elden-ring-diffusion)
 é€šè¿‡å°†å…¶ä¸å›¾åƒåˆ°å›¾åƒç®¡é“é“¾æ¥åˆ°ä» ControlNet ç”Ÿæˆçš„å›¾åƒï¼š



```
pipeline = AutoPipelineForImage2Image.from_pretrained(
    "nitrosocke/elden-ring-diffusion", torch_dtype=torch.float16,
).to("cuda")
pipeline.enable_model_cpu_offload()
# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed
pipeline.enable_xformers_memory_efficient_attention()

prompt = "elden ring style astronaut in a jungle" # include the token "elden ring style" in the prompt
negative_prompt = "ugly, deformed, disfigured, poor details, bad anatomy"

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image_control_net, strength=0.45, guidance_scale=10.5).images[0]
make_image_grid([init_image, depth_image, image_control_net, image_elden_ring], rows=2, cols=2)
```


![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/img2img-elden-ring.png)


## ä¼˜åŒ–



è¿è¡Œæ‰©æ•£æ¨¡å‹çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ä¸”å¯†é›†ï¼Œä½†é€šè¿‡ä¸€äº›ä¼˜åŒ–æŠ€å·§ï¼Œå®Œå…¨å¯ä»¥åœ¨æ¶ˆè´¹çº§å’Œå…è´¹ GPU ä¸Šè¿è¡Œå®ƒä»¬ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ›´èŠ‚çœå†…å­˜çš„æ³¨æ„åŠ›å½¢å¼ï¼Œä¾‹å¦‚ PyTorch 2.0 çš„
 [ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›](../optimization/torch2.0#scaled-dot-product-attention)
 æˆ–è€…
 [xFormers](../ä¼˜åŒ–/xformers)
 ï¼ˆæ‚¨å¯ä»¥ä½¿ç”¨å…¶ä¸­ä¹‹ä¸€ï¼Œä½†æ— éœ€åŒæ—¶ä½¿ç”¨ä¸¤è€…ï¼‰ã€‚æ‚¨è¿˜å¯ä»¥å°†æ¨¡å‹å¸è½½åˆ° GPUï¼Œè€Œå…¶ä»–ç®¡é“ç»„ä»¶åˆ™åœ¨ CPU ä¸Šç­‰å¾…ã€‚



```
+ pipeline.enable\_model\_cpu\_offload()
+ pipeline.enable\_xformers\_memory\_efficient\_attention()
```


å’Œ
 [`torch.compile`](../optimization/torch2.0#torchcompile)
 ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç”¨å®ƒåŒ…è£… UNet æ¥è¿›ä¸€æ­¥æé«˜æ¨ç†é€Ÿåº¦ï¼š



```
pipeline.unet = torch.compile(pipeline.unet, mode="reduce-overhead", fullgraph=True)
```


è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹
 [å‡å°‘å†…å­˜ä½¿ç”¨](../ä¼˜åŒ–/å†…å­˜)
 å’Œ
 [ç«ç‚¬2.0](../ä¼˜åŒ–/torch2.0)
 æŒ‡å—ã€‚