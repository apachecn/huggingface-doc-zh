# é‡‘å±æ€§èƒ½ç€è‰²å™¨ (MPS)

> è¯‘è€…ï¼š[ç‰‡åˆ»å°å“¥å“¥](https://github.com/jiangzhonglian)
>
> é¡¹ç›®åœ°å€ï¼š<https://huggingface.apachecn.org/docs/diffusers/optimization/mps>
>
> åŸå§‹åœ°å€ï¼š<https://huggingface.co/docs/diffusers/optimization/mps>


ğŸ¤— Diffusers ä½¿ç”¨ PyTorch ä¸ Apple èŠ¯ç‰‡ï¼ˆM1/M2 èŠ¯ç‰‡ï¼‰å…¼å®¹
 [`mps`](https://pytorch.org/docs/stable/notes/mps.html)
 è®¾å¤‡ï¼Œå®ƒä½¿ç”¨ Metal æ¡†æ¶æ¥åˆ©ç”¨ MacOS è®¾å¤‡ä¸Šçš„ GPUã€‚æ‚¨éœ€è¦ï¼š


* é…å¤‡ Apple Silicon (M1/M2) ç¡¬ä»¶çš„ macOS è®¡ç®—æœº
* macOS 12.6 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆæ¨è 13.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰
*arm64ç‰ˆæœ¬çš„Python
* [PyTorch 2.0](https://pytorch.org/get-started/locally/)
 ï¼ˆæ¨èï¼‰æˆ– 1.13ï¼ˆæ”¯æŒçš„æœ€ä½ç‰ˆæœ¬
 `è®®å‘˜`
 ï¼‰


è¿™
 `è®®å‘˜`
 åç«¯ä½¿ç”¨ PyTorch çš„
 `.to()`
 ç”¨äºå°†ç¨³å®šæ‰©æ•£ç®¡é“ç§»è‡³ M1 æˆ– M2 è®¾å¤‡çš„æ¥å£ï¼š



```
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipe.enable_attention_slicing()

prompt = "a photo of an astronaut riding a horse on mars"
```


å¯ä»¥æ‰¹é‡ç”Ÿæˆå¤šä¸ªæç¤º
 [å´©æºƒ](https://github.com/huggingface/diffusers/issues/363)
 æˆ–ä¸èƒ½å¯é å·¥ä½œã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ä¸
 [`mps`](https://github.com/pytorch/pytorch/issues/84039)
 PyTorch çš„åç«¯ã€‚åœ¨å¯¹æ­¤è¿›è¡Œè°ƒæŸ¥æ—¶ï¼Œæ‚¨åº”è¯¥è¿­ä»£è€Œä¸æ˜¯æ‰¹å¤„ç†ã€‚


å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨
 **PyTorch 1.13**
 ï¼Œæ‚¨éœ€è¦é€šè¿‡é¢å¤–çš„ä¸€æ¬¡æ€§ä¼ é€’æ¥â€œå¯åŠ¨â€ç®¡é“ã€‚è¿™æ˜¯é’ˆå¯¹ç¬¬ä¸€æ¬¡æ¨ç†è¿‡ç¨‹äº§ç”Ÿçš„ç»“æœä¸åç»­æ¨ç†è¿‡ç¨‹ç•¥æœ‰ä¸åŒçš„é—®é¢˜çš„ä¸´æ—¶è§£å†³æ–¹æ³•ã€‚æ‚¨åªéœ€æ‰§è¡Œä¸€æ¬¡æ­¤éï¼Œåªéœ€ä¸€ä¸ªæ¨ç†æ­¥éª¤åï¼Œæ‚¨å°±å¯ä»¥ä¸¢å¼ƒç»“æœã€‚



```
  from diffusers import DiffusionPipeline

  pipe = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5").to("mps")
  pipe.enable_attention_slicing()

  prompt = "a photo of an astronaut riding a horse on mars"
# First-time "warmup" pass if PyTorch version is 1.13
+ \_ = pipe(prompt, num\_inference\_steps=1)

# Results match those from the CPU device after the warmup pass.
  image = pipe(prompt).images[0]
```


## æ•…éšœæ’é™¤



M1/M2 æ€§èƒ½å¯¹å†…å­˜å‹åŠ›éå¸¸æ•æ„Ÿã€‚å‘ç”Ÿè¿™ç§æƒ…å†µæ—¶ï¼Œç³»ç»Ÿä¼šæ ¹æ®éœ€è¦è‡ªåŠ¨äº¤æ¢ï¼Œè¿™ä¼šæ˜¾ç€é™ä½æ€§èƒ½ã€‚


ä¸ºäº†é˜²æ­¢è¿™ç§æƒ…å†µå‘ç”Ÿï¼Œæˆ‘ä»¬å»ºè®®
 *æ³¨æ„åˆ‡ç‰‡*
 ä»¥å‡å°‘æ¨ç†æœŸé—´çš„å†…å­˜å‹åŠ›å¹¶é˜²æ­¢äº¤æ¢ã€‚å¦‚æœæ‚¨çš„è®¡ç®—æœºçš„ç³»ç»Ÿ RAM å°äº 64GBï¼Œæˆ–è€…æ‚¨ä»¥å¤§äº 512Ã—512 åƒç´ çš„éæ ‡å‡†åˆ†è¾¨ç‡ç”Ÿæˆå›¾åƒï¼Œè¿™ä¸€ç‚¹å°¤å…¶é‡è¦ã€‚è‡´ç”µ
 [enable\_attention\_slicing()](/docs/diffusers/v0.23.0/en/api/pipelines/stable_diffusion/image_variation#diffusers.StableDiffusionImageVariationPipeline.enable_attention_slicing)
 åœ¨æ‚¨çš„ç®¡é“ä¸Šè¿è¡Œï¼š



```
from diffusers import DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16, variant="fp16", use_safetensors=True).to("mps")
pipeline.enable_attention_slicing()
```


æ³¨æ„åŠ›åˆ‡ç‰‡åˆ†å¤šä¸ªæ­¥éª¤æ‰§è¡Œä»£ä»·é«˜æ˜‚çš„æ³¨æ„åŠ›æ“ä½œï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å…¨éƒ¨æ‰§è¡Œã€‚åœ¨æ²¡æœ‰é€šç”¨å†…å­˜çš„è®¡ç®—æœºä¸­ï¼Œå®ƒé€šå¸¸å¯ä»¥æé«˜çº¦ 20% çš„æ€§èƒ½ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°
 *æ›´å¥½çš„æ€§èƒ½*
 åœ¨å¤§å¤šæ•° Apple Silicon è®¡ç®—æœºä¸­ï¼Œé™¤éæ‚¨æœ‰ 64GB æˆ–æ›´å¤š RAMã€‚